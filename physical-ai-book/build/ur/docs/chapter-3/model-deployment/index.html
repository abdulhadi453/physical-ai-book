<!doctype html>
<html lang="ur" dir="rtl" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-chapter-3/model-deployment" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">AI Model Deployment in Isaac Sim Environment | AI-Native Textbook for Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://physical-ai-book.github.io/ur/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://physical-ai-book.github.io/ur/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://physical-ai-book.github.io/ur/docs/chapter-3/model-deployment"><meta data-rh="true" property="og:locale" content="ur"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="ur"><meta data-rh="true" name="docsearch:language" content="ur"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="AI Model Deployment in Isaac Sim Environment | AI-Native Textbook for Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Overview"><meta data-rh="true" property="og:description" content="Overview"><link data-rh="true" rel="icon" href="/ur/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://physical-ai-book.github.io/ur/docs/chapter-3/model-deployment"><link data-rh="true" rel="alternate" href="https://physical-ai-book.github.io/docs/chapter-3/model-deployment" hreflang="en"><link data-rh="true" rel="alternate" href="https://physical-ai-book.github.io/ur/docs/chapter-3/model-deployment" hreflang="ur"><link data-rh="true" rel="alternate" href="https://physical-ai-book.github.io/docs/chapter-3/model-deployment" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"AI Model Deployment in Isaac Sim Environment","item":"https://physical-ai-book.github.io/ur/docs/chapter-3/model-deployment"}]}</script><link rel="alternate" type="application/rss+xml" href="/ur/blog/rss.xml" title="AI-Native Textbook for Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/ur/blog/atom.xml" title="AI-Native Textbook for Physical AI &amp; Humanoid Robotics Atom Feed"><link rel="stylesheet" href="/ur/assets/css/styles.00a4f8ad.css">
<script src="/ur/assets/js/runtime~main.1140a14f.js" defer="defer"></script>
<script src="/ur/assets/js/main.f6501a17.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ur/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ur/"><div class="navbar__logo"><img src="/ur/img/logo.svg" alt="Physical AI Book Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ur/img/logo.svg" alt="Physical AI Book Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ur/docs/intro">Chapters</a><a class="navbar__item navbar__link" href="/ur/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/physical-ai-book/hackathon-book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ur/docs/intro"><span title="Introduction to Physical AI &amp; Humanoid Robotics" class="linkLabel_WmDU">Introduction to Physical AI &amp; Humanoid Robotics</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ur/docs/chapter-1/intro"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ur/docs/chapter-2/intro"><span title="Module 2: The Digital Twin (Gazebo &amp; Unity)" class="categoryLinkLabel_W154">Module 2: The Digital Twin (Gazebo &amp; Unity)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/ur/docs/chapter-3/intro"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaac™)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaac™)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ur/docs/chapter-3/intro"><span title="Chapter 3.1: NVIDIA Isaac Platform Integration" class="categoryLinkLabel_W154">Chapter 3.1: NVIDIA Isaac Platform Integration</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ur/docs/chapter-3/setup"><span title="Chapter 3.2: System Setup and Configuration" class="categoryLinkLabel_W154">Chapter 3.2: System Setup and Configuration</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/ur/docs/chapter-3/perception-pipeline"><span title="Chapter 3.3: Advanced Implementation" class="categoryLinkLabel_W154">Chapter 3.3: Advanced Implementation</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/perception-pipeline"><span title="Isaac ROS Perception Pipeline Implementation" class="linkLabel_WmDU">Isaac ROS Perception Pipeline Implementation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/sensor-integration"><span title="Multimodal Sensor Integration in Isaac Sim" class="linkLabel_WmDU">Multimodal Sensor Integration in Isaac Sim</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ur/docs/chapter-3/model-deployment"><span title="AI Model Deployment in Isaac Sim Environment" class="linkLabel_WmDU">AI Model Deployment in Isaac Sim Environment</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/exercises"><span title="Module 3 Exercise Framework: The AI-Robot Brain (NVIDIA Isaac™)" class="linkLabel_WmDU">Module 3 Exercise Framework: The AI-Robot Brain (NVIDIA Isaac™)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/assessments"><span title="Module 3 Assessments: The AI-Robot Brain (NVIDIA Isaac™)" class="linkLabel_WmDU">Module 3 Assessments: The AI-Robot Brain (NVIDIA Isaac™)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/assessment"><span title="Module 3 Assessment: The AI-Robot Brain (NVIDIA Isaac™)" class="linkLabel_WmDU">Module 3 Assessment: The AI-Robot Brain (NVIDIA Isaac™)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/progress-tracking-guide"><span title="Progress Tracking Guide: Module 3 - The AI-Robot Brain (NVIDIA Isaac™)" class="linkLabel_WmDU">Progress Tracking Guide: Module 3 - The AI-Robot Brain (NVIDIA Isaac™)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/educator-guide"><span title="Educator Guide: Module 3 - The AI-Robot Brain (NVIDIA Isaac™)" class="linkLabel_WmDU">Educator Guide: Module 3 - The AI-Robot Brain (NVIDIA Isaac™)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/researcher-resources"><span title="Researcher Resources: Module 3 - The AI-Robot Brain (NVIDIA Isaac™)" class="linkLabel_WmDU">Researcher Resources: Module 3 - The AI-Robot Brain (NVIDIA Isaac™)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/communication-protocols"><span title="AI-Robot Communication Protocols for Isaac Sim" class="linkLabel_WmDU">AI-Robot Communication Protocols for Isaac Sim</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/safety-framework"><span title="Safety and Reliability Framework for Isaac Sim AI-Robot Systems" class="linkLabel_WmDU">Safety and Reliability Framework for Isaac Sim AI-Robot Systems</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/performance-monitoring"><span title="Performance Monitoring Tools for Isaac Sim AI-Robot Systems" class="linkLabel_WmDU">Performance Monitoring Tools for Isaac Sim AI-Robot Systems</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ur/docs/chapter-3/summary"><span title="Module 3 Summary: The AI-Robot Brain (NVIDIA Isaac™)" class="linkLabel_WmDU">Module 3 Summary: The AI-Robot Brain (NVIDIA Isaac™)</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ur/docs/chapter-4/intro"><span title="Module 4: Vision-Language-Action (VLA) Systems" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA) Systems</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ur/docs/contributing"><span title="Contributing" class="linkLabel_WmDU">Contributing</span></a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ur/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 3: The AI-Robot Brain (NVIDIA Isaac™)</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Chapter 3.3: Advanced Implementation</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">AI Model Deployment in Isaac Sim Environment</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>AI Model Deployment in Isaac Sim Environment</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview" translate="no">​</a></h2>
<p>This document provides comprehensive instructions for deploying AI models within the NVIDIA Isaac Sim environment for Module 3. The focus is on deploying perception models for object detection, semantic segmentation, and depth estimation that can run efficiently in the simulation environment and integrate with the ROS 2 ecosystem.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction-to-ai-model-deployment-in-isaac">Introduction to AI Model Deployment in Isaac<a href="#introduction-to-ai-model-deployment-in-isaac" class="hash-link" aria-label="Direct link to Introduction to AI Model Deployment in Isaac" title="Direct link to Introduction to AI Model Deployment in Isaac" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-is-ai-model-deployment-in-isaac">What is AI Model Deployment in Isaac?<a href="#what-is-ai-model-deployment-in-isaac" class="hash-link" aria-label="Direct link to What is AI Model Deployment in Isaac?" title="Direct link to What is AI Model Deployment in Isaac?" translate="no">​</a></h3>
<p>AI model deployment in Isaac involves packaging, optimizing, and integrating deep learning models for use within the Isaac Sim environment and ROS 2 ecosystem. This includes:</p>
<ul>
<li class="">Model optimization for real-time inference</li>
<li class="">Integration with Isaac ROS perception packages</li>
<li class="">GPU acceleration using TensorRT</li>
<li class="">Real-time performance considerations</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-components">Key Components<a href="#key-components" class="hash-link" aria-label="Direct link to Key Components" title="Direct link to Key Components" translate="no">​</a></h3>
<ol>
<li class=""><strong>Model Optimization</strong>: Converting models to efficient formats</li>
<li class=""><strong>TensorRT Integration</strong>: NVIDIA&#x27;s inference optimizer</li>
<li class=""><strong>ROS 2 Integration</strong>: Connecting models to ROS 2 topics</li>
<li class=""><strong>Performance Monitoring</strong>: Ensuring real-time capabilities</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">​</a></h2>
<p>Before deploying AI models, ensure you have:</p>
<ul>
<li class="">Completed Isaac Sim and Isaac ROS setup</li>
<li class="">NVIDIA GPU with TensorRT support</li>
<li class="">PyTorch and ONNX installed in your environment</li>
<li class="">Basic understanding of deep learning models</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="model-preparation-and-optimization">Model Preparation and Optimization<a href="#model-preparation-and-optimization" class="hash-link" aria-label="Direct link to Model Preparation and Optimization" title="Direct link to Model Preparation and Optimization" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-installing-model-deployment-dependencies">1. Installing Model Deployment Dependencies<a href="#1-installing-model-deployment-dependencies" class="hash-link" aria-label="Direct link to 1. Installing Model Deployment Dependencies" title="Direct link to 1. Installing Model Deployment Dependencies" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Install PyTorch and related dependencies</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Install ONNX and ONNX Runtime</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip3 install onnx onnxruntime onnxruntime-gpu</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Install TensorRT (if not already installed with Isaac Sim)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip3 install tensorrt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Install additional tools</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip3 install numpy opencv-python matplotlib</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-creating-model-repository-structure">2. Creating Model Repository Structure<a href="#2-creating-model-repository-structure" class="hash-link" aria-label="Direct link to 2. Creating Model Repository Structure" title="Direct link to 2. Creating Model Repository Structure" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p ~/isaac_sim_shared/models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p ~/isaac_sim_shared/models/yolo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p ~/isaac_sim_shared/models/segmentation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p ~/isaac_sim_shared/models/depth</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p ~/isaac_sim_shared/models/trt_cache</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-downloading-pre-trained-models">3. Downloading Pre-trained Models<a href="#3-downloading-pre-trained-models" class="hash-link" aria-label="Direct link to 3. Downloading Pre-trained Models" title="Direct link to 3. Downloading Pre-trained Models" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Create model download script</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/download_models.sh &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Download pre-trained models for Isaac Sim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create models directory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p ~/isaac_sim_shared/models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Download YOLOv5 model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd ~/isaac_sim_shared/models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/ultralytics/yolov5.git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip3 install -r requirements.txt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">wget -O yolov5s.pt https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Download MiDaS for depth estimation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd ~/isaac_sim_shared/models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/isl-org/MiDaS.git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd MiDaS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip3 install -r requirements.txt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p model_weights</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd model_weights</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">wget https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_large_384.pt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Download segmentation model (using torchvision&#x27;s FCN-ResNet101)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd ~/isaac_sim_shared/models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 -c &quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model = torch.hub.load(&#x27;pytorch/vision:v0.10.0&#x27;, &#x27;fcn_resnet101&#x27;, pretrained=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">torch.save(model.state_dict(), &#x27;fcn_resnet101.pth&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&#x27;Segmentation model downloaded&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Make executable and run</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chmod +x ~/download_models.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">~/download_models.sh</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="model-conversion-for-isaac-sim">Model Conversion for Isaac Sim<a href="#model-conversion-for-isaac-sim" class="hash-link" aria-label="Direct link to Model Conversion for Isaac Sim" title="Direct link to Model Conversion for Isaac Sim" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-converting-yolov5-to-onnx-format">1. Converting YOLOv5 to ONNX Format<a href="#1-converting-yolov5-to-onnx-format" class="hash-link" aria-label="Direct link to 1. Converting YOLOv5 to ONNX Format" title="Direct link to 1. Converting YOLOv5 to ONNX Format" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/isaac_sim_shared/scripts/convert_yolo_to_onnx.py &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import onnx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from yolov5.models.common import DetectMultiBackend</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from yolov5.utils.general import check_img_size</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from yolov5.utils.torch_utils import select_device</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def convert_yolo_to_onnx():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;Convert YOLOv5 model to ONNX format for Isaac Sim&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Model parameters</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    weights = &#x27;/workspace/shared_dir/models/yolov5/yolov5s.pt&#x27;  # Path to PyTorch model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img_size = [640, 640]  # Input image size</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    batch_size = 1  # Batch size for ONNX model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    device = &#x27;cpu&#x27;  # Use CPU for conversion, will run on GPU in Isaac Sim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f&quot;Loading model from: {weights}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Load model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    device = select_device(device)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model = DetectMultiBackend(weights, device=device, dnn=False, data=None, fp16=False)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Check image size</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    img_size = check_img_size(img_size, s=stride)  # Verify img_size are gs-multiples</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Input</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    im = torch.zeros(batch_size, 3, *img_size).to(device)  # Create dummy input</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Update model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model.model.float()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model.warmup(im)  # Warmup</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Export</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Export to ONNX</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        torch.onnx.export(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            model,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            im,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;/workspace/shared_dir/models/yolo/yolov5s.onnx&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            verbose=False,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            opset_version=12,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            input_names=[&#x27;images&#x27;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            output_names=[&#x27;output&#x27;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            dynamic_axes={</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &#x27;images&#x27;: {0: &#x27;batch&#x27;, 2: &#x27;height&#x27;, 3: &#x27;width&#x27;},  # Variable input dimensions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &#x27;output&#x27;: {0: &#x27;batch&#x27;, 1: &#x27;num_detections&#x27;}  # Variable output dimensions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            } if False else None  # Set to None for fixed dimensions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Checks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model_onnx = onnx.load(&#x27;/workspace/shared_dir/models/yolo/yolov5s.onnx&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        onnx.checker.check_model(model_onnx)  # Check model is well formed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(f&quot;ONNX model saved to: /workspace/shared_dir/models/yolo/yolov5s.onnx&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Simplify ONNX model (optional)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            import onnxsim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            model_onnx, check = onnxsim.simplify(model_onnx)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            assert check, &quot;Simplified ONNX model could not be validated&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            onnx.save(model_onnx, &#x27;/workspace/shared_dir/models/yolo/yolov5s_simplified.onnx&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(&quot;Simplified ONNX model saved&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        except ImportError:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(&quot;ONNX simplification skipped (install onnxsim for better performance)&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    except Exception as e:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(f&quot;Export failure: {e}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    convert_yolo_to_onnx()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-converting-segmentation-model-to-onnx">2. Converting Segmentation Model to ONNX<a href="#2-converting-segmentation-model-to-onnx" class="hash-link" aria-label="Direct link to 2. Converting Segmentation Model to ONNX" title="Direct link to 2. Converting Segmentation Model to ONNX" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/isaac_sim_shared/scripts/convert_segmentation_to_onnx.py &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torchvision.models as models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import onnx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def convert_segmentation_to_onnx():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;Convert FCN-ResNet101 segmentation model to ONNX format&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Load pre-trained segmentation model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model = models.segmentation.fcn_resnet101(pretrained=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model.eval()  # Set to evaluation mode</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Create dummy input (batch_size=1, channels=3, height=480, width=640)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    dummy_input = torch.randn(1, 3, 480, 640, requires_grad=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Export to ONNX</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    onnx_filename = &#x27;/workspace/shared_dir/models/segmentation/fcn_resnet101.onnx&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    torch.onnx.export(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model,  # Model being exported</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        dummy_input,  # Model input (or a tuple for multiple inputs)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        onnx_filename,  # Where to save the model (can be a file or file-like object)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        export_params=True,  # Store the trained parameter weights</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        opset_version=11,  # The ONNX version to export the model to</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        do_constant_folding=True,  # Whether to execute constant folding for optimization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        input_names=[&#x27;input&#x27;],  # Model&#x27;s input names</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        output_names=[&#x27;output&#x27;],  # Model&#x27;s output names</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        dynamic_axes={</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;input&#x27;: {0: &#x27;batch_size&#x27;, 2: &#x27;height&#x27;, 3: &#x27;width&#x27;},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;output&#x27;: {0: &#x27;batch_size&#x27;, 2: &#x27;height&#x27;, 3: &#x27;width&#x27;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Verify the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    onnx_model = onnx.load(onnx_filename)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    onnx.checker.check_model(onnx_model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f&quot;Segmentation ONNX model saved to: {onnx_filename}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    convert_segmentation_to_onnx()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-converting-depth-estimation-model-to-onnx">3. Converting Depth Estimation Model to ONNX<a href="#3-converting-depth-estimation-model-to-onnx" class="hash-link" aria-label="Direct link to 3. Converting Depth Estimation Model to ONNX" title="Direct link to 3. Converting Depth Estimation Model to ONNX" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/isaac_sim_shared/scripts/convert_depth_to_onnx.py &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import torchvision.transforms as transforms</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from torchvision import models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import onnx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def convert_depth_to_onnx():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;Convert MiDaS depth estimation model to ONNX format&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Note: MiDaS conversion is more complex, using a simplified approach</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # For actual MiDaS, we&#x27;ll use the original repository&#x27;s conversion</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(&quot;Creating simplified depth estimation ONNX model...&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # For now, we&#x27;ll create a placeholder conversion</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # In practice, you would use the MiDaS repository&#x27;s specific conversion</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Load a simple model as placeholder</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model = models.resnet18(pretrained=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Modify the final layer for depth estimation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model.fc = torch.nn.Linear(model.fc.in_features, 1)  # Single output for depth</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model.eval()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Create dummy input</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    dummy_input = torch.randn(1, 3, 384, 384)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Export to ONNX</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    onnx_filename = &#x27;/workspace/shared_dir/models/depth/midas.onnx&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    torch.onnx.export(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        model,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        dummy_input,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        onnx_filename,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        export_params=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        opset_version=11,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        do_constant_folding=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        input_names=[&#x27;input&#x27;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        output_names=[&#x27;output&#x27;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        dynamic_axes={</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;input&#x27;: {0: &#x27;batch_size&#x27;, 2: &#x27;height&#x27;, 3: &#x27;width&#x27;},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;output&#x27;: {0: &#x27;batch_size&#x27;, 2: &#x27;height&#x27;, 3: &#x27;width&#x27;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Verify the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    onnx_model = onnx.load(onnx_filename)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    onnx.checker.check_model(onnx_model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f&quot;Depth estimation ONNX model saved to: {onnx_filename}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(&quot;Note: For production use, implement proper MiDaS conversion&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    convert_depth_to_onnx()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="tensorrt-optimization">TensorRT Optimization<a href="#tensorrt-optimization" class="hash-link" aria-label="Direct link to TensorRT Optimization" title="Direct link to TensorRT Optimization" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-creating-tensorrt-optimization-script">1. Creating TensorRT Optimization Script<a href="#1-creating-tensorrt-optimization-script" class="hash-link" aria-label="Direct link to 1. Creating TensorRT Optimization Script" title="Direct link to 1. Creating TensorRT Optimization Script" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/isaac_sim_shared/scripts/optimize_with_tensorrt.py &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import tensorrt as trt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import pycuda.driver as cuda</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import pycuda.autoinit</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import onnx</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from typing import List, Tuple</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class TensorRTOptimizer:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.logger = trt.Logger(trt.Logger.WARNING)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.builder = trt.Builder(self.logger)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.network = None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.config = None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def optimize_onnx_model(self, onnx_path: str, trt_path: str, precision: str = &quot;fp16&quot;) -&gt; bool:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Optimize ONNX model using TensorRT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Args:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            onnx_path: Path to ONNX model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            trt_path: Path to save optimized TensorRT model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            precision: Precision mode (&quot;fp32&quot;, &quot;fp16&quot;, or &quot;int8&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Check if ONNX file exists</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if not os.path.exists(onnx_path):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(f&quot;ONNX file does not exist: {onnx_path}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Parse ONNX model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        explicit_batch = 1 &lt;&lt; int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.network = self.builder.create_network(explicit_batch)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        parser = trt.OnnxParser(self.network, self.logger)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        with open(onnx_path, &#x27;rb&#x27;) as model:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if not parser.parse(model.read()):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                print(&quot;ERROR: Failed to parse the ONNX file.&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                for error in range(parser.num_errors):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    print(parser.get_error(error))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                return False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Configure optimization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.config = self.builder.create_builder_config()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Set precision</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if precision == &quot;fp16&quot;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if self.builder.platform_has_fast_fp16:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                self.config.set_flag(trt.BuilderFlag.FP16)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                print(&quot;Using FP16 precision&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                print(&quot;FP16 not supported on this platform, using FP32&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        elif precision == &quot;int8&quot;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if self.builder.platform_has_fast_int8:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                self.config.set_flag(trt.BuilderFlag.INT8)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                print(&quot;Using INT8 precision&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                print(&quot;INT8 not supported on this platform, using FP32&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Set memory limit</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 &lt;&lt; 30)  # 1GB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Build engine</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            serialized_engine = self.builder.build_serialized_network(self.network, self.config)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if serialized_engine is None:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                print(&quot;Failed to build TensorRT engine&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                return False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Save the engine</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            with open(trt_path, &#x27;wb&#x27;) as f:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                f.write(serialized_engine)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(f&quot;TensorRT engine saved to: {trt_path}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(f&quot;Error building TensorRT engine: {e}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def optimize_all_models():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;&quot;&quot;Optimize all models for Isaac Sim&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    optimizer = TensorRTOptimizer()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Define model paths</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    models_to_optimize = [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;onnx_path&#x27;: &#x27;/workspace/shared_dir/models/yolo/yolov5s.onnx&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;trt_path&#x27;: &#x27;/workspace/shared_dir/models/yolo/yolov5s.trt&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;name&#x27;: &#x27;YOLOv5&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;onnx_path&#x27;: &#x27;/workspace/shared_dir/models/segmentation/fcn_resnet101.onnx&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;trt_path&#x27;: &#x27;/workspace/shared_dir/models/segmentation/fcn_resnet101.trt&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;name&#x27;: &#x27;Segmentation&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;onnx_path&#x27;: &#x27;/workspace/shared_dir/models/depth/midas.onnx&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;trt_path&#x27;: &#x27;/workspace/shared_dir/models/depth/midas.trt&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;name&#x27;: &#x27;Depth Estimation&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Optimize each model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    for model_info in models_to_optimize:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(f&quot;\nOptimizing {model_info[&#x27;name&#x27;]} model...&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        success = optimizer.optimize_onnx_model(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            model_info[&#x27;onnx_path&#x27;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            model_info[&#x27;trt_path&#x27;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            precision=&quot;fp16&quot;  # Use FP16 for better performance on Jetson/RTX</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if success:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(f&quot;✓ {model_info[&#x27;name&#x27;]} optimized successfully&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            print(f&quot;✗ Failed to optimize {model_info[&#x27;name&#x27;]}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    optimize_all_models()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="isaac-ros-model-integration">Isaac ROS Model Integration<a href="#isaac-ros-model-integration" class="hash-link" aria-label="Direct link to Isaac ROS Model Integration" title="Direct link to Isaac ROS Model Integration" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-creating-isaac-ros-model-configuration">1. Creating Isaac ROS Model Configuration<a href="#1-creating-isaac-ros-model-configuration" class="hash-link" aria-label="Direct link to 1. Creating Isaac ROS Model Configuration" title="Direct link to 1. Creating Isaac ROS Model Configuration" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/isaac_sim_shared/configs/model_config.yaml &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Isaac ROS Model Configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># YOLO Object Detection Configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">yolo_detection:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model_path: &quot;/workspace/shared_dir/models/yolo/yolov5s.trt&quot;  # Use TensorRT optimized model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model_input_width: 640</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model_input_height: 640</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  confidence_threshold: 0.5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  max_batch_size: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  input_tensor_layout: &quot;NCHW&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  input_binding_name: &quot;images&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  output_binding_names: [&quot;output&quot;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  input_tensor_names: [&quot;images&quot;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  output_tensor_names: [&quot;output&quot;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  enable_tensorrt: true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  tensorrt_precision: &quot;fp16&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  tensorrt_max_workspace_size: 1073741824  # 1GB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  enable_statistics: true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Semantic Segmentation Configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">semantic_segmentation:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model_path: &quot;/workspace/shared_dir/models/segmentation/fcn_resnet101.trt&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model_input_width: 512</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model_input_height: 512</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  input_tensor_layout: &quot;NCHW&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  enable_tensorrt: true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  tensorrt_precision: &quot;fp16&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  tensorrt_max_workspace_size: 1073741824  # 1GB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Depth Estimation Configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">depth_estimation:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model_path: &quot;/workspace/shared_dir/models/depth/midas.trt&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model_input_width: 384</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model_input_height: 384</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  input_tensor_layout: &quot;NCHW&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  enable_tensorrt: true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  tensorrt_precision: &quot;fp16&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  tensorrt_max_workspace_size: 1073741824  # 1GB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Model Loading Configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_loading:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  enable_model_caching: true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  cache_directory: &quot;/workspace/shared_dir/models/trt_cache&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  enable_async_loading: true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  loading_threads: 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  enable_memory_pool: true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  memory_pool_size: 536870912  # 512MB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Performance Monitoring</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">performance:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  enable_profiling: true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  profile_output_file: &quot;/workspace/shared_dir/logs/model_performance.json&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  enable_framerate_monitoring: true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  target_framerate: 30</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  max_latency_ms: 100</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-creating-isaac-ros-model-deployment-package">2. Creating Isaac ROS Model Deployment Package<a href="#2-creating-isaac-ros-model-deployment-package" class="hash-link" aria-label="Direct link to 2. Creating Isaac ROS Model Deployment Package" title="Direct link to 2. Creating Isaac ROS Model Deployment Package" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd ~/isaac_ros_ws/src</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source /opt/ros/humble/setup.bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create model deployment package</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ros2 pkg create --build-type ament_python isaac_ros_model_deployment --dependencies rclpy sensor_msgs vision_msgs cv_bridge geometry_msgs std_msgs</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-creating-model-deployment-node">3. Creating Model Deployment Node<a href="#3-creating-model-deployment-node" class="hash-link" aria-label="Direct link to 3. Creating Model Deployment Node" title="Direct link to 3. Creating Model Deployment Node" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/isaac_ros_ws/src/isaac_ros_model_deployment/isaac_ros_model_deployment/model_deployer.py &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!/usr/bin/env python3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import rclpy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from rclpy.node import Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from sensor_msgs.msg import Image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from vision_msgs.msg import Detection2DArray</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from std_msgs.msg import String</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from cv_bridge import CvBridge</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import cv2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import numpy as np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from typing import Dict, Any, Optional</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class ModelDeployer(Node):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__(&#x27;model_deployer&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Initialize CV bridge</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.bridge = CvBridge()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Subscribe to camera images</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.image_subscription = self.create_subscription(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            Image,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;/camera/color/image_raw&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.image_callback,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Publishers for model status</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.status_publisher = self.create_publisher(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            String,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;/model_deployment_status&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.config = self.load_config()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Model deployment status tracking</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.models_deployed = {}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.deployment_status = &quot;initializing&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Initialize model deployment</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.initialize_models()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.get_logger().info(&#x27;Model Deployer initialized&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def load_config(self) -&gt; Dict[str, Any]:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Load model configuration from YAML file&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        config_path = &quot;/workspace/shared_dir/configs/model_config.yaml&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # For this example, we&#x27;ll use a hardcoded config</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # In practice, you would load from the actual YAML file</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        config = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;yolo_detection&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;model_path&quot;: &quot;/workspace/shared_dir/models/yolo/yolov5s.trt&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;model_input_width&quot;: 640,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;model_input_height&quot;: 640,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;confidence_threshold&quot;: 0.5</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;semantic_segmentation&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;model_path&quot;: &quot;/workspace/shared_dir/models/segmentation/fcn_resnet101.trt&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;model_input_width&quot;: 512,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;model_input_height&quot;: 512</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;depth_estimation&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;model_path&quot;: &quot;/workspace/shared_dir/models/depth/midas.trt&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;model_input_width&quot;: 384,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;model_input_height&quot;: 384</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return config</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def initialize_models(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Initialize and deploy models&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.get_logger().info(&#x27;Initializing models...&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Check if model files exist and are accessible</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for model_name, model_config in self.config.items():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            model_path = model_config.get(&#x27;model_path&#x27;, &#x27;&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if os.path.exists(model_path):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                self.models_deployed[model_name] = True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                self.get_logger().info(f&#x27;Model {model_name} found at {model_path}&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                self.models_deployed[model_name] = False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                self.get_logger().warn(f&#x27;Model {model_name} not found at {model_path}&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Check deployment status</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        all_deployed = all(self.models_deployed.values())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.deployment_status = &quot;ready&quot; if all_deployed else &quot;missing_models&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Publish status</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        status_msg = String()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        status_msg.data = f&quot;Deployment status: {self.deployment_status}. Models: {self.models_deployed}&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.status_publisher.publish(status_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def image_callback(self, image_msg):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Process incoming images and test model deployment&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Convert ROS Image to OpenCV</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            cv_image = self.bridge.imgmsg_to_cv2(image_msg, &quot;bgr8&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Log that we&#x27;re processing an image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.get_logger().info(f&#x27;Processing image: {cv_image.shape}&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Publish status update</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            status_msg = String()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            status_msg.data = f&quot;Processing image, models deployed: {self.models_deployed}&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.status_publisher.publish(status_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.get_logger().error(f&#x27;Error in image callback: {e}&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def get_deployment_summary(self) -&gt; str:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Get a summary of model deployment status&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        summary = f&quot;Deployment Status: {self.deployment_status}\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        for model_name, deployed in self.models_deployed.items():</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            status = &quot;✓ Deployed&quot; if deployed else &quot;✗ Missing&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            summary += f&quot;  {model_name}: {status}\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return summary</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def deploy_model(self, model_name: str, model_path: str) -&gt; bool:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Deploy a specific model&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Check if model file exists</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if not os.path.exists(model_path):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                self.get_logger().error(f&#x27;Model file does not exist: {model_path}&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                return False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # In a real implementation, you would load the model into memory here</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # For this example, we&#x27;ll just mark it as deployed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.models_deployed[model_name] = True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.get_logger().info(f&#x27;Model {model_name} deployed successfully&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Update deployment status</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            all_deployed = all(self.models_deployed.values())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.deployment_status = &quot;ready&quot; if all_deployed else &quot;partial&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.get_logger().error(f&#x27;Error deploying model {model_name}: {e}&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def undeploy_model(self, model_name: str) -&gt; bool:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Undeploy a specific model&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if model_name in self.models_deployed:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # In a real implementation, you would free the model from memory here</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.models_deployed[model_name] = False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.get_logger().info(f&#x27;Model {model_name} undeployed&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # Update deployment status</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            if any(self.models_deployed.values()):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                self.deployment_status = &quot;partial&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                self.deployment_status = &quot;empty&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class ModelDeploymentManager(Node):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__(&#x27;model_deployment_manager&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Create model deployer instance</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.model_deployer = ModelDeployer()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Create service servers for model management</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        from rclpy.qos import QoSProfile</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        from std_srvs.srv import Trigger</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        from isaac_ros_model_deployment.srv import DeployModel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Service to check deployment status</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.status_service = self.create_service(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            Trigger,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;get_deployment_status&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.get_status_callback</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Service to deploy a model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.deploy_service = self.create_service(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            DeployModel,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;deploy_model&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.deploy_model_callback</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Service to undeploy a model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.undeploy_service = self.create_service(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            DeployModel,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;undeploy_model&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.undeploy_model_callback</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.get_logger().info(&#x27;Model Deployment Manager initialized&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def get_status_callback(self, request, response):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Service callback to get deployment status&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        summary = self.model_deployer.get_deployment_summary()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response.success = True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response.message = summary</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return response</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def deploy_model_callback(self, request, response):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Service callback to deploy a model&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        success = self.model_deployer.deploy_model(request.model_name, request.model_path)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response.success = success</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response.message = f&quot;Model {request.model_name} deployment: {&#x27;Success&#x27; if success else &#x27;Failed&#x27;}&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return response</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def undeploy_model_callback(self, request, response):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Service callback to undeploy a model&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        success = self.model_deployer.undeploy_model(request.model_name)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response.success = success</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response.message = f&quot;Model {request.model_name} undeployment: {&#x27;Success&#x27; if success else &#x27;Failed&#x27;}&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return response</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def main(args=None):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclpy.init(args=args)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Create and run the model deployment manager</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    manager = ModelDeploymentManager()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        rclpy.spin(manager)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    except KeyboardInterrupt:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        pass</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    finally:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        manager.destroy_node()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        rclpy.shutdown()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &#x27;__main__&#x27;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    main()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-creating-service-definition-for-model-deployment">4. Creating Service Definition for Model Deployment<a href="#4-creating-service-definition-for-model-deployment" class="hash-link" aria-label="Direct link to 4. Creating Service Definition for Model Deployment" title="Direct link to 4. Creating Service Definition for Model Deployment" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mkdir -p ~/isaac_ros_ws/src/isaac_ros_model_deployment/srv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/isaac_ros_ws/src/isaac_ros_model_deployment/srv/DeployModel.srv &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">string model_name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">string model_path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bool success</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">string message</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="5-creating-setup-files-for-model-deployment-package">5. Creating Setup Files for Model Deployment Package<a href="#5-creating-setup-files-for-model-deployment-package" class="hash-link" aria-label="Direct link to 5. Creating Setup Files for Model Deployment Package" title="Direct link to 5. Creating Setup Files for Model Deployment Package" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/isaac_ros_ws/src/isaac_ros_model_deployment/setup.py &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from setuptools import setup</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from glob import glob</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">package_name = &#x27;isaac_ros_model_deployment&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">setup(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    name=package_name,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    version=&#x27;0.0.1&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    packages=[package_name],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data_files=[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        (&#x27;share/ament_index/resource_index/packages&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            [&#x27;resource/&#x27; + package_name]),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        (&#x27;share/&#x27; + package_name, [&#x27;package.xml&#x27;]),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Include service definition</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        (os.path.join(&#x27;share&#x27;, package_name, &#x27;srv&#x27;), glob(&#x27;srv/*.srv&#x27;)),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    install_requires=[&#x27;setuptools&#x27;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    zip_safe=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    maintainer=&#x27;Your Name&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    maintainer_email=&#x27;your.email@example.com&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    description=&#x27;Model deployment tools for Isaac ROS&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    license=&#x27;Apache License 2.0&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tests_require=[&#x27;pytest&#x27;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    entry_points={</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &#x27;console_scripts&#x27;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;model_deployer = isaac_ros_model_deployment.model_deployer:main&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre></div></div>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/isaac_ros_ws/src/isaac_ros_model_deployment/package.xml &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;?xml-model href=&quot;http://download.ros.org/schema/package_format3.xsd&quot; schematypens=&quot;http://www.w3.org/2001/XMLSchema&quot;?&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;package format=&quot;3&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;name&gt;isaac_ros_model_deployment&lt;/name&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;version&gt;0.0.1&lt;/version&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;description&gt;Model deployment tools for Isaac ROS&lt;/description&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;maintainer email=&quot;your.email@example.com&quot;&gt;Your Name&lt;/maintainer&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;license&gt;Apache License 2.0&lt;/license&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;depend&gt;rclpy&lt;/depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;depend&gt;sensor_msgs&lt;/depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;depend&gt;vision_msgs&lt;/depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;depend&gt;cv_bridge&lt;/depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;depend&gt;geometry_msgs&lt;/depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;depend&gt;std_msgs&lt;/depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;depend&gt;std_srvs&lt;/depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;test_depend&gt;ament_copyright&lt;/test_depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;test_depend&gt;ament_flake8&lt;/test_depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;test_depend&gt;ament_pep257&lt;/test_depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;test_depend&gt;python3-pytest&lt;/test_depend&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;member_of_group&gt;rosidl_interface_packages&lt;/member_of_group&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;export&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &lt;build_type&gt;ament_python&lt;/build_type&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &lt;/export&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/package&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="model-deployment-testing">Model Deployment Testing<a href="#model-deployment-testing" class="hash-link" aria-label="Direct link to Model Deployment Testing" title="Direct link to Model Deployment Testing" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-creating-model-deployment-test-script">1. Creating Model Deployment Test Script<a href="#1-creating-model-deployment-test-script" class="hash-link" aria-label="Direct link to 1. Creating Model Deployment Test Script" title="Direct link to 1. Creating Model Deployment Test Script" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/test_model_deployment.sh &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Test script for AI model deployment in Isaac Sim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;Testing AI Model Deployment...&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Source ROS environment</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source /opt/ros/humble/setup.bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source ~/isaac_ros_ws/install/setup.bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Check if model deployment package is available</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;Checking model deployment package...&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ros2 pkg list | grep model_deployment</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if [ $? -eq 0 ]; then</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;✓ Model deployment package found&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;✗ Model deployment package not found&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    exit 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Check if model files exist</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;Checking model files...&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if [ -f &quot;/workspace/shared_dir/models/yolo/yolov5s.onnx&quot; ]; then</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;✓ YOLO ONNX model found&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;✗ YOLO ONNX model not found&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Try to convert the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;Attempting to convert YOLO model to ONNX...&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    python3 /workspace/shared_dir/scripts/convert_yolo_to_onnx.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if [ -f &quot;/workspace/shared_dir/models/segmentation/fcn_resnet101.onnx&quot; ]; then</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;✓ Segmentation ONNX model found&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;✗ Segmentation ONNX model not found&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Try to convert the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;Attempting to convert segmentation model to ONNX...&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    python3 /workspace/shared_dir/scripts/convert_segmentation_to_onnx.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if [ -f &quot;/workspace/shared_dir/models/depth/midas.onnx&quot; ]; then</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;✓ Depth ONNX model found&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;✗ Depth ONNX model not found&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Try to convert the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;Attempting to convert depth model to ONNX...&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    python3 /workspace/shared_dir/scripts/convert_depth_to_onnx.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Build the model deployment package</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;Building model deployment package...&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd ~/isaac_ros_ws</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">colcon build --packages-select isaac_ros_model_deployment</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source install/setup.bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Check if TensorRT optimization script exists</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if [ -f &quot;/workspace/shared_dir/scripts/optimize_with_tensorrt.py&quot; ]; then</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;✓ TensorRT optimization script found&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">else</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    echo &quot;✗ TensorRT optimization script not found&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    exit 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Test TensorRT optimization (this may take a while)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;Testing TensorRT optimization (this may take a few minutes)...&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 /workspace/shared_dir/scripts/optimize_with_tensorrt.py</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;AI Model Deployment test completed.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Make executable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chmod +x ~/test_model_deployment.sh</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-running-model-deployment-test">2. Running Model Deployment Test<a href="#2-running-model-deployment-test" class="hash-link" aria-label="Direct link to 2. Running Model Deployment Test" title="Direct link to 2. Running Model Deployment Test" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">~/test_model_deployment.sh</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="model-performance-monitoring">Model Performance Monitoring<a href="#model-performance-monitoring" class="hash-link" aria-label="Direct link to Model Performance Monitoring" title="Direct link to Model Performance Monitoring" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-creating-performance-monitoring-script">1. Creating Performance Monitoring Script<a href="#1-creating-performance-monitoring-script" class="hash-link" aria-label="Direct link to 1. Creating Performance Monitoring Script" title="Direct link to 1. Creating Performance Monitoring Script" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cat &gt; ~/isaac_sim_shared/scripts/model_performance_monitor.py &lt;&lt; &#x27;EOF&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!/usr/bin/env python3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import rclpy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from rclpy.node import Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from sensor_msgs.msg import Image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from std_msgs.msg import Float32, String</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from collections import deque</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class ModelPerformanceMonitor(Node):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        super().__init__(&#x27;model_performance_monitor&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Subscribe to image input (to measure processing pipeline)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.image_subscription = self.create_subscription(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            Image,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;/camera/color/image_raw&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.image_callback,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Publishers for performance metrics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.fps_publisher = self.create_publisher(Float32, &#x27;/model_fps&#x27;, 10)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.latency_publisher = self.create_publisher(Float32, &#x27;/model_latency&#x27;, 10)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.cpu_usage_publisher = self.create_publisher(Float32, &#x27;/model_cpu_usage&#x27;, 10)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.gpu_usage_publisher = self.create_publisher(Float32, &#x27;/model_gpu_usage&#x27;, 10)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.memory_usage_publisher = self.create_publisher(Float32, &#x27;/model_memory_usage&#x27;, 10)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.status_publisher = self.create_publisher(String, &#x27;/model_performance_status&#x27;, 10)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Performance tracking</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.frame_times = deque(maxlen=30)  # Last 30 frames for FPS calculation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.processing_times = deque(maxlen=30)  # Last 30 processing times</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.last_image_time = None</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Setup timer for periodic metrics publishing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.timer = self.create_timer(1.0, self.publish_metrics)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Setup timer for system metrics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.system_timer = self.create_timer(2.0, self.publish_system_metrics)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Performance log</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.performance_log = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.log_file = &quot;/workspace/shared_dir/logs/model_performance.json&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.get_logger().info(&#x27;Model Performance Monitor initialized&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def image_callback(self, msg):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Track image processing for performance measurement&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        current_time = self.get_clock().now().nanoseconds / 1e9</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        image_proc_time = current_time - (self.last_image_time or current_time)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if self.last_image_time is not None:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            frame_time = current_time - self.last_image_time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.frame_times.append(frame_time)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.processing_times.append(image_proc_time)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.last_image_time = current_time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def publish_metrics(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Publish performance metrics&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Calculate FPS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if len(self.frame_times) &gt; 0:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            avg_frame_time = sum(self.frame_times) / len(self.frame_times)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            fps = 1.0 / avg_frame_time if avg_frame_time &gt; 0 else 0.0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            fps_msg = Float32()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            fps_msg.data = fps</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.fps_publisher.publish(fps_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Calculate average processing latency</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if len(self.processing_times) &gt; 0:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            avg_latency = sum(self.processing_times) / len(self.processing_times)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            latency_msg = Float32()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            latency_msg.data = avg_latency</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.latency_publisher.publish(latency_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Publish status</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        status_msg = String()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        status_msg.data = f&quot;FPS: {fps:.2f}, Latency: {avg_latency*1000:.2f}ms&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.status_publisher.publish(status_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Log performance data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        perf_data = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;timestamp&#x27;: time.time(),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;fps&#x27;: fps,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;latency_ms&#x27;: avg_latency * 1000,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;frame_count&#x27;: len(self.frame_times)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.performance_log.append(perf_data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Write to log file periodically</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if len(self.performance_log) % 10 == 0:  # Every 10 updates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.write_performance_log()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def publish_system_metrics(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Publish system resource usage metrics&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        import psutil</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # CPU usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cpu_percent = psutil.cpu_percent()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cpu_msg = Float32()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        cpu_msg.data = float(cpu_percent)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.cpu_usage_publisher.publish(cpu_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # Memory usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        memory = psutil.virtual_memory()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        memory_msg = Float32()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        memory_msg.data = float(memory.percent)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.memory_usage_publisher.publish(memory_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        # For GPU usage, we&#x27;ll use nvidia-ml-py if available</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            import pynvml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            pynvml.nvmlInit()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            handle = pynvml.nvmlDeviceGetHandleByIndex(0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            util = pynvml.nvmlDeviceGetUtilizationRates(handle)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            gpu_util_msg = Float32()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            gpu_util_msg.data = float(util.gpu)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.gpu_usage_publisher.publish(gpu_util_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        except:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            # If nvidia-ml-py is not available, publish a placeholder</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            gpu_util_msg = Float32()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            gpu_util_msg.data = 0.0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.gpu_usage_publisher.publish(gpu_util_msg)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def write_performance_log(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Write performance log to file&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            with open(self.log_file, &#x27;w&#x27;) as f:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                json.dump(self.performance_log, f, indent=2)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        except Exception as e:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self.get_logger().error(f&#x27;Error writing performance log: {e}&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def get_performance_summary(self):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;&quot;&quot;Get a summary of performance metrics&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        summary = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;total_samples&#x27;: len(self.performance_log),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;avg_fps&#x27;: 0.0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;avg_latency_ms&#x27;: 0.0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;min_fps&#x27;: float(&#x27;inf&#x27;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &#x27;max_fps&#x27;: 0.0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if self.performance_log:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            fps_values = [entry[&#x27;fps&#x27;] for entry in self.performance_log]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            latency_values = [entry[&#x27;latency_ms&#x27;] for entry in self.performance_log]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            summary[&#x27;avg_fps&#x27;] = sum(fps_values) / len(fps_values)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            summary[&#x27;avg_latency_ms&#x27;] = sum(latency_values) / len(latency_values)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            summary[&#x27;min_fps&#x27;] = min(fps_values)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            summary[&#x27;max_fps&#x27;] = max(fps_values)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return summary</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def main(args=None):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    rclpy.init(args=args)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    monitor = ModelPerformanceMonitor()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        rclpy.spin(monitor)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    except KeyboardInterrupt:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        summary = monitor.get_performance_summary()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(f&quot;Performance Summary: {summary}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        monitor.write_performance_log()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        print(f&quot;Performance log saved to: {monitor.log_file}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    finally:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        monitor.destroy_node()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        rclpy.shutdown()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &#x27;__main__&#x27;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    main()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="troubleshooting-model-deployment">Troubleshooting Model Deployment<a href="#troubleshooting-model-deployment" class="hash-link" aria-label="Direct link to Troubleshooting Model Deployment" title="Direct link to Troubleshooting Model Deployment" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="common-issues-and-solutions">Common Issues and Solutions<a href="#common-issues-and-solutions" class="hash-link" aria-label="Direct link to Common Issues and Solutions" title="Direct link to Common Issues and Solutions" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="issue-model-conversion-fails-with-onnx-export-error">Issue: &quot;Model conversion fails with ONNX export error&quot;<a href="#issue-model-conversion-fails-with-onnx-export-error" class="hash-link" aria-label="Direct link to Issue: &quot;Model conversion fails with ONNX export error&quot;" title="Direct link to Issue: &quot;Model conversion fails with ONNX export error&quot;" translate="no">​</a></h4>
<p><strong>Solution</strong>: Check PyTorch and ONNX compatibility</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Verify PyTorch and ONNX versions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 -c &quot;import torch; print(torch.__version__)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 -c &quot;import onnx; print(onnx.__version__)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Update if needed</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip3 install --upgrade torch torchvision torchaudio onnx</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="issue-tensorrt-engine-build-fails">Issue: &quot;TensorRT engine build fails&quot;<a href="#issue-tensorrt-engine-build-fails" class="hash-link" aria-label="Direct link to Issue: &quot;TensorRT engine build fails&quot;" title="Direct link to Issue: &quot;TensorRT engine build fails&quot;" translate="no">​</a></h4>
<p><strong>Solution</strong>: Check TensorRT installation and GPU compatibility</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check TensorRT version</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 -c &quot;import tensorrt; print(tensorrt.__version__)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Check GPU compute capability</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">nvidia-smi</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="issue-models-not-loading-in-isaac-sim">Issue: &quot;Models not loading in Isaac Sim&quot;<a href="#issue-models-not-loading-in-isaac-sim" class="hash-link" aria-label="Direct link to Issue: &quot;Models not loading in Isaac Sim&quot;" title="Direct link to Issue: &quot;Models not loading in Isaac Sim&quot;" translate="no">​</a></h4>
<p><strong>Solution</strong>: Verify file paths and permissions</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Check model file existence</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ls -la /workspace/shared_dir/models/yolo/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ls -la /workspace/shared_dir/models/segmentation/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ls -la /workspace/shared_dir/models/depth/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Check permissions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chmod -R 755 /workspace/shared_dir/models/</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="verification-checklist">Verification Checklist<a href="#verification-checklist" class="hash-link" aria-label="Direct link to Verification Checklist" title="Direct link to Verification Checklist" translate="no">​</a></h2>
<ul class="contains-task-list containsTaskList_mC6p">
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Model conversion scripts created and tested</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->ONNX models generated successfully</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->TensorRT optimization implemented</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Isaac ROS model deployment package created</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Model configuration files created</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Performance monitoring tools implemented</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Test scripts created and functional</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Troubleshooting guide reviewed</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps" translate="no">​</a></h2>
<p>After deploying AI models:</p>
<ol>
<li class=""><strong>Test model performance</strong> in Isaac Sim environment</li>
<li class=""><strong>Optimize models</strong> based on performance metrics</li>
<li class=""><strong>Integrate with perception pipeline</strong> from previous exercises</li>
<li class=""><strong>Create model deployment exercises</strong> for students</li>
</ol>
<p>The AI model deployment framework is now configured and ready for Module 3, providing students with tools to deploy and optimize AI models in the Isaac Sim environment.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter-3/model-deployment.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ur/docs/chapter-3/sensor-integration"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Multimodal Sensor Integration in Isaac Sim</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ur/docs/chapter-3/exercises"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Module 3 Exercise Framework: The AI-Robot Brain (NVIDIA Isaac™)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a></li><li><a href="#introduction-to-ai-model-deployment-in-isaac" class="table-of-contents__link toc-highlight">Introduction to AI Model Deployment in Isaac</a><ul><li><a href="#what-is-ai-model-deployment-in-isaac" class="table-of-contents__link toc-highlight">What is AI Model Deployment in Isaac?</a></li><li><a href="#key-components" class="table-of-contents__link toc-highlight">Key Components</a></li></ul></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#model-preparation-and-optimization" class="table-of-contents__link toc-highlight">Model Preparation and Optimization</a><ul><li><a href="#1-installing-model-deployment-dependencies" class="table-of-contents__link toc-highlight">1. Installing Model Deployment Dependencies</a></li><li><a href="#2-creating-model-repository-structure" class="table-of-contents__link toc-highlight">2. Creating Model Repository Structure</a></li><li><a href="#3-downloading-pre-trained-models" class="table-of-contents__link toc-highlight">3. Downloading Pre-trained Models</a></li></ul></li><li><a href="#model-conversion-for-isaac-sim" class="table-of-contents__link toc-highlight">Model Conversion for Isaac Sim</a><ul><li><a href="#1-converting-yolov5-to-onnx-format" class="table-of-contents__link toc-highlight">1. Converting YOLOv5 to ONNX Format</a></li><li><a href="#2-converting-segmentation-model-to-onnx" class="table-of-contents__link toc-highlight">2. Converting Segmentation Model to ONNX</a></li><li><a href="#3-converting-depth-estimation-model-to-onnx" class="table-of-contents__link toc-highlight">3. Converting Depth Estimation Model to ONNX</a></li></ul></li><li><a href="#tensorrt-optimization" class="table-of-contents__link toc-highlight">TensorRT Optimization</a><ul><li><a href="#1-creating-tensorrt-optimization-script" class="table-of-contents__link toc-highlight">1. Creating TensorRT Optimization Script</a></li></ul></li><li><a href="#isaac-ros-model-integration" class="table-of-contents__link toc-highlight">Isaac ROS Model Integration</a><ul><li><a href="#1-creating-isaac-ros-model-configuration" class="table-of-contents__link toc-highlight">1. Creating Isaac ROS Model Configuration</a></li><li><a href="#2-creating-isaac-ros-model-deployment-package" class="table-of-contents__link toc-highlight">2. Creating Isaac ROS Model Deployment Package</a></li><li><a href="#3-creating-model-deployment-node" class="table-of-contents__link toc-highlight">3. Creating Model Deployment Node</a></li><li><a href="#4-creating-service-definition-for-model-deployment" class="table-of-contents__link toc-highlight">4. Creating Service Definition for Model Deployment</a></li><li><a href="#5-creating-setup-files-for-model-deployment-package" class="table-of-contents__link toc-highlight">5. Creating Setup Files for Model Deployment Package</a></li></ul></li><li><a href="#model-deployment-testing" class="table-of-contents__link toc-highlight">Model Deployment Testing</a><ul><li><a href="#1-creating-model-deployment-test-script" class="table-of-contents__link toc-highlight">1. Creating Model Deployment Test Script</a></li><li><a href="#2-running-model-deployment-test" class="table-of-contents__link toc-highlight">2. Running Model Deployment Test</a></li></ul></li><li><a href="#model-performance-monitoring" class="table-of-contents__link toc-highlight">Model Performance Monitoring</a><ul><li><a href="#1-creating-performance-monitoring-script" class="table-of-contents__link toc-highlight">1. Creating Performance Monitoring Script</a></li></ul></li><li><a href="#troubleshooting-model-deployment" class="table-of-contents__link toc-highlight">Troubleshooting Model Deployment</a><ul><li><a href="#common-issues-and-solutions" class="table-of-contents__link toc-highlight">Common Issues and Solutions</a></li></ul></li><li><a href="#verification-checklist" class="table-of-contents__link toc-highlight">Verification Checklist</a></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Chapters</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ur/docs/intro">Introduction</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/physical-ai-book/hackathon-book/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussions<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/ur/docs/contributing">Contributing</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ur/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/physical-ai-book/hackathon-book" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 AI-Native Textbook for Physical AI & Humanoid Robotics. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>