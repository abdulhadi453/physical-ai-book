"use strict";(globalThis.webpackChunkai_native_textbook_physical_ai_humanoid_robotics=globalThis.webpackChunkai_native_textbook_physical_ai_humanoid_robotics||[]).push([[7780],{1781:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"chapter-4/integration-guide","title":"Integration Guide: Vision-Language-Action (VLA) Systems","description":"Overview","source":"@site/docs/chapter-4/integration-guide.md","sourceDirName":"chapter-4","slug":"/chapter-4/integration-guide","permalink":"/ur/docs/chapter-4/integration-guide","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter-4/integration-guide.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"VLA System Setup Guide","permalink":"/ur/docs/chapter-4/setup"},"next":{"title":"VLA Practical Exercises","permalink":"/ur/docs/chapter-4/exercises"}}');var s=r(4848),i=r(8453);const o={},a="Integration Guide: Vision-Language-Action (VLA) Systems",l={},c=[{value:"Overview",id:"overview",level:2},{value:"System Architecture Overview",id:"system-architecture-overview",level:2},{value:"High-Level Architecture",id:"high-level-architecture",level:3},{value:"Component Responsibilities",id:"component-responsibilities",level:3},{value:"Integration Prerequisites",id:"integration-prerequisites",level:2},{value:"1. Environment Setup",id:"1-environment-setup",level:3},{value:"2. Configuration Files",id:"2-configuration-files",level:3},{value:"3. Environment Variables",id:"3-environment-variables",level:3},{value:"Component Integration Steps",id:"component-integration-steps",level:2},{value:"Step 1: Initialize Core Components",id:"step-1-initialize-core-components",level:3},{value:"Step 2: Create Integration Orchestration",id:"step-2-create-integration-orchestration",level:3},{value:"Step 3: Implement Data Flow Management",id:"step-3-implement-data-flow-management",level:3},{value:"Step 4: Create Integration Testing Framework",id:"step-4-create-integration-testing-framework",level:3},{value:"Configuration and Deployment",id:"configuration-and-deployment",level:2},{value:"1. Docker Integration",id:"1-docker-integration",level:3},{value:"2. ROS 2 Launch Integration",id:"2-ros-2-launch-integration",level:3},{value:"Troubleshooting Guide",id:"troubleshooting-guide",level:2},{value:"Common Integration Issues",id:"common-integration-issues",level:3},{value:"Issue 1: Component Communication Failures",id:"issue-1-component-communication-failures",level:4},{value:"Issue 2: Performance Bottlenecks",id:"issue-2-performance-bottlenecks",level:4},{value:"Issue 3: Memory Leaks",id:"issue-3-memory-leaks",level:4},{value:"Debugging Tools",id:"debugging-tools",level:3},{value:"1. System Monitor",id:"1-system-monitor",level:4},{value:"2. Component Health Checker",id:"2-component-health-checker",level:4},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"1. Component-Specific Optimizations",id:"1-component-specific-optimizations",level:3},{value:"Whisper Optimization",id:"whisper-optimization",level:4},{value:"Vision System Optimization",id:"vision-system-optimization",level:4},{value:"Deployment Considerations",id:"deployment-considerations",level:2},{value:"1. Production Deployment Checklist",id:"1-production-deployment-checklist",level:3},{value:"2. Container Orchestration",id:"2-container-orchestration",level:3}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"integration-guide-vision-language-action-vla-systems",children:"Integration Guide: Vision-Language-Action (VLA) Systems"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This integration guide provides detailed instructions for integrating the Vision-Language-Action (VLA) system components into a cohesive, functional pipeline. The guide covers component interfaces, data flow patterns, configuration requirements, and troubleshooting procedures necessary to successfully deploy the complete VLA system."}),"\n",(0,s.jsx)(n.h2,{id:"system-architecture-overview",children:"System Architecture Overview"}),"\n",(0,s.jsx)(n.h3,{id:"high-level-architecture",children:"High-Level Architecture"}),"\n",(0,s.jsx)(n.p,{children:"The VLA system consists of five main integrated components:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502   Voice Input   \u2502\u2500\u2500\u2500\u25b6\u2502 Cognitive       \u2502\u2500\u2500\u2500\u25b6\u2502 Visual          \u2502\r\n\u2502   Processing    \u2502    \u2502 Planning        \u2502    \u2502 Perception      \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n         \u2502                       \u2502                       \u2502\r\n         \u25bc                       \u25bc                       \u25bc\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502 Action Executor \u2502\u25c0\u2500\u2500\u2500\u2502 State Manager   \u2502\u2500\u2500\u2500\u25c0\u2502 Feedback        \u2502\r\n\u2502 (ROS 2)         \u2502    \u2502 & Monitoring    \u2502    \u2502 Processor       \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h3,{id:"component-responsibilities",children:"Component Responsibilities"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Voice Input Processing"}),": Converts speech to text and validates commands"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cognitive Planning"}),": Interprets commands and generates action sequences"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Visual Perception"}),": Detects objects and provides spatial context"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Action Executor"}),": Executes actions through ROS 2 interfaces"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"State Manager"}),": Tracks execution state and coordinates components"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Feedback Processor"}),": Provides status updates to users"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"integration-prerequisites",children:"Integration Prerequisites"}),"\n",(0,s.jsx)(n.h3,{id:"1-environment-setup",children:"1. Environment Setup"}),"\n",(0,s.jsx)(n.p,{children:"Before integrating components, ensure all prerequisites are met:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Verify ROS 2 installation\r\nsource /opt/ros/humble/setup.bash\r\nros2 topic list\r\n\r\n# Verify Python environment\r\npython3 -c "import torch, openai, whisper, cv2, rclpy"\r\n\r\n# Verify Isaac Sim connection (if using simulation)\r\n# Check Isaac Sim server is running on port 50051\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-configuration-files",children:"2. Configuration Files"}),"\n",(0,s.jsx)(n.p,{children:"Create configuration files for system integration:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# config/vla_system.yaml\r\nvla_system:\r\n  whisper:\r\n    model_size: "base"\r\n    sample_rate: 16000\r\n    confidence_threshold: 0.5\r\n\r\n  llm:\r\n    model: "gpt-4-turbo"\r\n    max_tokens: 500\r\n    temperature: 0.1\r\n\r\n  vision:\r\n    detection_threshold: 0.5\r\n    frame_rate: 10\r\n    camera_matrix: [640, 0, 320, 0, 640, 240, 0, 0, 1]  # 3x3 matrix as list\r\n\r\n  ros2:\r\n    domain_id: 42\r\n    action_timeout: 30\r\n    navigation_timeout: 60\r\n\r\n  integration:\r\n    max_execution_time: 300  # 5 minutes\r\n    command_queue_size: 10\r\n    feedback_interval: 2.0  # seconds\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-environment-variables",children:"3. Environment Variables"}),"\n",(0,s.jsx)(n.p,{children:"Set required environment variables:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# In .env file or environment\r\nexport OPENAI_API_KEY="your-api-key"\r\nexport ROS_DOMAIN_ID=42\r\nexport VLA_CONFIG_PATH="/path/to/config/vla_system.yaml"\r\nexport ISAAC_SIM_SERVER_PORT=50051\n'})}),"\n",(0,s.jsx)(n.h2,{id:"component-integration-steps",children:"Component Integration Steps"}),"\n",(0,s.jsx)(n.h3,{id:"step-1-initialize-core-components",children:"Step 1: Initialize Core Components"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# integration/vla_initializer.py\r\nimport yaml\r\nimport os\r\nfrom typing import Dict, Any\r\n\r\nclass VLAInitializer:\r\n    \"\"\"\r\n    Initializes and configures all VLA system components.\r\n    \"\"\"\r\n    def __init__(self, config_path: str = None):\r\n        self.config = self._load_config(config_path)\r\n        self.components = {}\r\n\r\n    def _load_config(self, config_path: str) -> Dict[str, Any]:\r\n        \"\"\"Load configuration from YAML file.\"\"\"\r\n        if config_path is None:\r\n            config_path = os.getenv('VLA_CONFIG_PATH', 'config/vla_system.yaml')\r\n\r\n        with open(config_path, 'r') as f:\r\n            return yaml.safe_load(f)\r\n\r\n    def initialize_all_components(self):\r\n        \"\"\"Initialize all VLA system components.\"\"\"\r\n        # Initialize speech processing\r\n        self.components['whisper_processor'] = self._initialize_whisper()\r\n        self.components['voice_handler'] = self._initialize_voice_handler()\r\n\r\n        # Initialize cognitive planning\r\n        self.components['llm_client'] = self._initialize_llm()\r\n        self.components['cognitive_planner'] = self._initialize_planner()\r\n\r\n        # Initialize visual perception\r\n        self.components['object_detector'] = self._initialize_detector()\r\n        self.components['perception_pipeline'] = self._initialize_pipeline()\r\n        self.components['vision_processor'] = self._initialize_vision_processor()\r\n\r\n        # Initialize action execution\r\n        self.components['action_executor'] = self._initialize_action_executor()\r\n\r\n        # Initialize integration components\r\n        self.components['state_manager'] = self._initialize_state_manager()\r\n        self.components['feedback_processor'] = self._initialize_feedback_processor()\r\n\r\n        return self.components\r\n\r\n    def _initialize_whisper(self):\r\n        from src.vla.speech.whisper_processor import WhisperProcessor\r\n        model_size = self.config['vla_system']['whisper']['model_size']\r\n        return WhisperProcessor(model_size=model_size)\r\n\r\n    def _initialize_voice_handler(self):\r\n        from src.vla.speech.voice_input_handler import VoiceInputHandler\r\n        sample_rate = self.config['vla_system']['whisper']['sample_rate']\r\n        return VoiceInputHandler(sample_rate=sample_rate)\r\n\r\n    def _initialize_llm(self):\r\n        from src.vla.llm.llm_client import LLMClient\r\n        api_key = os.getenv('OPENAI_API_KEY')\r\n        model = self.config['vla_system']['llm']['model']\r\n        return LLMClient(api_key=api_key, model=model)\r\n\r\n    def _initialize_planner(self):\r\n        from src.vla.llm.cognitive_planner import CognitivePlanner\r\n        llm_client = self.components['llm_client']\r\n        return CognitivePlanner(llm_client)\r\n\r\n    def _initialize_detector(self):\r\n        from src.vla.vision.object_detector import ObjectDetector\r\n        threshold = self.config['vla_system']['vision']['detection_threshold']\r\n        return ObjectDetector(confidence_threshold=threshold)\r\n\r\n    def _initialize_pipeline(self):\r\n        from src.vla.vision.perception_pipeline import PerceptionPipeline\r\n        detector = self.components['object_detector']\r\n        # Use camera matrix from config\r\n        camera_matrix = self.config['vla_system']['vision']['camera_matrix']\r\n        return PerceptionPipeline(detector)\r\n\r\n    def _initialize_vision_processor(self):\r\n        from src.vla.vision.vision_processor import VisionProcessor\r\n        pipeline = self.components['perception_pipeline']\r\n        return VisionProcessor(pipeline)\r\n\r\n    def _initialize_action_executor(self):\r\n        # Need to initialize ROS 2 node separately\r\n        import rclpy\r\n        from src.vla.ros2.action_executor import ActionExecutor\r\n\r\n        rclpy.init()\r\n        return ActionExecutor()\r\n\r\n    def _initialize_state_manager(self):\r\n        from src.vla.integration.state_manager import StateManager\r\n        return StateManager()\r\n\r\n    def _initialize_feedback_processor(self):\r\n        from src.vla.integration.feedback_processor import FeedbackProcessor\r\n        return FeedbackProcessor()\n"})}),"\n",(0,s.jsx)(n.h3,{id:"step-2-create-integration-orchestration",children:"Step 2: Create Integration Orchestration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# integration/vla_orchestrator.py\r\nimport threading\r\nimport queue\r\nimport time\r\nfrom typing import Dict, Any, Callable, Optional\r\nfrom src.vla.integration.vla_system import VLASystem\r\nfrom src.vla.integration.feedback_processor import FeedbackProcessor\r\n\r\nclass VLAOrchestrator:\r\n    """\r\n    Orchestrates the complete VLA system integration.\r\n    """\r\n    def __init__(self, components: Dict[str, Any]):\r\n        self.components = components\r\n        self.vla_system = None\r\n        self.feedback_processor = components[\'feedback_processor\']\r\n\r\n        # System state\r\n        self.is_running = False\r\n        self.main_thread = None\r\n\r\n        # Initialize the complete VLA system\r\n        self._initialize_vla_system()\r\n\r\n    def _initialize_vla_system(self):\r\n        """Initialize the complete VLA system with all components."""\r\n        self.vla_system = VLASystem(\r\n            whisper_processor=self.components[\'whisper_processor\'],\r\n            llm_client=self.components[\'llm_client\'],\r\n            object_detector=self.components[\'object_detector\'],\r\n            action_executor=self.components[\'action_executor\']\r\n        )\r\n\r\n        # Register feedback processor\r\n        self.vla_system.feedback_processor = self.feedback_processor\r\n\r\n    def start_system(self):\r\n        """Start the integrated VLA system."""\r\n        if self.is_running:\r\n            return\r\n\r\n        self.is_running = True\r\n\r\n        # Start feedback processor\r\n        self.feedback_processor.start()\r\n\r\n        # Start VLA system\r\n        self.vla_system.start_system()\r\n\r\n        # Add feedback callback\r\n        def system_feedback(message, message_type):\r\n            print(f"[VLA SYSTEM] {message_type.upper()}: {message}")\r\n\r\n        self.feedback_processor.add_callback(system_feedback)\r\n\r\n        print("VLA System integration started successfully")\r\n\r\n    def stop_system(self):\r\n        """Stop the integrated VLA system."""\r\n        if not self.is_running:\r\n            return\r\n\r\n        self.is_running = False\r\n\r\n        # Stop VLA system\r\n        self.vla_system.stop_system()\r\n\r\n        # Stop feedback processor\r\n        self.feedback_processor.stop()\r\n\r\n        print("VLA System integration stopped")\r\n\r\n    def process_command(self, command_text: str, command_type: str = "direct"):\r\n        """\r\n        Process a command through the integrated system.\r\n\r\n        Args:\r\n            command_text: The command to process\r\n            command_type: Type of command ("direct", "voice", etc.)\r\n        """\r\n        if command_type == "direct":\r\n            execution_id = self.vla_system.process_command_direct(command_text)\r\n        else:\r\n            # For voice commands, you\'d use the voice processing pipeline\r\n            execution_id = self.vla_system.process_command_direct(command_text)\r\n\r\n        return execution_id\r\n\r\n    def get_system_status(self) -> Dict[str, Any]:\r\n        """Get comprehensive system status."""\r\n        status = {\r\n            \'is_running\': self.is_running,\r\n            \'timestamp\': time.time(),\r\n            \'components\': {\r\n                \'whisper\': \'initialized\',\r\n                \'llm\': \'initialized\',\r\n                \'vision\': \'initialized\',\r\n                \'action_executor\': \'initialized\',\r\n                \'state_manager\': \'initialized\',\r\n                \'feedback_processor\': \'running\' if self.feedback_processor.is_active else \'stopped\'\r\n            }\r\n        }\r\n\r\n        # Add VLA system status\r\n        if self.vla_system:\r\n            status.update(self.vla_system.get_system_status())\r\n\r\n        return status\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-3-implement-data-flow-management",children:"Step 3: Implement Data Flow Management"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# integration/data_flow_manager.py\r\nimport asyncio\r\nimport threading\r\nfrom typing import Dict, Any, Callable, List\r\nfrom queue import Queue, Empty\r\nimport time\r\n\r\nclass DataFlowManager:\r\n    """\r\n    Manages data flow between VLA system components.\r\n    """\r\n    def __init__(self):\r\n        self.data_queues = {\r\n            \'voice_to_planning\': Queue(maxsize=10),\r\n            \'planning_to_vision\': Queue(maxsize=10),\r\n            \'vision_to_execution\': Queue(maxsize=10),\r\n            \'execution_to_feedback\': Queue(maxsize=10),\r\n            \'system_status\': Queue(maxsize=5)\r\n        }\r\n\r\n        self.processing_threads = {}\r\n        self.is_active = False\r\n\r\n    def start_processing(self):\r\n        """Start data flow processing threads."""\r\n        self.is_active = True\r\n\r\n        # Start processing thread for each queue\r\n        for queue_name, queue_obj in self.data_queues.items():\r\n            thread = threading.Thread(\r\n                target=self._process_queue,\r\n                args=(queue_name, queue_obj),\r\n                daemon=True\r\n            )\r\n            thread.start()\r\n            self.processing_threads[queue_name] = thread\r\n\r\n    def stop_processing(self):\r\n        """Stop data flow processing."""\r\n        self.is_active = False\r\n\r\n        # Wait for threads to finish\r\n        for thread in self.processing_threads.values():\r\n            thread.join(timeout=2.0)\r\n\r\n    def _process_queue(self, queue_name: str, queue: Queue):\r\n        """Process items from a specific queue."""\r\n        while self.is_active:\r\n            try:\r\n                item = queue.get(timeout=0.1)\r\n\r\n                # Process the item based on queue type\r\n                if queue_name == \'voice_to_planning\':\r\n                    self._process_voice_to_planning(item)\r\n                elif queue_name == \'planning_to_vision\':\r\n                    self._process_planning_to_vision(item)\r\n                elif queue_name == \'vision_to_execution\':\r\n                    self._process_vision_to_execution(item)\r\n                elif queue_name == \'execution_to_feedback\':\r\n                    self._process_execution_to_feedback(item)\r\n                elif queue_name == \'system_status\':\r\n                    self._process_system_status(item)\r\n\r\n                queue.task_done()\r\n\r\n            except Empty:\r\n                continue\r\n            except Exception as e:\r\n                print(f"Error processing {queue_name}: {e}")\r\n\r\n    def _process_voice_to_planning(self, item):\r\n        """Process voice data for planning."""\r\n        # Item format: {\'command_text\': str, \'confidence\': float, \'timestamp\': float}\r\n        print(f"Processing voice command: {item.get(\'command_text\', \'\')}")\r\n\r\n    def _process_planning_to_vision(self, item):\r\n        """Process planning data for vision system."""\r\n        # Item format: {\'intent\': ProcessedIntent, \'timestamp\': float}\r\n        print(f"Processing planning data for vision: {len(item.get(\'intent\', {}).get(\'action_sequence\', []))} actions")\r\n\r\n    def _process_vision_to_execution(self, item):\r\n        """Process vision data for execution."""\r\n        # Item format: {\'perception_data\': PerceptionData, \'action_sequence\': list}\r\n        print(f"Processing vision data for execution: {len(item.get(\'action_sequence\', []))} actions")\r\n\r\n    def _process_execution_to_feedback(self, item):\r\n        """Process execution results for feedback."""\r\n        # Item format: {\'execution_state\': ExecutionState, \'result\': dict}\r\n        print(f"Processing execution result: {item.get(\'execution_state\', {}).get(\'status\', \'unknown\')}")\r\n\r\n    def _process_system_status(self, item):\r\n        """Process system status updates."""\r\n        # Item format: {\'status\': dict, \'timestamp\': float}\r\n        print(f"System status update: {item.get(\'status\', {})}")\r\n\r\n    def submit_data(self, queue_name: str, data: Any):\r\n        """Submit data to a specific queue."""\r\n        if queue_name in self.data_queues:\r\n            try:\r\n                self.data_queues[queue_name].put_nowait(data)\r\n                return True\r\n            except:\r\n                print(f"Queue {queue_name} is full")\r\n                return False\r\n        else:\r\n            print(f"Unknown queue: {queue_name}")\r\n            return False\n'})}),"\n",(0,s.jsx)(n.h3,{id:"step-4-create-integration-testing-framework",children:"Step 4: Create Integration Testing Framework"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# integration/integration_tester.py\r\nimport time\r\nimport threading\r\nfrom typing import Dict, List, Any\r\nfrom src.vla.models.action_step import ActionStep, ActionStepType\r\nfrom src.vla.models.execution_state import ExecutionStatus\r\n\r\nclass IntegrationTester:\r\n    \"\"\"\r\n    Comprehensive testing framework for VLA system integration.\r\n    \"\"\"\r\n    def __init__(self, orchestrator):\r\n        self.orchestrator = orchestrator\r\n        self.test_results = []\r\n        self.test_history = []\r\n\r\n    def run_comprehensive_test(self) -> Dict[str, Any]:\r\n        \"\"\"Run comprehensive integration test.\"\"\"\r\n        results = {\r\n            'start_time': time.time(),\r\n            'tests_run': 0,\r\n            'tests_passed': 0,\r\n            'tests_failed': 0,\r\n            'details': [],\r\n            'performance_metrics': {}\r\n        }\r\n\r\n        # Test sequence\r\n        test_functions = [\r\n            self._test_component_initialization,\r\n            self._test_simple_command,\r\n            self._test_multi_step_command,\r\n            self._test_error_handling,\r\n            self._test_performance,\r\n        ]\r\n\r\n        for test_func in test_functions:\r\n            test_name = test_func.__name__\r\n            print(f\"Running {test_name}...\")\r\n\r\n            try:\r\n                test_result = test_func()\r\n                results['tests_run'] += 1\r\n\r\n                if test_result['passed']:\r\n                    results['tests_passed'] += 1\r\n                    print(f\"\u2713 {test_name} PASSED\")\r\n                else:\r\n                    results['tests_failed'] += 1\r\n                    print(f\"\u2717 {test_name} FAILED: {test_result.get('error', 'Unknown error')}\")\r\n\r\n                results['details'].append({\r\n                    'test': test_name,\r\n                    'passed': test_result['passed'],\r\n                    'error': test_result.get('error'),\r\n                    'metrics': test_result.get('metrics', {})\r\n                })\r\n\r\n            except Exception as e:\r\n                results['tests_failed'] += 1\r\n                results['details'].append({\r\n                    'test': test_name,\r\n                    'passed': False,\r\n                    'error': str(e),\r\n                    'metrics': {}\r\n                })\r\n                print(f\"\u2717 {test_name} ERROR: {e}\")\r\n\r\n        results['end_time'] = time.time()\r\n        results['total_time'] = results['end_time'] - results['start_time']\r\n\r\n        return results\r\n\r\n    def _test_component_initialization(self) -> Dict[str, Any]:\r\n        \"\"\"Test that all components are properly initialized.\"\"\"\r\n        try:\r\n            status = self.orchestrator.get_system_status()\r\n\r\n            required_components = [\r\n                'whisper', 'llm', 'vision', 'action_executor',\r\n                'state_manager', 'feedback_processor'\r\n            ]\r\n\r\n            all_initialized = True\r\n            for comp in required_components:\r\n                if status['components'].get(comp) != 'initialized':\r\n                    all_initialized = False\r\n                    break\r\n\r\n            return {\r\n                'passed': all_initialized,\r\n                'metrics': {'components_checked': len(required_components)}\r\n            }\r\n\r\n        except Exception as e:\r\n            return {'passed': False, 'error': str(e)}\r\n\r\n    def _test_simple_command(self) -> Dict[str, Any]:\r\n        \"\"\"Test processing of a simple command.\"\"\"\r\n        try:\r\n            start_time = time.time()\r\n\r\n            # Process a simple command\r\n            execution_id = self.orchestrator.process_command(\"Move forward 1 meter\")\r\n\r\n            # Wait briefly to allow processing\r\n            time.sleep(2)\r\n\r\n            # Check execution status\r\n            status = self.orchestrator.get_system_status()\r\n\r\n            processing_time = time.time() - start_time\r\n\r\n            return {\r\n                'passed': execution_id is not None,\r\n                'metrics': {\r\n                    'execution_id': execution_id,\r\n                    'processing_time': processing_time\r\n                }\r\n            }\r\n\r\n        except Exception as e:\r\n            return {'passed': False, 'error': str(e)}\r\n\r\n    def _test_multi_step_command(self) -> Dict[str, Any]:\r\n        \"\"\"Test processing of a multi-step command.\"\"\"\r\n        try:\r\n            start_time = time.time()\r\n\r\n            # Process a multi-step command\r\n            execution_id = self.orchestrator.process_command(\r\n                \"Go to the table, find a red object, and pick it up\"\r\n            )\r\n\r\n            # Wait for completion or timeout\r\n            max_wait = 10  # seconds\r\n            waited = 0\r\n            while waited < max_wait:\r\n                time.sleep(1)\r\n                waited += 1\r\n\r\n                # In a real test, you'd check actual execution status\r\n                # For simulation, we'll assume it works after waiting\r\n                break\r\n\r\n            processing_time = time.time() - start_time\r\n\r\n            return {\r\n                'passed': execution_id is not None,\r\n                'metrics': {\r\n                    'execution_id': execution_id,\r\n                    'processing_time': processing_time,\r\n                    'waited_time': waited\r\n                }\r\n            }\r\n\r\n        except Exception as e:\r\n            return {'passed': False, 'error': str(e)}\r\n\r\n    def _test_error_handling(self) -> Dict[str, Any]:\r\n        \"\"\"Test system response to invalid commands.\"\"\"\r\n        try:\r\n            # Process an invalid command\r\n            execution_id = self.orchestrator.process_command(\"invalid command with no meaning\")\r\n\r\n            # Check that system handles it gracefully\r\n            status = self.orchestrator.get_system_status()\r\n\r\n            return {\r\n                'passed': True,  # Should not crash\r\n                'metrics': {'execution_id': execution_id}\r\n            }\r\n\r\n        except Exception as e:\r\n            return {'passed': False, 'error': str(e)}\r\n\r\n    def _test_performance(self) -> Dict[str, Any]:\r\n        \"\"\"Test system performance under load.\"\"\"\r\n        try:\r\n            start_time = time.time()\r\n\r\n            # Process multiple commands in sequence\r\n            commands = [\r\n                \"Move forward\",\r\n                \"Turn left\",\r\n                \"Move backward\",\r\n                \"Turn right\"\r\n            ]\r\n\r\n            execution_times = []\r\n            for cmd in commands:\r\n                cmd_start = time.time()\r\n                self.orchestrator.process_command(cmd)\r\n                execution_times.append(time.time() - cmd_start)\r\n                time.sleep(0.5)  # Brief pause between commands\r\n\r\n            total_time = time.time() - start_time\r\n            avg_time = sum(execution_times) / len(execution_times) if execution_times else 0\r\n\r\n            return {\r\n                'passed': avg_time < 5.0,  # Should process quickly\r\n                'metrics': {\r\n                    'total_commands': len(commands),\r\n                    'total_time': total_time,\r\n                    'avg_time_per_command': avg_time,\r\n                    'execution_times': execution_times\r\n                }\r\n            }\r\n\r\n        except Exception as e:\r\n            return {'passed': False, 'error': str(e)}\r\n\r\n    def generate_test_report(self, results: Dict[str, Any]) -> str:\r\n        \"\"\"Generate a comprehensive test report.\"\"\"\r\n        report = []\r\n        report.append(\"VLA System Integration Test Report\")\r\n        report.append(\"=\" * 50)\r\n        report.append(f\"Start Time: {results['start_time']}\")\r\n        report.append(f\"End Time: {results['end_time']}\")\r\n        report.append(f\"Total Duration: {results['total_time']:.2f}s\")\r\n        report.append(\"\")\r\n        report.append(f\"Tests Run: {results['tests_run']}\")\r\n        report.append(f\"Tests Passed: {results['tests_passed']}\")\r\n        report.append(f\"Tests Failed: {results['tests_failed']}\")\r\n        report.append(f\"Success Rate: {(results['tests_passed']/results['tests_run']*100):.1f}%\" if results['tests_run'] > 0 else \"0%\")\r\n        report.append(\"\")\r\n\r\n        report.append(\"Test Details:\")\r\n        report.append(\"-\" * 20)\r\n        for detail in results['details']:\r\n            status = \"PASS\" if detail['passed'] else \"FAIL\"\r\n            report.append(f\"  {detail['test']}: {status}\")\r\n            if detail.get('error'):\r\n                report.append(f\"    Error: {detail['error']}\")\r\n            if detail.get('metrics'):\r\n                for key, value in detail['metrics'].items():\r\n                    report.append(f\"    {key}: {value}\")\r\n            report.append(\"\")\r\n\r\n        return \"\\n\".join(report)\n"})}),"\n",(0,s.jsx)(n.h2,{id:"configuration-and-deployment",children:"Configuration and Deployment"}),"\n",(0,s.jsx)(n.h3,{id:"1-docker-integration",children:"1. Docker Integration"}),"\n",(0,s.jsx)(n.p,{children:"Create a Dockerfile for containerized deployment:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-dockerfile",children:'# Dockerfile for VLA system\r\nFROM nvidia/cuda:11.8-devel-ubuntu22.04\r\n\r\n# Install system dependencies\r\nRUN apt-get update && apt-get install -y \\\r\n    python3-pip \\\r\n    python3-dev \\\r\n    build-essential \\\r\n    libasound-dev \\\r\n    portaudio-dev \\\r\n    libportaudio2 \\\r\n    libportaudiocpp0 \\\r\n    ffmpeg \\\r\n    libavcodec-dev \\\r\n    libavformat-dev \\\r\n    libavdevice-dev \\\r\n    && rm -rf /var/lib/apt/lists/*\r\n\r\n# Set working directory\r\nWORKDIR /app\r\n\r\n# Copy requirements\r\nCOPY requirements.txt .\r\n\r\n# Install Python dependencies\r\nRUN pip3 install pip -U\r\nRUN pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\r\nRUN pip3 install -r requirements.txt\r\n\r\n# Copy source code\r\nCOPY . .\r\n\r\n# Install the package\r\nRUN pip3 install -e .\r\n\r\n# Set environment variables\r\nENV PYTHONPATH=/app\r\nENV ROS_DOMAIN_ID=42\r\n\r\n# Expose necessary ports\r\nEXPOSE 50051  # Isaac Sim\r\nEXPOSE 9090   # ROS bridge\r\n\r\n# Start the VLA system\r\nCMD ["python3", "src/vla/main.py"]\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-ros-2-launch-integration",children:"2. ROS 2 Launch Integration"}),"\n",(0,s.jsx)(n.p,{children:"Create a launch file for coordinated startup:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# launch/vla_system.launch.py\r\nfrom launch import LaunchDescription\r\nfrom launch_ros.actions import Node\r\nfrom launch.actions import DeclareLaunchArgument\r\nfrom launch.substitutions import LaunchConfiguration\r\nimport os\r\n\r\ndef generate_launch_description():\r\n    return LaunchDescription([\r\n        # Declare launch arguments\r\n        DeclareLaunchArgument(\r\n            'config_file',\r\n            default_value=os.path.join(\r\n                os.getenv('VLA_CONFIG_PATH', '/app/config'),\r\n                'vla_system.yaml'\r\n            ),\r\n            description='Path to VLA system configuration file'\r\n        ),\r\n\r\n        # VLA system node\r\n        Node(\r\n            package='vla_system',\r\n            executable='vla_orchestrator',\r\n            name='vla_orchestrator',\r\n            parameters=[LaunchConfiguration('config_file')],\r\n            output='screen'\r\n        ),\r\n\r\n        # Action executor node\r\n        Node(\r\n            package='vla_ros2',\r\n            executable='action_executor',\r\n            name='vla_action_executor',\r\n            parameters=[LaunchConfiguration('config_file')],\r\n            output='screen'\r\n        )\r\n    ])\n"})}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting-guide",children:"Troubleshooting Guide"}),"\n",(0,s.jsx)(n.h3,{id:"common-integration-issues",children:"Common Integration Issues"}),"\n",(0,s.jsx)(n.h4,{id:"issue-1-component-communication-failures",children:"Issue 1: Component Communication Failures"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Symptoms"}),": Components not passing data between each other\r\n",(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Check ROS 2 domain IDs match across all nodes"}),"\n",(0,s.jsx)(n.li,{children:"Verify network connectivity for distributed components"}),"\n",(0,s.jsx)(n.li,{children:"Ensure message types are compatible between components"}),"\n",(0,s.jsx)(n.li,{children:"Check queue sizes aren't causing bottlenecks"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"issue-2-performance-bottlenecks",children:"Issue 2: Performance Bottlenecks"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Symptoms"}),": Slow response times, component timeouts\r\n",(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Profile each component to identify bottlenecks"}),"\n",(0,s.jsx)(n.li,{children:"Optimize model sizes or use faster alternatives"}),"\n",(0,s.jsx)(n.li,{children:"Implement proper threading and async processing"}),"\n",(0,s.jsx)(n.li,{children:"Adjust queue sizes and buffer configurations"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"issue-3-memory-leaks",children:"Issue 3: Memory Leaks"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Symptoms"}),": System memory usage increases over time\r\n",(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Implement proper resource cleanup in all components"}),"\n",(0,s.jsx)(n.li,{children:"Use memory profiling tools to identify leaks"}),"\n",(0,s.jsx)(n.li,{children:"Implement object pooling where appropriate"}),"\n",(0,s.jsx)(n.li,{children:"Set up monitoring for memory usage"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"debugging-tools",children:"Debugging Tools"}),"\n",(0,s.jsx)(n.h4,{id:"1-system-monitor",children:"1. System Monitor"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# integration/system_monitor.py\r\nimport psutil\r\nimport time\r\nfrom typing import Dict, Any\r\n\r\nclass SystemMonitor:\r\n    """\r\n    Monitors system resources and component health.\r\n    """\r\n    def __init__(self):\r\n        self.metrics_history = []\r\n\r\n    def get_system_metrics(self) -> Dict[str, Any]:\r\n        """Get current system metrics."""\r\n        return {\r\n            \'timestamp\': time.time(),\r\n            \'cpu_percent\': psutil.cpu_percent(interval=1),\r\n            \'memory_percent\': psutil.virtual_memory().percent,\r\n            \'disk_percent\': psutil.disk_usage(\'/\').percent,\r\n            \'process_count\': len(psutil.pids()),\r\n            \'network_io\': psutil.net_io_counters()._asdict(),\r\n            \'memory_info\': psutil.virtual_memory()._asdict()\r\n        }\r\n\r\n    def monitor_continuously(self, interval: float = 5.0):\r\n        """Monitor system continuously."""\r\n        while True:\r\n            metrics = self.get_system_metrics()\r\n            self.metrics_history.append(metrics)\r\n\r\n            # Keep only last 1000 metrics\r\n            if len(self.metrics_history) > 1000:\r\n                self.metrics_history = self.metrics_history[-1000:]\r\n\r\n            time.sleep(interval)\n'})}),"\n",(0,s.jsx)(n.h4,{id:"2-component-health-checker",children:"2. Component Health Checker"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# integration/health_checker.py\r\nimport time\r\nfrom typing import Dict, Any, List\r\n\r\nclass ComponentHealthChecker:\r\n    \"\"\"\r\n    Checks health of VLA system components.\r\n    \"\"\"\r\n    def __init__(self, orchestrator):\r\n        self.orchestrator = orchestrator\r\n        self.health_history = []\r\n\r\n    def check_component_health(self) -> Dict[str, Any]:\r\n        \"\"\"Check health of all components.\"\"\"\r\n        status = self.orchestrator.get_system_status()\r\n\r\n        health_report = {\r\n            'timestamp': time.time(),\r\n            'system_running': status.get('is_active', False),\r\n            'components': {},\r\n            'overall_health': 'healthy'\r\n        }\r\n\r\n        # Check each component\r\n        for comp_name, comp_status in status.get('components', {}).items():\r\n            is_healthy = comp_status == 'initialized' or comp_status == 'active'\r\n            health_report['components'][comp_name] = {\r\n                'status': comp_status,\r\n                'healthy': is_healthy\r\n            }\r\n\r\n            if not is_healthy:\r\n                health_report['overall_health'] = 'degraded'\r\n\r\n        # Check for execution issues\r\n        active_executions = status.get('active_executions', 0)\r\n        if active_executions > 5:  # Threshold for too many active executions\r\n            health_report['overall_health'] = 'degraded'\r\n            health_report['active_executions'] = active_executions\r\n\r\n        return health_report\r\n\r\n    def run_health_check(self) -> List[Dict[str, Any]]:\r\n        \"\"\"Run comprehensive health check.\"\"\"\r\n        reports = []\r\n\r\n        # Run multiple checks\r\n        for i in range(3):  # Run 3 checks with small delay\r\n            report = self.check_component_health()\r\n            reports.append(report)\r\n            time.sleep(0.5)\r\n\r\n        return reports\n"})}),"\n",(0,s.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"1-component-specific-optimizations",children:"1. Component-Specific Optimizations"}),"\n",(0,s.jsx)(n.h4,{id:"whisper-optimization",children:"Whisper Optimization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# optimization/whisper_optimizer.py\r\nimport torch\r\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\r\n\r\nclass WhisperOptimizer:\r\n    """\r\n    Optimizes Whisper performance for VLA system.\r\n    """\r\n    def __init__(self, model_size: str = "base"):\r\n        self.model_size = model_size\r\n        self.model = None\r\n        self.processor = None\r\n\r\n    def optimize_model(self):\r\n        """Apply optimizations to Whisper model."""\r\n        # Load model with optimizations\r\n        device = "cuda" if torch.cuda.is_available() else "cpu"\r\n\r\n        self.model = WhisperForConditionalGeneration.from_pretrained(\r\n            f"openai/whisper-{self.model_size}",\r\n            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\r\n            device_map=device\r\n        )\r\n\r\n        self.processor = WhisperProcessor.from_pretrained(f"openai/whisper-{self.model_size}")\r\n\r\n        # Apply optimizations\r\n        if torch.cuda.is_available():\r\n            self.model = self.model.half()  # Use half precision\r\n\r\n        return self.model, self.processor\n'})}),"\n",(0,s.jsx)(n.h4,{id:"vision-system-optimization",children:"Vision System Optimization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# optimization/vision_optimizer.py\r\nimport cv2\r\nimport numpy as np\r\nimport torch\r\n\r\nclass VisionOptimizer:\r\n    """\r\n    Optimizes vision system performance.\r\n    """\r\n    def __init__(self):\r\n        self.optimization_level = "balanced"  # "speed", "accuracy", "balanced"\r\n\r\n    def optimize_detection(self, image):\r\n        """Optimize object detection for performance."""\r\n        # Resize image based on optimization level\r\n        if self.optimization_level == "speed":\r\n            target_size = (320, 320)  # Smaller for speed\r\n        elif self.optimization_level == "accuracy":\r\n            target_size = (640, 640)  # Larger for accuracy\r\n        else:  # balanced\r\n            target_size = (416, 416)\r\n\r\n        resized = cv2.resize(image, target_size)\r\n\r\n        # Apply preprocessing optimizations\r\n        normalized = resized.astype(np.float32) / 255.0\r\n\r\n        return normalized\n'})}),"\n",(0,s.jsx)(n.h2,{id:"deployment-considerations",children:"Deployment Considerations"}),"\n",(0,s.jsx)(n.h3,{id:"1-production-deployment-checklist",children:"1. Production Deployment Checklist"}),"\n",(0,s.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Configuration Management"}),": All configurations externalized and versioned"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Monitoring"}),": System health, performance, and error monitoring in place"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Logging"}),": Comprehensive logging with appropriate levels"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Security"}),": API keys and sensitive data properly secured"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Backup"}),": Configuration and data backup procedures established"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Rollback"}),": Ability to rollback to previous working versions"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Documentation"}),": Complete deployment and operation documentation"]}),"\n",(0,s.jsxs)(n.li,{className:"task-list-item",children:[(0,s.jsx)(n.input,{type:"checkbox",disabled:!0})," ",(0,s.jsx)(n.strong,{children:"Testing"}),": Automated tests for deployment verification"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"2-container-orchestration",children:"2. Container Orchestration"}),"\n",(0,s.jsx)(n.p,{children:"For production deployments, consider using Kubernetes with the following configuration:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# k8s/vla-system-deployment.yaml\r\napiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: vla-system\r\nspec:\r\n  replicas: 1\r\n  selector:\r\n    matchLabels:\r\n      app: vla-system\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: vla-system\r\n    spec:\r\n      containers:\r\n      - name: vla-orchestrator\r\n        image: vla-system:latest\r\n        ports:\r\n        - containerPort: 50051\r\n        env:\r\n        - name: OPENAI_API_KEY\r\n          valueFrom:\r\n            secretKeyRef:\r\n              name: vla-secrets\r\n              key: openai-api-key\r\n        resources:\r\n          requests:\r\n            memory: "4Gi"\r\n            cpu: "2"\r\n          limits:\r\n            memory: "8Gi"\r\n            cpu: "4"\r\n        volumeMounts:\r\n        - name: config-volume\r\n          mountPath: /app/config\r\n      volumes:\r\n      - name: config-volume\r\n        configMap:\r\n          name: vla-config\r\n---\r\napiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  name: vla-service\r\nspec:\r\n  selector:\r\n    app: vla-system\r\n  ports:\r\n    - protocol: TCP\r\n      port: 50051\r\n      targetPort: 50051\r\n  type: ClusterIP\n'})}),"\n",(0,s.jsx)(n.p,{children:"This integration guide provides comprehensive instructions for connecting all VLA system components into a functional, production-ready system. The guide covers technical integration, configuration, testing, optimization, and deployment considerations necessary for successful VLA system implementation."})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(m,{...e})}):m(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var t=r(6540);const s={},i=t.createContext(s);function o(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);