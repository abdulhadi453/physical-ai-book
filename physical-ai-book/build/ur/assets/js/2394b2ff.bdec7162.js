"use strict";(globalThis.webpackChunkai_native_textbook_physical_ai_humanoid_robotics=globalThis.webpackChunkai_native_textbook_physical_ai_humanoid_robotics||[]).push([[3573],{7748:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>i,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"chapter-3/model-deployment","title":"AI Model Deployment in Isaac Sim Environment","description":"Overview","source":"@site/docs/chapter-3/model-deployment.md","sourceDirName":"chapter-3","slug":"/chapter-3/model-deployment","permalink":"/ur/docs/chapter-3/model-deployment","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter-3/model-deployment.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Multimodal Sensor Integration in Isaac Sim","permalink":"/ur/docs/chapter-3/sensor-integration"},"next":{"title":"Module 3 Exercise Framework: The AI-Robot Brain (NVIDIA Isaac\u2122)","permalink":"/ur/docs/chapter-3/exercises"}}');var t=r(4848),s=r(8453);const i={},l="AI Model Deployment in Isaac Sim Environment",a={},d=[{value:"Overview",id:"overview",level:2},{value:"Introduction to AI Model Deployment in Isaac",id:"introduction-to-ai-model-deployment-in-isaac",level:2},{value:"What is AI Model Deployment in Isaac?",id:"what-is-ai-model-deployment-in-isaac",level:3},{value:"Key Components",id:"key-components",level:3},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Model Preparation and Optimization",id:"model-preparation-and-optimization",level:2},{value:"1. Installing Model Deployment Dependencies",id:"1-installing-model-deployment-dependencies",level:3},{value:"2. Creating Model Repository Structure",id:"2-creating-model-repository-structure",level:3},{value:"3. Downloading Pre-trained Models",id:"3-downloading-pre-trained-models",level:3},{value:"Model Conversion for Isaac Sim",id:"model-conversion-for-isaac-sim",level:2},{value:"1. Converting YOLOv5 to ONNX Format",id:"1-converting-yolov5-to-onnx-format",level:3},{value:"2. Converting Segmentation Model to ONNX",id:"2-converting-segmentation-model-to-onnx",level:3},{value:"3. Converting Depth Estimation Model to ONNX",id:"3-converting-depth-estimation-model-to-onnx",level:3},{value:"TensorRT Optimization",id:"tensorrt-optimization",level:2},{value:"1. Creating TensorRT Optimization Script",id:"1-creating-tensorrt-optimization-script",level:3},{value:"Isaac ROS Model Integration",id:"isaac-ros-model-integration",level:2},{value:"1. Creating Isaac ROS Model Configuration",id:"1-creating-isaac-ros-model-configuration",level:3},{value:"2. Creating Isaac ROS Model Deployment Package",id:"2-creating-isaac-ros-model-deployment-package",level:3},{value:"3. Creating Model Deployment Node",id:"3-creating-model-deployment-node",level:3},{value:"4. Creating Service Definition for Model Deployment",id:"4-creating-service-definition-for-model-deployment",level:3},{value:"5. Creating Setup Files for Model Deployment Package",id:"5-creating-setup-files-for-model-deployment-package",level:3},{value:"Model Deployment Testing",id:"model-deployment-testing",level:2},{value:"1. Creating Model Deployment Test Script",id:"1-creating-model-deployment-test-script",level:3},{value:"2. Running Model Deployment Test",id:"2-running-model-deployment-test",level:3},{value:"Model Performance Monitoring",id:"model-performance-monitoring",level:2},{value:"1. Creating Performance Monitoring Script",id:"1-creating-performance-monitoring-script",level:3},{value:"Troubleshooting Model Deployment",id:"troubleshooting-model-deployment",level:2},{value:"Common Issues and Solutions",id:"common-issues-and-solutions",level:3},{value:"Issue: &quot;Model conversion fails with ONNX export error&quot;",id:"issue-model-conversion-fails-with-onnx-export-error",level:4},{value:"Issue: &quot;TensorRT engine build fails&quot;",id:"issue-tensorrt-engine-build-fails",level:4},{value:"Issue: &quot;Models not loading in Isaac Sim&quot;",id:"issue-models-not-loading-in-isaac-sim",level:4},{value:"Verification Checklist",id:"verification-checklist",level:2},{value:"Next Steps",id:"next-steps",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"ai-model-deployment-in-isaac-sim-environment",children:"AI Model Deployment in Isaac Sim Environment"})}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"This document provides comprehensive instructions for deploying AI models within the NVIDIA Isaac Sim environment for Module 3. The focus is on deploying perception models for object detection, semantic segmentation, and depth estimation that can run efficiently in the simulation environment and integrate with the ROS 2 ecosystem."}),"\n",(0,t.jsx)(n.h2,{id:"introduction-to-ai-model-deployment-in-isaac",children:"Introduction to AI Model Deployment in Isaac"}),"\n",(0,t.jsx)(n.h3,{id:"what-is-ai-model-deployment-in-isaac",children:"What is AI Model Deployment in Isaac?"}),"\n",(0,t.jsx)(n.p,{children:"AI model deployment in Isaac involves packaging, optimizing, and integrating deep learning models for use within the Isaac Sim environment and ROS 2 ecosystem. This includes:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Model optimization for real-time inference"}),"\n",(0,t.jsx)(n.li,{children:"Integration with Isaac ROS perception packages"}),"\n",(0,t.jsx)(n.li,{children:"GPU acceleration using TensorRT"}),"\n",(0,t.jsx)(n.li,{children:"Real-time performance considerations"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"key-components",children:"Key Components"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Model Optimization"}),": Converting models to efficient formats"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TensorRT Integration"}),": NVIDIA's inference optimizer"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS 2 Integration"}),": Connecting models to ROS 2 topics"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Performance Monitoring"}),": Ensuring real-time capabilities"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsx)(n.p,{children:"Before deploying AI models, ensure you have:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Completed Isaac Sim and Isaac ROS setup"}),"\n",(0,t.jsx)(n.li,{children:"NVIDIA GPU with TensorRT support"}),"\n",(0,t.jsx)(n.li,{children:"PyTorch and ONNX installed in your environment"}),"\n",(0,t.jsx)(n.li,{children:"Basic understanding of deep learning models"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"model-preparation-and-optimization",children:"Model Preparation and Optimization"}),"\n",(0,t.jsx)(n.h3,{id:"1-installing-model-deployment-dependencies",children:"1. Installing Model Deployment Dependencies"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Install PyTorch and related dependencies\r\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\r\n\r\n# Install ONNX and ONNX Runtime\r\npip3 install onnx onnxruntime onnxruntime-gpu\r\n\r\n# Install TensorRT (if not already installed with Isaac Sim)\r\npip3 install tensorrt\r\n\r\n# Install additional tools\r\npip3 install numpy opencv-python matplotlib\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-creating-model-repository-structure",children:"2. Creating Model Repository Structure"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/isaac_sim_shared/models\r\nmkdir -p ~/isaac_sim_shared/models/yolo\r\nmkdir -p ~/isaac_sim_shared/models/segmentation\r\nmkdir -p ~/isaac_sim_shared/models/depth\r\nmkdir -p ~/isaac_sim_shared/models/trt_cache\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-downloading-pre-trained-models",children:"3. Downloading Pre-trained Models"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Create model download script\r\ncat > ~/download_models.sh << 'EOF'\r\n#!/bin/bash\r\n\r\n# Download pre-trained models for Isaac Sim\r\n\r\n# Create models directory\r\nmkdir -p ~/isaac_sim_shared/models\r\n\r\n# Download YOLOv5 model\r\ncd ~/isaac_sim_shared/models\r\ngit clone https://github.com/ultralytics/yolov5.git\r\ncd yolov5\r\npip3 install -r requirements.txt\r\nwget -O yolov5s.pt https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt\r\n\r\n# Download MiDaS for depth estimation\r\ncd ~/isaac_sim_shared/models\r\ngit clone https://github.com/isl-org/MiDaS.git\r\ncd MiDaS\r\npip3 install -r requirements.txt\r\nmkdir -p model_weights\r\ncd model_weights\r\nwget https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_large_384.pt\r\n\r\n# Download segmentation model (using torchvision's FCN-ResNet101)\r\ncd ~/isaac_sim_shared/models\r\npython3 -c \"\r\nimport torch\r\nmodel = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\r\ntorch.save(model.state_dict(), 'fcn_resnet101.pth')\r\nprint('Segmentation model downloaded')\r\n\"\r\nEOF\r\n\r\n# Make executable and run\r\nchmod +x ~/download_models.sh\r\n~/download_models.sh\n"})}),"\n",(0,t.jsx)(n.h2,{id:"model-conversion-for-isaac-sim",children:"Model Conversion for Isaac Sim"}),"\n",(0,t.jsx)(n.h3,{id:"1-converting-yolov5-to-onnx-format",children:"1. Converting YOLOv5 to ONNX Format"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cat > ~/isaac_sim_shared/scripts/convert_yolo_to_onnx.py << 'EOF'\r\nimport torch\r\nimport numpy as np\r\nimport onnx\r\nfrom yolov5.models.common import DetectMultiBackend\r\nfrom yolov5.utils.general import check_img_size\r\nfrom yolov5.utils.torch_utils import select_device\r\nimport os\r\n\r\ndef convert_yolo_to_onnx():\r\n    \"\"\"Convert YOLOv5 model to ONNX format for Isaac Sim\"\"\"\r\n\r\n    # Model parameters\r\n    weights = '/workspace/shared_dir/models/yolov5/yolov5s.pt'  # Path to PyTorch model\r\n    img_size = [640, 640]  # Input image size\r\n    batch_size = 1  # Batch size for ONNX model\r\n    device = 'cpu'  # Use CPU for conversion, will run on GPU in Isaac Sim\r\n\r\n    print(f\"Loading model from: {weights}\")\r\n\r\n    # Load model\r\n    device = select_device(device)\r\n    model = DetectMultiBackend(weights, device=device, dnn=False, data=None, fp16=False)\r\n    stride, names, pt, jit, onnx, engine = model.stride, model.names, model.pt, model.jit, model.onnx, model.engine\r\n\r\n    # Check image size\r\n    img_size = check_img_size(img_size, s=stride)  # Verify img_size are gs-multiples\r\n\r\n    # Input\r\n    im = torch.zeros(batch_size, 3, *img_size).to(device)  # Create dummy input\r\n\r\n    # Update model\r\n    model.model.float()\r\n    model.warmup(im)  # Warmup\r\n\r\n    # Export\r\n    try:\r\n        # Export to ONNX\r\n        torch.onnx.export(\r\n            model,\r\n            im,\r\n            '/workspace/shared_dir/models/yolo/yolov5s.onnx',\r\n            verbose=False,\r\n            opset_version=12,\r\n            input_names=['images'],\r\n            output_names=['output'],\r\n            dynamic_axes={\r\n                'images': {0: 'batch', 2: 'height', 3: 'width'},  # Variable input dimensions\r\n                'output': {0: 'batch', 1: 'num_detections'}  # Variable output dimensions\r\n            } if False else None  # Set to None for fixed dimensions\r\n        )\r\n\r\n        # Checks\r\n        model_onnx = onnx.load('/workspace/shared_dir/models/yolo/yolov5s.onnx')\r\n        onnx.checker.check_model(model_onnx)  # Check model is well formed\r\n        print(f\"ONNX model saved to: /workspace/shared_dir/models/yolo/yolov5s.onnx\")\r\n\r\n        # Simplify ONNX model (optional)\r\n        try:\r\n            import onnxsim\r\n            model_onnx, check = onnxsim.simplify(model_onnx)\r\n            assert check, \"Simplified ONNX model could not be validated\"\r\n\r\n            onnx.save(model_onnx, '/workspace/shared_dir/models/yolo/yolov5s_simplified.onnx')\r\n            print(\"Simplified ONNX model saved\")\r\n        except ImportError:\r\n            print(\"ONNX simplification skipped (install onnxsim for better performance)\")\r\n\r\n    except Exception as e:\r\n        print(f\"Export failure: {e}\")\r\n\r\nif __name__ == \"__main__\":\r\n    convert_yolo_to_onnx()\r\nEOF\n"})}),"\n",(0,t.jsx)(n.h3,{id:"2-converting-segmentation-model-to-onnx",children:"2. Converting Segmentation Model to ONNX"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cat > ~/isaac_sim_shared/scripts/convert_segmentation_to_onnx.py << 'EOF'\r\nimport torch\r\nimport torchvision.models as models\r\nimport onnx\r\nimport os\r\n\r\ndef convert_segmentation_to_onnx():\r\n    \"\"\"Convert FCN-ResNet101 segmentation model to ONNX format\"\"\"\r\n\r\n    # Load pre-trained segmentation model\r\n    model = models.segmentation.fcn_resnet101(pretrained=True)\r\n    model.eval()  # Set to evaluation mode\r\n\r\n    # Create dummy input (batch_size=1, channels=3, height=480, width=640)\r\n    dummy_input = torch.randn(1, 3, 480, 640, requires_grad=True)\r\n\r\n    # Export to ONNX\r\n    onnx_filename = '/workspace/shared_dir/models/segmentation/fcn_resnet101.onnx'\r\n\r\n    torch.onnx.export(\r\n        model,  # Model being exported\r\n        dummy_input,  # Model input (or a tuple for multiple inputs)\r\n        onnx_filename,  # Where to save the model (can be a file or file-like object)\r\n        export_params=True,  # Store the trained parameter weights\r\n        opset_version=11,  # The ONNX version to export the model to\r\n        do_constant_folding=True,  # Whether to execute constant folding for optimization\r\n        input_names=['input'],  # Model's input names\r\n        output_names=['output'],  # Model's output names\r\n        dynamic_axes={\r\n            'input': {0: 'batch_size', 2: 'height', 3: 'width'},\r\n            'output': {0: 'batch_size', 2: 'height', 3: 'width'}\r\n        }\r\n    )\r\n\r\n    # Verify the model\r\n    onnx_model = onnx.load(onnx_filename)\r\n    onnx.checker.check_model(onnx_model)\r\n\r\n    print(f\"Segmentation ONNX model saved to: {onnx_filename}\")\r\n\r\nif __name__ == \"__main__\":\r\n    convert_segmentation_to_onnx()\r\nEOF\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-converting-depth-estimation-model-to-onnx",children:"3. Converting Depth Estimation Model to ONNX"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cat > ~/isaac_sim_shared/scripts/convert_depth_to_onnx.py << 'EOF'\r\nimport torch\r\nimport torchvision.transforms as transforms\r\nfrom torchvision import models\r\nimport onnx\r\nimport os\r\n\r\ndef convert_depth_to_onnx():\r\n    \"\"\"Convert MiDaS depth estimation model to ONNX format\"\"\"\r\n\r\n    # Note: MiDaS conversion is more complex, using a simplified approach\r\n    # For actual MiDaS, we'll use the original repository's conversion\r\n\r\n    print(\"Creating simplified depth estimation ONNX model...\")\r\n\r\n    # For now, we'll create a placeholder conversion\r\n    # In practice, you would use the MiDaS repository's specific conversion\r\n\r\n    # Load a simple model as placeholder\r\n    model = models.resnet18(pretrained=True)\r\n    # Modify the final layer for depth estimation\r\n    model.fc = torch.nn.Linear(model.fc.in_features, 1)  # Single output for depth\r\n\r\n    model.eval()\r\n\r\n    # Create dummy input\r\n    dummy_input = torch.randn(1, 3, 384, 384)\r\n\r\n    # Export to ONNX\r\n    onnx_filename = '/workspace/shared_dir/models/depth/midas.onnx'\r\n\r\n    torch.onnx.export(\r\n        model,\r\n        dummy_input,\r\n        onnx_filename,\r\n        export_params=True,\r\n        opset_version=11,\r\n        do_constant_folding=True,\r\n        input_names=['input'],\r\n        output_names=['output'],\r\n        dynamic_axes={\r\n            'input': {0: 'batch_size', 2: 'height', 3: 'width'},\r\n            'output': {0: 'batch_size', 2: 'height', 3: 'width'}\r\n        }\r\n    )\r\n\r\n    # Verify the model\r\n    onnx_model = onnx.load(onnx_filename)\r\n    onnx.checker.check_model(onnx_model)\r\n\r\n    print(f\"Depth estimation ONNX model saved to: {onnx_filename}\")\r\n    print(\"Note: For production use, implement proper MiDaS conversion\")\r\n\r\nif __name__ == \"__main__\":\r\n    convert_depth_to_onnx()\r\nEOF\n"})}),"\n",(0,t.jsx)(n.h2,{id:"tensorrt-optimization",children:"TensorRT Optimization"}),"\n",(0,t.jsx)(n.h3,{id:"1-creating-tensorrt-optimization-script",children:"1. Creating TensorRT Optimization Script"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cat > ~/isaac_sim_shared/scripts/optimize_with_tensorrt.py << 'EOF'\r\nimport tensorrt as trt\r\nimport pycuda.driver as cuda\r\nimport pycuda.autoinit\r\nimport numpy as np\r\nimport onnx\r\nimport os\r\nfrom typing import List, Tuple\r\n\r\nclass TensorRTOptimizer:\r\n    def __init__(self):\r\n        self.logger = trt.Logger(trt.Logger.WARNING)\r\n        self.builder = trt.Builder(self.logger)\r\n        self.network = None\r\n        self.config = None\r\n\r\n    def optimize_onnx_model(self, onnx_path: str, trt_path: str, precision: str = \"fp16\") -> bool:\r\n        \"\"\"\r\n        Optimize ONNX model using TensorRT\r\n\r\n        Args:\r\n            onnx_path: Path to ONNX model\r\n            trt_path: Path to save optimized TensorRT model\r\n            precision: Precision mode (\"fp32\", \"fp16\", or \"int8\")\r\n        \"\"\"\r\n\r\n        # Check if ONNX file exists\r\n        if not os.path.exists(onnx_path):\r\n            print(f\"ONNX file does not exist: {onnx_path}\")\r\n            return False\r\n\r\n        # Parse ONNX model\r\n        explicit_batch = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\r\n        self.network = self.builder.create_network(explicit_batch)\r\n        parser = trt.OnnxParser(self.network, self.logger)\r\n\r\n        with open(onnx_path, 'rb') as model:\r\n            if not parser.parse(model.read()):\r\n                print(\"ERROR: Failed to parse the ONNX file.\")\r\n                for error in range(parser.num_errors):\r\n                    print(parser.get_error(error))\r\n                return False\r\n\r\n        # Configure optimization\r\n        self.config = self.builder.create_builder_config()\r\n\r\n        # Set precision\r\n        if precision == \"fp16\":\r\n            if self.builder.platform_has_fast_fp16:\r\n                self.config.set_flag(trt.BuilderFlag.FP16)\r\n                print(\"Using FP16 precision\")\r\n            else:\r\n                print(\"FP16 not supported on this platform, using FP32\")\r\n\r\n        elif precision == \"int8\":\r\n            if self.builder.platform_has_fast_int8:\r\n                self.config.set_flag(trt.BuilderFlag.INT8)\r\n                print(\"Using INT8 precision\")\r\n            else:\r\n                print(\"INT8 not supported on this platform, using FP32\")\r\n\r\n        # Set memory limit\r\n        self.config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GB\r\n\r\n        # Build engine\r\n        try:\r\n            serialized_engine = self.builder.build_serialized_network(self.network, self.config)\r\n\r\n            if serialized_engine is None:\r\n                print(\"Failed to build TensorRT engine\")\r\n                return False\r\n\r\n            # Save the engine\r\n            with open(trt_path, 'wb') as f:\r\n                f.write(serialized_engine)\r\n\r\n            print(f\"TensorRT engine saved to: {trt_path}\")\r\n            return True\r\n\r\n        except Exception as e:\r\n            print(f\"Error building TensorRT engine: {e}\")\r\n            return False\r\n\r\ndef optimize_all_models():\r\n    \"\"\"Optimize all models for Isaac Sim\"\"\"\r\n\r\n    optimizer = TensorRTOptimizer()\r\n\r\n    # Define model paths\r\n    models_to_optimize = [\r\n        {\r\n            'onnx_path': '/workspace/shared_dir/models/yolo/yolov5s.onnx',\r\n            'trt_path': '/workspace/shared_dir/models/yolo/yolov5s.trt',\r\n            'name': 'YOLOv5'\r\n        },\r\n        {\r\n            'onnx_path': '/workspace/shared_dir/models/segmentation/fcn_resnet101.onnx',\r\n            'trt_path': '/workspace/shared_dir/models/segmentation/fcn_resnet101.trt',\r\n            'name': 'Segmentation'\r\n        },\r\n        {\r\n            'onnx_path': '/workspace/shared_dir/models/depth/midas.onnx',\r\n            'trt_path': '/workspace/shared_dir/models/depth/midas.trt',\r\n            'name': 'Depth Estimation'\r\n        }\r\n    ]\r\n\r\n    # Optimize each model\r\n    for model_info in models_to_optimize:\r\n        print(f\"\\nOptimizing {model_info['name']} model...\")\r\n\r\n        success = optimizer.optimize_onnx_model(\r\n            model_info['onnx_path'],\r\n            model_info['trt_path'],\r\n            precision=\"fp16\"  # Use FP16 for better performance on Jetson/RTX\r\n        )\r\n\r\n        if success:\r\n            print(f\"\u2713 {model_info['name']} optimized successfully\")\r\n        else:\r\n            print(f\"\u2717 Failed to optimize {model_info['name']}\")\r\n\r\nif __name__ == \"__main__\":\r\n    optimize_all_models()\r\nEOF\n"})}),"\n",(0,t.jsx)(n.h2,{id:"isaac-ros-model-integration",children:"Isaac ROS Model Integration"}),"\n",(0,t.jsx)(n.h3,{id:"1-creating-isaac-ros-model-configuration",children:"1. Creating Isaac ROS Model Configuration"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'cat > ~/isaac_sim_shared/configs/model_config.yaml << \'EOF\'\r\n# Isaac ROS Model Configuration\r\n\r\n# YOLO Object Detection Configuration\r\nyolo_detection:\r\n  model_path: "/workspace/shared_dir/models/yolo/yolov5s.trt"  # Use TensorRT optimized model\r\n  model_input_width: 640\r\n  model_input_height: 640\r\n  confidence_threshold: 0.5\r\n  max_batch_size: 1\r\n  input_tensor_layout: "NCHW"\r\n  input_binding_name: "images"\r\n  output_binding_names: ["output"]\r\n  input_tensor_names: ["images"]\r\n  output_tensor_names: ["output"]\r\n  enable_tensorrt: true\r\n  tensorrt_precision: "fp16"\r\n  tensorrt_max_workspace_size: 1073741824  # 1GB\r\n  enable_statistics: true\r\n\r\n# Semantic Segmentation Configuration\r\nsemantic_segmentation:\r\n  model_path: "/workspace/shared_dir/models/segmentation/fcn_resnet101.trt"\r\n  model_input_width: 512\r\n  model_input_height: 512\r\n  input_tensor_layout: "NCHW"\r\n  enable_tensorrt: true\r\n  tensorrt_precision: "fp16"\r\n  tensorrt_max_workspace_size: 1073741824  # 1GB\r\n\r\n# Depth Estimation Configuration\r\ndepth_estimation:\r\n  model_path: "/workspace/shared_dir/models/depth/midas.trt"\r\n  model_input_width: 384\r\n  model_input_height: 384\r\n  input_tensor_layout: "NCHW"\r\n  enable_tensorrt: true\r\n  tensorrt_precision: "fp16"\r\n  tensorrt_max_workspace_size: 1073741824  # 1GB\r\n\r\n# Model Loading Configuration\r\nmodel_loading:\r\n  enable_model_caching: true\r\n  cache_directory: "/workspace/shared_dir/models/trt_cache"\r\n  enable_async_loading: true\r\n  loading_threads: 2\r\n  enable_memory_pool: true\r\n  memory_pool_size: 536870912  # 512MB\r\n\r\n# Performance Monitoring\r\nperformance:\r\n  enable_profiling: true\r\n  profile_output_file: "/workspace/shared_dir/logs/model_performance.json"\r\n  enable_framerate_monitoring: true\r\n  target_framerate: 30\r\n  max_latency_ms: 100\r\nEOF\n'})}),"\n",(0,t.jsx)(n.h3,{id:"2-creating-isaac-ros-model-deployment-package",children:"2. Creating Isaac ROS Model Deployment Package"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd ~/isaac_ros_ws/src\r\nsource /opt/ros/humble/setup.bash\r\n\r\n# Create model deployment package\r\nros2 pkg create --build-type ament_python isaac_ros_model_deployment --dependencies rclpy sensor_msgs vision_msgs cv_bridge geometry_msgs std_msgs\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-creating-model-deployment-node",children:"3. Creating Model Deployment Node"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'cat > ~/isaac_ros_ws/src/isaac_ros_model_deployment/isaac_ros_model_deployment/model_deployer.py << \'EOF\'\r\n#!/usr/bin/env python3\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image\r\nfrom vision_msgs.msg import Detection2DArray\r\nfrom std_msgs.msg import String\r\nfrom cv_bridge import CvBridge\r\nimport cv2\r\nimport numpy as np\r\nimport os\r\nimport json\r\nfrom typing import Dict, Any, Optional\r\n\r\nclass ModelDeployer(Node):\r\n    def __init__(self):\r\n        super().__init__(\'model_deployer\')\r\n\r\n        # Initialize CV bridge\r\n        self.bridge = CvBridge()\r\n\r\n        # Subscribe to camera images\r\n        self.image_subscription = self.create_subscription(\r\n            Image,\r\n            \'/camera/color/image_raw\',\r\n            self.image_callback,\r\n            10\r\n        )\r\n\r\n        # Publishers for model status\r\n        self.status_publisher = self.create_publisher(\r\n            String,\r\n            \'/model_deployment_status\',\r\n            10\r\n        )\r\n\r\n        # Configuration\r\n        self.config = self.load_config()\r\n\r\n        # Model deployment status tracking\r\n        self.models_deployed = {}\r\n        self.deployment_status = "initializing"\r\n\r\n        # Initialize model deployment\r\n        self.initialize_models()\r\n\r\n        self.get_logger().info(\'Model Deployer initialized\')\r\n\r\n    def load_config(self) -> Dict[str, Any]:\r\n        """Load model configuration from YAML file"""\r\n        config_path = "/workspace/shared_dir/configs/model_config.yaml"\r\n\r\n        # For this example, we\'ll use a hardcoded config\r\n        # In practice, you would load from the actual YAML file\r\n        config = {\r\n            "yolo_detection": {\r\n                "model_path": "/workspace/shared_dir/models/yolo/yolov5s.trt",\r\n                "model_input_width": 640,\r\n                "model_input_height": 640,\r\n                "confidence_threshold": 0.5\r\n            },\r\n            "semantic_segmentation": {\r\n                "model_path": "/workspace/shared_dir/models/segmentation/fcn_resnet101.trt",\r\n                "model_input_width": 512,\r\n                "model_input_height": 512\r\n            },\r\n            "depth_estimation": {\r\n                "model_path": "/workspace/shared_dir/models/depth/midas.trt",\r\n                "model_input_width": 384,\r\n                "model_input_height": 384\r\n            }\r\n        }\r\n\r\n        return config\r\n\r\n    def initialize_models(self):\r\n        """Initialize and deploy models"""\r\n        self.get_logger().info(\'Initializing models...\')\r\n\r\n        # Check if model files exist and are accessible\r\n        for model_name, model_config in self.config.items():\r\n            model_path = model_config.get(\'model_path\', \'\')\r\n\r\n            if os.path.exists(model_path):\r\n                self.models_deployed[model_name] = True\r\n                self.get_logger().info(f\'Model {model_name} found at {model_path}\')\r\n            else:\r\n                self.models_deployed[model_name] = False\r\n                self.get_logger().warn(f\'Model {model_name} not found at {model_path}\')\r\n\r\n        # Check deployment status\r\n        all_deployed = all(self.models_deployed.values())\r\n        self.deployment_status = "ready" if all_deployed else "missing_models"\r\n\r\n        # Publish status\r\n        status_msg = String()\r\n        status_msg.data = f"Deployment status: {self.deployment_status}. Models: {self.models_deployed}"\r\n        self.status_publisher.publish(status_msg)\r\n\r\n    def image_callback(self, image_msg):\r\n        """Process incoming images and test model deployment"""\r\n        try:\r\n            # Convert ROS Image to OpenCV\r\n            cv_image = self.bridge.imgmsg_to_cv2(image_msg, "bgr8")\r\n\r\n            # Log that we\'re processing an image\r\n            self.get_logger().info(f\'Processing image: {cv_image.shape}\')\r\n\r\n            # Publish status update\r\n            status_msg = String()\r\n            status_msg.data = f"Processing image, models deployed: {self.models_deployed}"\r\n            self.status_publisher.publish(status_msg)\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error in image callback: {e}\')\r\n\r\n    def get_deployment_summary(self) -> str:\r\n        """Get a summary of model deployment status"""\r\n        summary = f"Deployment Status: {self.deployment_status}\\n"\r\n        for model_name, deployed in self.models_deployed.items():\r\n            status = "\u2713 Deployed" if deployed else "\u2717 Missing"\r\n            summary += f"  {model_name}: {status}\\n"\r\n        return summary\r\n\r\n    def deploy_model(self, model_name: str, model_path: str) -> bool:\r\n        """Deploy a specific model"""\r\n        try:\r\n            # Check if model file exists\r\n            if not os.path.exists(model_path):\r\n                self.get_logger().error(f\'Model file does not exist: {model_path}\')\r\n                return False\r\n\r\n            # In a real implementation, you would load the model into memory here\r\n            # For this example, we\'ll just mark it as deployed\r\n            self.models_deployed[model_name] = True\r\n            self.get_logger().info(f\'Model {model_name} deployed successfully\')\r\n\r\n            # Update deployment status\r\n            all_deployed = all(self.models_deployed.values())\r\n            self.deployment_status = "ready" if all_deployed else "partial"\r\n\r\n            return True\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error deploying model {model_name}: {e}\')\r\n            return False\r\n\r\n    def undeploy_model(self, model_name: str) -> bool:\r\n        """Undeploy a specific model"""\r\n        if model_name in self.models_deployed:\r\n            # In a real implementation, you would free the model from memory here\r\n            self.models_deployed[model_name] = False\r\n            self.get_logger().info(f\'Model {model_name} undeployed\')\r\n\r\n            # Update deployment status\r\n            if any(self.models_deployed.values()):\r\n                self.deployment_status = "partial"\r\n            else:\r\n                self.deployment_status = "empty"\r\n\r\n            return True\r\n        return False\r\n\r\n\r\nclass ModelDeploymentManager(Node):\r\n    def __init__(self):\r\n        super().__init__(\'model_deployment_manager\')\r\n\r\n        # Create model deployer instance\r\n        self.model_deployer = ModelDeployer()\r\n\r\n        # Create service servers for model management\r\n        from rclpy.qos import QoSProfile\r\n        from std_srvs.srv import Trigger\r\n        from isaac_ros_model_deployment.srv import DeployModel\r\n\r\n        # Service to check deployment status\r\n        self.status_service = self.create_service(\r\n            Trigger,\r\n            \'get_deployment_status\',\r\n            self.get_status_callback\r\n        )\r\n\r\n        # Service to deploy a model\r\n        self.deploy_service = self.create_service(\r\n            DeployModel,\r\n            \'deploy_model\',\r\n            self.deploy_model_callback\r\n        )\r\n\r\n        # Service to undeploy a model\r\n        self.undeploy_service = self.create_service(\r\n            DeployModel,\r\n            \'undeploy_model\',\r\n            self.undeploy_model_callback\r\n        )\r\n\r\n        self.get_logger().info(\'Model Deployment Manager initialized\')\r\n\r\n    def get_status_callback(self, request, response):\r\n        """Service callback to get deployment status"""\r\n        summary = self.model_deployer.get_deployment_summary()\r\n        response.success = True\r\n        response.message = summary\r\n        return response\r\n\r\n    def deploy_model_callback(self, request, response):\r\n        """Service callback to deploy a model"""\r\n        success = self.model_deployer.deploy_model(request.model_name, request.model_path)\r\n        response.success = success\r\n        response.message = f"Model {request.model_name} deployment: {\'Success\' if success else \'Failed\'}"\r\n        return response\r\n\r\n    def undeploy_model_callback(self, request, response):\r\n        """Service callback to undeploy a model"""\r\n        success = self.model_deployer.undeploy_model(request.model_name)\r\n        response.success = success\r\n        response.message = f"Model {request.model_name} undeployment: {\'Success\' if success else \'Failed\'}"\r\n        return response\r\n\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n\r\n    # Create and run the model deployment manager\r\n    manager = ModelDeploymentManager()\r\n\r\n    try:\r\n        rclpy.spin(manager)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        manager.destroy_node()\r\n        rclpy.shutdown()\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()\r\nEOF\n'})}),"\n",(0,t.jsx)(n.h3,{id:"4-creating-service-definition-for-model-deployment",children:"4. Creating Service Definition for Model Deployment"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/isaac_ros_ws/src/isaac_ros_model_deployment/srv\r\ncat > ~/isaac_ros_ws/src/isaac_ros_model_deployment/srv/DeployModel.srv << 'EOF'\r\nstring model_name\r\nstring model_path\r\n---\r\nbool success\r\nstring message\r\nEOF\n"})}),"\n",(0,t.jsx)(n.h3,{id:"5-creating-setup-files-for-model-deployment-package",children:"5. Creating Setup Files for Model Deployment Package"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cat > ~/isaac_ros_ws/src/isaac_ros_model_deployment/setup.py << 'EOF'\r\nfrom setuptools import setup\r\nfrom glob import glob\r\nimport os\r\n\r\npackage_name = 'isaac_ros_model_deployment'\r\n\r\nsetup(\r\n    name=package_name,\r\n    version='0.0.1',\r\n    packages=[package_name],\r\n    data_files=[\r\n        ('share/ament_index/resource_index/packages',\r\n            ['resource/' + package_name]),\r\n        ('share/' + package_name, ['package.xml']),\r\n        # Include service definition\r\n        (os.path.join('share', package_name, 'srv'), glob('srv/*.srv')),\r\n    ],\r\n    install_requires=['setuptools'],\r\n    zip_safe=True,\r\n    maintainer='Your Name',\r\n    maintainer_email='your.email@example.com',\r\n    description='Model deployment tools for Isaac ROS',\r\n    license='Apache License 2.0',\r\n    tests_require=['pytest'],\r\n    entry_points={\r\n        'console_scripts': [\r\n            'model_deployer = isaac_ros_model_deployment.model_deployer:main',\r\n        ],\r\n    },\r\n)\r\nEOF\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'cat > ~/isaac_ros_ws/src/isaac_ros_model_deployment/package.xml << \'EOF\'\r\n<?xml version="1.0"?>\r\n<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>\r\n<package format="3">\r\n  <name>isaac_ros_model_deployment</name>\r\n  <version>0.0.1</version>\r\n  <description>Model deployment tools for Isaac ROS</description>\r\n  <maintainer email="your.email@example.com">Your Name</maintainer>\r\n  <license>Apache License 2.0</license>\r\n\r\n  <depend>rclpy</depend>\r\n  <depend>sensor_msgs</depend>\r\n  <depend>vision_msgs</depend>\r\n  <depend>cv_bridge</depend>\r\n  <depend>geometry_msgs</depend>\r\n  <depend>std_msgs</depend>\r\n  <depend>std_srvs</depend>\r\n\r\n  <test_depend>ament_copyright</test_depend>\r\n  <test_depend>ament_flake8</test_depend>\r\n  <test_depend>ament_pep257</test_depend>\r\n  <test_depend>python3-pytest</test_depend>\r\n\r\n  <member_of_group>rosidl_interface_packages</member_of_group>\r\n\r\n  <export>\r\n    <build_type>ament_python</build_type>\r\n  </export>\r\n</package>\r\nEOF\n'})}),"\n",(0,t.jsx)(n.h2,{id:"model-deployment-testing",children:"Model Deployment Testing"}),"\n",(0,t.jsx)(n.h3,{id:"1-creating-model-deployment-test-script",children:"1. Creating Model Deployment Test Script"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'cat > ~/test_model_deployment.sh << \'EOF\'\r\n#!/bin/bash\r\n\r\n# Test script for AI model deployment in Isaac Sim\r\n\r\necho "Testing AI Model Deployment..."\r\n\r\n# Source ROS environment\r\nsource /opt/ros/humble/setup.bash\r\nsource ~/isaac_ros_ws/install/setup.bash\r\n\r\n# Check if model deployment package is available\r\necho "Checking model deployment package..."\r\nros2 pkg list | grep model_deployment\r\n\r\nif [ $? -eq 0 ]; then\r\n    echo "\u2713 Model deployment package found"\r\nelse\r\n    echo "\u2717 Model deployment package not found"\r\n    exit 1\r\nfi\r\n\r\n# Check if model files exist\r\necho "Checking model files..."\r\nif [ -f "/workspace/shared_dir/models/yolo/yolov5s.onnx" ]; then\r\n    echo "\u2713 YOLO ONNX model found"\r\nelse\r\n    echo "\u2717 YOLO ONNX model not found"\r\n    # Try to convert the model\r\n    echo "Attempting to convert YOLO model to ONNX..."\r\n    python3 /workspace/shared_dir/scripts/convert_yolo_to_onnx.py\r\nfi\r\n\r\nif [ -f "/workspace/shared_dir/models/segmentation/fcn_resnet101.onnx" ]; then\r\n    echo "\u2713 Segmentation ONNX model found"\r\nelse\r\n    echo "\u2717 Segmentation ONNX model not found"\r\n    # Try to convert the model\r\n    echo "Attempting to convert segmentation model to ONNX..."\r\n    python3 /workspace/shared_dir/scripts/convert_segmentation_to_onnx.py\r\nfi\r\n\r\nif [ -f "/workspace/shared_dir/models/depth/midas.onnx" ]; then\r\n    echo "\u2713 Depth ONNX model found"\r\nelse\r\n    echo "\u2717 Depth ONNX model not found"\r\n    # Try to convert the model\r\n    echo "Attempting to convert depth model to ONNX..."\r\n    python3 /workspace/shared_dir/scripts/convert_depth_to_onnx.py\r\nfi\r\n\r\n# Build the model deployment package\r\necho "Building model deployment package..."\r\ncd ~/isaac_ros_ws\r\ncolcon build --packages-select isaac_ros_model_deployment\r\nsource install/setup.bash\r\n\r\n# Check if TensorRT optimization script exists\r\nif [ -f "/workspace/shared_dir/scripts/optimize_with_tensorrt.py" ]; then\r\n    echo "\u2713 TensorRT optimization script found"\r\nelse\r\n    echo "\u2717 TensorRT optimization script not found"\r\n    exit 1\r\nfi\r\n\r\n# Test TensorRT optimization (this may take a while)\r\necho "Testing TensorRT optimization (this may take a few minutes)..."\r\npython3 /workspace/shared_dir/scripts/optimize_with_tensorrt.py\r\n\r\necho "AI Model Deployment test completed."\r\nEOF\r\n\r\n# Make executable\r\nchmod +x ~/test_model_deployment.sh\n'})}),"\n",(0,t.jsx)(n.h3,{id:"2-running-model-deployment-test",children:"2. Running Model Deployment Test"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"~/test_model_deployment.sh\n"})}),"\n",(0,t.jsx)(n.h2,{id:"model-performance-monitoring",children:"Model Performance Monitoring"}),"\n",(0,t.jsx)(n.h3,{id:"1-creating-performance-monitoring-script",children:"1. Creating Performance Monitoring Script"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cat > ~/isaac_sim_shared/scripts/model_performance_monitor.py << 'EOF'\r\n#!/usr/bin/env python3\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image\r\nfrom std_msgs.msg import Float32, String\r\nimport time\r\nfrom collections import deque\r\nimport json\r\nimport os\r\n\r\nclass ModelPerformanceMonitor(Node):\r\n    def __init__(self):\r\n        super().__init__('model_performance_monitor')\r\n\r\n        # Subscribe to image input (to measure processing pipeline)\r\n        self.image_subscription = self.create_subscription(\r\n            Image,\r\n            '/camera/color/image_raw',\r\n            self.image_callback,\r\n            10\r\n        )\r\n\r\n        # Publishers for performance metrics\r\n        self.fps_publisher = self.create_publisher(Float32, '/model_fps', 10)\r\n        self.latency_publisher = self.create_publisher(Float32, '/model_latency', 10)\r\n        self.cpu_usage_publisher = self.create_publisher(Float32, '/model_cpu_usage', 10)\r\n        self.gpu_usage_publisher = self.create_publisher(Float32, '/model_gpu_usage', 10)\r\n        self.memory_usage_publisher = self.create_publisher(Float32, '/model_memory_usage', 10)\r\n        self.status_publisher = self.create_publisher(String, '/model_performance_status', 10)\r\n\r\n        # Performance tracking\r\n        self.frame_times = deque(maxlen=30)  # Last 30 frames for FPS calculation\r\n        self.processing_times = deque(maxlen=30)  # Last 30 processing times\r\n        self.last_image_time = None\r\n\r\n        # Setup timer for periodic metrics publishing\r\n        self.timer = self.create_timer(1.0, self.publish_metrics)\r\n\r\n        # Setup timer for system metrics\r\n        self.system_timer = self.create_timer(2.0, self.publish_system_metrics)\r\n\r\n        # Performance log\r\n        self.performance_log = []\r\n        self.log_file = \"/workspace/shared_dir/logs/model_performance.json\"\r\n\r\n        self.get_logger().info('Model Performance Monitor initialized')\r\n\r\n    def image_callback(self, msg):\r\n        \"\"\"Track image processing for performance measurement\"\"\"\r\n        current_time = self.get_clock().now().nanoseconds / 1e9\r\n        image_proc_time = current_time - (self.last_image_time or current_time)\r\n\r\n        if self.last_image_time is not None:\r\n            frame_time = current_time - self.last_image_time\r\n            self.frame_times.append(frame_time)\r\n            self.processing_times.append(image_proc_time)\r\n\r\n        self.last_image_time = current_time\r\n\r\n    def publish_metrics(self):\r\n        \"\"\"Publish performance metrics\"\"\"\r\n        # Calculate FPS\r\n        if len(self.frame_times) > 0:\r\n            avg_frame_time = sum(self.frame_times) / len(self.frame_times)\r\n            fps = 1.0 / avg_frame_time if avg_frame_time > 0 else 0.0\r\n            fps_msg = Float32()\r\n            fps_msg.data = fps\r\n            self.fps_publisher.publish(fps_msg)\r\n\r\n        # Calculate average processing latency\r\n        if len(self.processing_times) > 0:\r\n            avg_latency = sum(self.processing_times) / len(self.processing_times)\r\n            latency_msg = Float32()\r\n            latency_msg.data = avg_latency\r\n            self.latency_publisher.publish(latency_msg)\r\n\r\n        # Publish status\r\n        status_msg = String()\r\n        status_msg.data = f\"FPS: {fps:.2f}, Latency: {avg_latency*1000:.2f}ms\"\r\n        self.status_publisher.publish(status_msg)\r\n\r\n        # Log performance data\r\n        perf_data = {\r\n            'timestamp': time.time(),\r\n            'fps': fps,\r\n            'latency_ms': avg_latency * 1000,\r\n            'frame_count': len(self.frame_times)\r\n        }\r\n        self.performance_log.append(perf_data)\r\n\r\n        # Write to log file periodically\r\n        if len(self.performance_log) % 10 == 0:  # Every 10 updates\r\n            self.write_performance_log()\r\n\r\n    def publish_system_metrics(self):\r\n        \"\"\"Publish system resource usage metrics\"\"\"\r\n        import psutil\r\n\r\n        # CPU usage\r\n        cpu_percent = psutil.cpu_percent()\r\n        cpu_msg = Float32()\r\n        cpu_msg.data = float(cpu_percent)\r\n        self.cpu_usage_publisher.publish(cpu_msg)\r\n\r\n        # Memory usage\r\n        memory = psutil.virtual_memory()\r\n        memory_msg = Float32()\r\n        memory_msg.data = float(memory.percent)\r\n        self.memory_usage_publisher.publish(memory_msg)\r\n\r\n        # For GPU usage, we'll use nvidia-ml-py if available\r\n        try:\r\n            import pynvml\r\n            pynvml.nvmlInit()\r\n            handle = pynvml.nvmlDeviceGetHandleByIndex(0)\r\n            util = pynvml.nvmlDeviceGetUtilizationRates(handle)\r\n            gpu_util_msg = Float32()\r\n            gpu_util_msg.data = float(util.gpu)\r\n            self.gpu_usage_publisher.publish(gpu_util_msg)\r\n        except:\r\n            # If nvidia-ml-py is not available, publish a placeholder\r\n            gpu_util_msg = Float32()\r\n            gpu_util_msg.data = 0.0\r\n            self.gpu_usage_publisher.publish(gpu_util_msg)\r\n\r\n    def write_performance_log(self):\r\n        \"\"\"Write performance log to file\"\"\"\r\n        try:\r\n            with open(self.log_file, 'w') as f:\r\n                json.dump(self.performance_log, f, indent=2)\r\n        except Exception as e:\r\n            self.get_logger().error(f'Error writing performance log: {e}')\r\n\r\n    def get_performance_summary(self):\r\n        \"\"\"Get a summary of performance metrics\"\"\"\r\n        summary = {\r\n            'total_samples': len(self.performance_log),\r\n            'avg_fps': 0.0,\r\n            'avg_latency_ms': 0.0,\r\n            'min_fps': float('inf'),\r\n            'max_fps': 0.0\r\n        }\r\n\r\n        if self.performance_log:\r\n            fps_values = [entry['fps'] for entry in self.performance_log]\r\n            latency_values = [entry['latency_ms'] for entry in self.performance_log]\r\n\r\n            summary['avg_fps'] = sum(fps_values) / len(fps_values)\r\n            summary['avg_latency_ms'] = sum(latency_values) / len(latency_values)\r\n            summary['min_fps'] = min(fps_values)\r\n            summary['max_fps'] = max(fps_values)\r\n\r\n        return summary\r\n\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    monitor = ModelPerformanceMonitor()\r\n\r\n    try:\r\n        rclpy.spin(monitor)\r\n    except KeyboardInterrupt:\r\n        summary = monitor.get_performance_summary()\r\n        print(f\"Performance Summary: {summary}\")\r\n        monitor.write_performance_log()\r\n        print(f\"Performance log saved to: {monitor.log_file}\")\r\n    finally:\r\n        monitor.destroy_node()\r\n        rclpy.shutdown()\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\nEOF\n"})}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting-model-deployment",children:"Troubleshooting Model Deployment"}),"\n",(0,t.jsx)(n.h3,{id:"common-issues-and-solutions",children:"Common Issues and Solutions"}),"\n",(0,t.jsx)(n.h4,{id:"issue-model-conversion-fails-with-onnx-export-error",children:'Issue: "Model conversion fails with ONNX export error"'}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Solution"}),": Check PyTorch and ONNX compatibility"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Verify PyTorch and ONNX versions\r\npython3 -c "import torch; print(torch.__version__)"\r\npython3 -c "import onnx; print(onnx.__version__)"\r\n\r\n# Update if needed\r\npip3 install --upgrade torch torchvision torchaudio onnx\n'})}),"\n",(0,t.jsx)(n.h4,{id:"issue-tensorrt-engine-build-fails",children:'Issue: "TensorRT engine build fails"'}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Solution"}),": Check TensorRT installation and GPU compatibility"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'# Check TensorRT version\r\npython3 -c "import tensorrt; print(tensorrt.__version__)"\r\n\r\n# Check GPU compute capability\r\nnvidia-smi\n'})}),"\n",(0,t.jsx)(n.h4,{id:"issue-models-not-loading-in-isaac-sim",children:'Issue: "Models not loading in Isaac Sim"'}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Solution"}),": Verify file paths and permissions"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Check model file existence\r\nls -la /workspace/shared_dir/models/yolo/\r\nls -la /workspace/shared_dir/models/segmentation/\r\nls -la /workspace/shared_dir/models/depth/\r\n\r\n# Check permissions\r\nchmod -R 755 /workspace/shared_dir/models/\n"})}),"\n",(0,t.jsx)(n.h2,{id:"verification-checklist",children:"Verification Checklist"}),"\n",(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Model conversion scripts created and tested"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","ONNX models generated successfully"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","TensorRT optimization implemented"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Isaac ROS model deployment package created"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Model configuration files created"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Performance monitoring tools implemented"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Test scripts created and functional"]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Troubleshooting guide reviewed"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(n.p,{children:"After deploying AI models:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Test model performance"})," in Isaac Sim environment"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Optimize models"})," based on performance metrics"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Integrate with perception pipeline"})," from previous exercises"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Create model deployment exercises"})," for students"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The AI model deployment framework is now configured and ready for Module 3, providing students with tools to deploy and optimize AI models in the Isaac Sim environment."})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(m,{...e})}):m(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>l});var o=r(6540);const t={},s=o.createContext(t);function i(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);