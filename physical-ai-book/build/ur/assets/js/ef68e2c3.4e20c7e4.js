"use strict";(globalThis.webpackChunkai_native_textbook_physical_ai_humanoid_robotics=globalThis.webpackChunkai_native_textbook_physical_ai_humanoid_robotics||[]).push([[723],{5855:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"chapter-4/setup","title":"VLA System Setup Guide","description":"Overview","source":"@site/docs/chapter-4/setup.md","sourceDirName":"chapter-4","slug":"/chapter-4/setup","permalink":"/ur/docs/chapter-4/setup","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter-4/setup.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 4.1.5: VLA System Integration","permalink":"/ur/docs/chapter-4/lesson-5"},"next":{"title":"Integration Guide: Vision-Language-Action (VLA) Systems","permalink":"/ur/docs/chapter-4/integration-guide"}}');var r=i(4848),o=i(8453);const t={},l="VLA System Setup Guide",a={},c=[{value:"Overview",id:"overview",level:2},{value:"System Requirements",id:"system-requirements",level:2},{value:"Hardware Requirements",id:"hardware-requirements",level:3},{value:"Software Requirements",id:"software-requirements",level:3},{value:"Prerequisites Installation",id:"prerequisites-installation",level:2},{value:"1. ROS 2 Humble Installation",id:"1-ros-2-humble-installation",level:3},{value:"2. NVIDIA Isaac Sim Installation",id:"2-nvidia-isaac-sim-installation",level:3},{value:"Method A: Docker Installation (Recommended)",id:"method-a-docker-installation-recommended",level:4},{value:"Method B: Local Installation",id:"method-b-local-installation",level:4},{value:"3. Python Environment Setup",id:"3-python-environment-setup",level:3},{value:"VLA System Installation",id:"vla-system-installation",level:2},{value:"1. Clone the Repository",id:"1-clone-the-repository",level:3},{value:"2. Install VLA-Specific Dependencies",id:"2-install-vla-specific-dependencies",level:3},{value:"3. Configure Environment Variables",id:"3-configure-environment-variables",level:3},{value:"Component Configuration",id:"component-configuration",level:2},{value:"1. Whisper Speech Processing Setup",id:"1-whisper-speech-processing-setup",level:3},{value:"2. LLM Client Configuration",id:"2-llm-client-configuration",level:3},{value:"3. Vision System Configuration",id:"3-vision-system-configuration",level:3},{value:"4. ROS 2 Integration Setup",id:"4-ros-2-integration-setup",level:3},{value:"Environment Configuration",id:"environment-configuration",level:2},{value:"1. Isaac Sim Connection",id:"1-isaac-sim-connection",level:3},{value:"2. Audio Input Configuration",id:"2-audio-input-configuration",level:3},{value:"3. Network Configuration",id:"3-network-configuration",level:3},{value:"Verification Steps",id:"verification-steps",level:2},{value:"1. Test Individual Components",id:"1-test-individual-components",level:3},{value:"2. Test ROS 2 Integration",id:"2-test-ros-2-integration",level:3},{value:"3. Run Complete System Test",id:"3-run-complete-system-test",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues and Solutions",id:"common-issues-and-solutions",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"1. GPU Acceleration",id:"1-gpu-acceleration",level:3},{value:"2. Model Selection",id:"2-model-selection",level:3},{value:"3. Resource Management",id:"3-resource-management",level:3},{value:"Next Steps",id:"next-steps",level:2},{value:"Support and Resources",id:"support-and-resources",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"vla-system-setup-guide",children:"VLA System Setup Guide"})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"This guide provides detailed instructions for setting up the Vision-Language-Action (VLA) system. The VLA system integrates speech processing, cognitive planning, visual perception, and robotic action execution to enable natural language control of humanoid robots in simulation."}),"\n",(0,r.jsx)(n.h2,{id:"system-requirements",children:"System Requirements"}),"\n",(0,r.jsx)(n.h3,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CPU"}),": Multi-core processor (Intel i7 or equivalent recommended)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GPU"}),": NVIDIA GPU with CUDA support (RTX 3060 or better recommended)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RAM"}),": 16GB minimum, 32GB recommended"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Storage"}),": 50GB free space for Isaac Sim and dependencies"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Microphone"}),": USB or built-in microphone for voice input"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Internet"}),": Required for LLM access and package downloads"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"software-requirements",children:"Software Requirements"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"OS"}),": Ubuntu 22.04 LTS (recommended) or Windows 10/11 with WSL2"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ROS 2"}),": Humble Hawksbill distribution"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Python"}),": 3.11 or higher"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CUDA"}),": 11.8 or higher (for GPU acceleration)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Docker"}),": For Isaac Sim container deployment (optional but recommended)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites-installation",children:"Prerequisites Installation"}),"\n",(0,r.jsx)(n.h3,{id:"1-ros-2-humble-installation",children:"1. ROS 2 Humble Installation"}),"\n",(0,r.jsx)(n.p,{children:"For Ubuntu 22.04:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Set locale\r\nsudo locale-gen en_US.UTF-8\r\nexport LANG=en_US.UTF-8\r\n\r\n# Add ROS 2 apt repository\r\nsudo apt update && sudo apt install -y curl gnupg lsb-release\r\nsudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg\r\necho "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(source /etc/os-release && echo $UBUNTU_CODENAME) main" | sudo tee /etc/apt/sources.list.d/ros2.list > /dev/null\r\n\r\n# Install ROS 2 Humble\r\nsudo apt update\r\nsudo apt install -y ros-humble-desktop\r\nsudo apt install -y python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential\r\n\r\n# Initialize rosdep\r\nsudo rosdep init\r\nrosdep update\r\n\r\n# Source ROS 2 environment\r\necho "source /opt/ros/humble/setup.bash" >> ~/.bashrc\r\nsource ~/.bashrc\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-nvidia-isaac-sim-installation",children:"2. NVIDIA Isaac Sim Installation"}),"\n",(0,r.jsx)(n.p,{children:"Choose one of the following installation methods:"}),"\n",(0,r.jsx)(n.h4,{id:"method-a-docker-installation-recommended",children:"Method A: Docker Installation (Recommended)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Install Docker if not already installed\r\nsudo apt update\r\nsudo apt install -y docker.io\r\nsudo usermod -aG docker $USER  # Log out and back in for this to take effect\r\n\r\n# Pull Isaac Sim Docker image\r\ndocker pull nvcr.io/nvidia/isaac-sim:4.0.0\r\n\r\n# Create a script to run Isaac Sim\r\ncat << 'EOF' > ~/run_isaac_sim.sh\r\n#!/bin/bash\r\nxhost +local:docker\r\ndocker run --gpus all -it --rm \\\r\n  --network=host \\\r\n  --env NVIDIA_DISABLE_REQUIRE=1 \\\r\n  --env PYTHON_ROOT_DIR=/isaac-sim/python.sh \\\r\n  --env IsaacSim_SERVER_PORT=50051 \\\r\n  --volume $HOME/isaac-sim-assets:/isaac-sim/assets \\\r\n  --volume $HOME/isaac-sim-examples:/isaac-sim/examples \\\r\n  --volume $HOME/isaac-sim-workspace:/isaac-sim/workspace \\\r\n  --volume $HOME/isaac-sim-python:/isaac-sim/python \\\r\n  --volume $HOME/isaac-sim-config:/isaac-sim/config \\\r\n  --volume $HOME/isaac-sim-logs:/isaac-sim/logs \\\r\n  --volume $HOME/isaac-sim-data:/isaac-sim/data \\\r\n  --privileged \\\r\n  --pid=host \\\r\n  nvcr.io/nvidia/isaac-sim:4.0.0\r\nEOF\r\n\r\nchmod +x ~/run_isaac_sim.sh\n"})}),"\n",(0,r.jsx)(n.h4,{id:"method-b-local-installation",children:"Method B: Local Installation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Download Isaac Sim from NVIDIA Developer website\r\n# Follow the official installation guide for your platform\r\n# https://docs.omniverse.nvidia.com/isaacsim/latest/overview.html\n"})}),"\n",(0,r.jsx)(n.h3,{id:"3-python-environment-setup",children:"3. Python Environment Setup"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Create virtual environment\r\npython3 -m venv vla_env\r\nsource vla_env/bin/activate\r\n\r\n# Upgrade pip\r\npip install --upgrade pip\r\n\r\n# Install core dependencies\r\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\r\npip install openai-whisper\r\npip install openai\r\npip install ultralytics  # For YOLO object detection\r\npip install opencv-python\r\npip install rclpy  # ROS 2 Python client library\r\npip install numpy pandas matplotlib\r\npip install tenacity  # For retry logic\r\npip install pyaudio  # For audio input\n"})}),"\n",(0,r.jsx)(n.h2,{id:"vla-system-installation",children:"VLA System Installation"}),"\n",(0,r.jsx)(n.h3,{id:"1-clone-the-repository",children:"1. Clone the Repository"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/your-organization/physical-ai-book.git\r\ncd physical-ai-book\n"})}),"\n",(0,r.jsx)(n.h3,{id:"2-install-vla-specific-dependencies",children:"2. Install VLA-Specific Dependencies"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd physical-ai-book\r\nsource vla_env/bin/activate\r\n\r\n# Install additional dependencies\r\npip install -e .  # If setup.py exists\r\n# OR install individual packages\r\npip install transformers  # For additional NLP capabilities\r\npip install sentence-transformers  # For semantic similarity\r\npip install faiss-cpu  # For vector similarity search\n"})}),"\n",(0,r.jsx)(n.h3,{id:"3-configure-environment-variables",children:"3. Configure Environment Variables"}),"\n",(0,r.jsxs)(n.p,{children:["Create a ",(0,r.jsx)(n.code,{children:".env"})," file in the project root:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Create .env file\r\ncat << 'EOF' > .env\r\n# OpenAI API Configuration\r\nOPENAI_API_KEY=your_openai_api_key_here\r\n\r\n# ROS 2 Configuration\r\nROS_DOMAIN_ID=42\r\n\r\n# Isaac Sim Configuration\r\nISAAC_SIM_PATH=/path/to/isaac/sim  # Only if installed locally\r\nISAAC_SIM_SERVER_PORT=50051\r\n\r\n# Whisper Model Configuration\r\nWHISPER_MODEL_SIZE=base  # tiny, base, small, medium, large\r\n\r\n# System Configuration\r\nVLA_WORKSPACE_PATH=/path/to/vla/workspace\r\nVLA_LOG_LEVEL=INFO\r\nEOF\n"})}),"\n",(0,r.jsx)(n.h2,{id:"component-configuration",children:"Component Configuration"}),"\n",(0,r.jsx)(n.h3,{id:"1-whisper-speech-processing-setup",children:"1. Whisper Speech Processing Setup"}),"\n",(0,r.jsx)(n.p,{children:"The Whisper component is configured automatically, but you can customize the model size:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# In src/vla/speech/whisper_processor.py, you can adjust:\r\nmodel_size = "base"  # Options: tiny, base, small, medium, large\r\n# Larger models are more accurate but slower\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-llm-client-configuration",children:"2. LLM Client Configuration"}),"\n",(0,r.jsx)(n.p,{children:"Set up your OpenAI API key in the environment variables:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'export OPENAI_API_KEY="your-api-key-here"\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Or use the ",(0,r.jsx)(n.code,{children:".env"})," file created earlier."]}),"\n",(0,r.jsx)(n.h3,{id:"3-vision-system-configuration",children:"3. Vision System Configuration"}),"\n",(0,r.jsx)(n.p,{children:"The vision system uses YOLOv8 by default. You can configure it as follows:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# In src/vla/vision/object_detector.py:\r\nconfidence_threshold = 0.5  # Adjust based on your needs\r\n# Lower values detect more objects but may include false positives\n"})}),"\n",(0,r.jsx)(n.h3,{id:"4-ros-2-integration-setup",children:"4. ROS 2 Integration Setup"}),"\n",(0,r.jsx)(n.p,{children:"Ensure ROS 2 is properly sourced:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"source /opt/ros/humble/setup.bash\r\nsource install/setup.bash  # If you have a colcon workspace\n"})}),"\n",(0,r.jsx)(n.h2,{id:"environment-configuration",children:"Environment Configuration"}),"\n",(0,r.jsx)(n.h3,{id:"1-isaac-sim-connection",children:"1. Isaac Sim Connection"}),"\n",(0,r.jsx)(n.p,{children:"If using Isaac Sim Docker, ensure it's running:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Run Isaac Sim in one terminal\r\n./run_isaac_sim.sh\r\n\r\n# In another terminal, verify connection\r\npython3 -c \"import omni; print('Isaac Sim connection test')\"\n"})}),"\n",(0,r.jsx)(n.h3,{id:"2-audio-input-configuration",children:"2. Audio Input Configuration"}),"\n",(0,r.jsx)(n.p,{children:"Test your microphone:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Install and test audio input\r\npip install pyaudio\r\npython3 -c "\r\nimport pyaudio\r\np = pyaudio.PyAudio()\r\nprint(\'Available audio devices:\')\r\nfor i in range(p.get_device_count()):\r\n    info = p.get_device_info_by_index(i)\r\n    print(f\'{i}: {info[\\"name\\"]} - {info[\\"maxInputChannels\\"]} input channels\')\r\n"\n'})}),"\n",(0,r.jsx)(n.h3,{id:"3-network-configuration",children:"3. Network Configuration"}),"\n",(0,r.jsx)(n.p,{children:"Ensure proper network connectivity between components:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Check if ROS 2 nodes can communicate\r\nsource /opt/ros/humble/setup.bash\r\nros2 topic list\r\n\r\n# Check Isaac Sim connection (if using remote API)\r\nnetstat -tuln | grep 50051\n"})}),"\n",(0,r.jsx)(n.h2,{id:"verification-steps",children:"Verification Steps"}),"\n",(0,r.jsx)(n.h3,{id:"1-test-individual-components",children:"1. Test Individual Components"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Test Whisper processing\r\nsource vla_env/bin/activate\r\ncd physical-ai-book\r\npython3 -c \"\r\nfrom src.vla.speech.whisper_processor import WhisperProcessor\r\nprocessor = WhisperProcessor(model_size='base')\r\nprint('Whisper processor initialized successfully')\r\n\"\r\n\r\n# Test LLM client\r\npython3 -c \"\r\nimport os\r\nfrom src.vla.llm.llm_client import LLMClient\r\n# This will fail if API key is not set, which is expected\r\ntry:\r\n    client = LLMClient()\r\n    print('LLM client initialized successfully')\r\nexcept ValueError as e:\r\n    print(f'LLM client setup issue: {e}')\r\n\"\r\n\r\n# Test vision components\r\npython3 -c \"\r\nfrom src.vla.vision.object_detector import ObjectDetector\r\ndetector = ObjectDetector()\r\nprint('Vision components initialized successfully')\r\n\"\n"})}),"\n",(0,r.jsx)(n.h3,{id:"2-test-ros-2-integration",children:"2. Test ROS 2 Integration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Source ROS 2 environment\r\nsource /opt/ros/humble/setup.bash\r\n\r\n# Run a simple ROS 2 test\r\npython3 -c \"\r\nimport rclpy\r\nrclpy.init()\r\nnode = rclpy.create_node('test_node')\r\nprint('ROS 2 connection successful')\r\nnode.destroy_node()\r\nrclpy.shutdown()\r\n\"\n"})}),"\n",(0,r.jsx)(n.h3,{id:"3-run-complete-system-test",children:"3. Run Complete System Test"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# In the project root\r\nsource vla_env/bin/activate\r\nsource /opt/ros/humble/setup.bash\r\n\r\npython3 -c \"\r\nfrom src.vla.integration.vla_system import VLASystem\r\nfrom src.vla.speech.whisper_processor import WhisperProcessor\r\nfrom src.vla.llm.llm_client import LLMClient\r\nfrom src.vla.vision.object_detector import ObjectDetector\r\nfrom src.vla.ros2.action_executor import ActionExecutor\r\n\r\n# Initialize components (with mock API key for testing)\r\nimport os\r\nos.environ['OPENAI_API_KEY'] = 'test-key'  # Only for initialization test\r\n\r\ntry:\r\n    whisper = WhisperProcessor(model_size='base')\r\n    llm_client = LLMClient(api_key='test-key')\r\n    detector = ObjectDetector()\r\n    executor = ActionExecutor()\r\n\r\n    vla_system = VLASystem(whisper, llm_client, detector, executor)\r\n    print('VLA System initialized successfully')\r\n\r\n    # Test direct command processing\r\n    result = vla_system.process_command_direct('Move forward 1 meter')\r\n    print(f'Direct command test completed: {result}')\r\n\r\nexcept Exception as e:\r\n    print(f'Error in system initialization: {e}')\r\n\"\n"})}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"common-issues-and-solutions",children:"Common Issues and Solutions"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Issue 1"}),": CUDA not found"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Symptoms"}),": PyTorch errors, Whisper processing fails"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Ensure CUDA drivers and toolkit are properly installed"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"nvidia-smi  # Check if GPU drivers are working\r\nnvcc --version  # Check CUDA toolkit\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Issue 2"}),": ROS 2 packages not found"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Symptoms"}),": ImportError when importing rclpy"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Ensure ROS 2 environment is properly sourced"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"source /opt/ros/humble/setup.bash\r\necho $PYTHONPATH  # Should include ROS 2 paths\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Issue 3"}),": Isaac Sim connection fails"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Symptoms"}),": Isaac Sim client cannot connect to server"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Verify Isaac Sim is running and ports are accessible"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Check if Isaac Sim server is running\r\nnetstat -tuln | grep 50051\r\ndocker ps  # If using Docker\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Issue 4"}),": Audio input not working"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Symptoms"}),": Voice commands not being captured"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Check microphone permissions and configuration"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Test audio recording\r\narecord -D hw:0,0 -f cd test.wav  # Replace hw:0,0 with your device\r\n# Play back to verify\r\naplay test.wav\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Issue 5"}),": OpenAI API errors"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Symptoms"}),": LLM planning fails with authentication errors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Verify API key is correctly set in environment"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"echo $OPENAI_API_KEY  # Should show your API key\r\n# Or check .env file\n"})}),"\n",(0,r.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(n.h3,{id:"1-gpu-acceleration",children:"1. GPU Acceleration"}),"\n",(0,r.jsx)(n.p,{children:"Ensure all components utilize GPU when available:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Whisper processing with GPU"}),"\n",(0,r.jsx)(n.li,{children:"PyTorch models with CUDA"}),"\n",(0,r.jsx)(n.li,{children:"Vision processing acceleration"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-model-selection",children:"2. Model Selection"}),"\n",(0,r.jsx)(n.p,{children:"Choose appropriate model sizes for your hardware:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Whisper: Use 'base' or 'small' for real-time performance"}),"\n",(0,r.jsx)(n.li,{children:"YOLO: Use 'n' (nano) or 's' (small) for faster inference"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"3-resource-management",children:"3. Resource Management"}),"\n",(0,r.jsx)(n.p,{children:"Monitor system resources during operation:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Monitor GPU usage\r\nnvidia-smi -l 1\r\n\r\n# Monitor CPU and memory\r\nhtop\r\n\r\n# Monitor ROS 2 topics\r\nsource /opt/ros/humble/setup.bash\r\nros2 topic hz /your_topic_name\n"})}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(n.p,{children:"After completing the setup:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Run the VLA system"}),": Start with simple commands to verify functionality"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Follow the lessons"}),": Complete Module 4 lessons in order"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Test with Isaac Sim"}),": Connect to simulation environment"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Execute capstone project"}),": Implement the autonomous humanoid task"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"support-and-resources",children:"Support and Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Documentation"}),": Refer to individual component documentation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Issues"}),": Report setup problems in the project repository"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Community"}),": Join the Physical AI & Humanoid Robotics community"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Troubleshooting"}),": Check the troubleshooting section in each lesson"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Your VLA system is now ready for use. Proceed to Lesson 1 to begin implementing the voice processing component."})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var s=i(6540);const r={},o=s.createContext(r);function t(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);