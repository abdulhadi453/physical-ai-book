"use strict";(globalThis.webpackChunkai_native_textbook_physical_ai_humanoid_robotics=globalThis.webpackChunkai_native_textbook_physical_ai_humanoid_robotics||[]).push([[265],{5341:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"chapter-2/exercise-3","title":"Exercise 3: Advanced Navigation","description":"Overview","source":"@site/docs/chapter-2/exercise-3.md","sourceDirName":"chapter-2","slug":"/chapter-2/exercise-3","permalink":"/ur/docs/chapter-2/exercise-3","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter-2/exercise-3.md","tags":[],"version":"current","sidebarPosition":18,"frontMatter":{"sidebar_position":18},"sidebar":"tutorialSidebar","previous":{"title":"Exercise 2: Sensor Integration","permalink":"/ur/docs/chapter-2/exercise-2"},"next":{"title":"Exercise 4: Cross-Platform Comparative Analysis","permalink":"/ur/docs/chapter-2/exercise-4"}}');var i=r(4848),a=r(8453);const s={sidebar_position:18},o="Exercise 3: Advanced Navigation",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Exercise Setup",id:"exercise-setup",level:2},{value:"Environment Configuration",id:"environment-configuration",level:3},{value:"Robot Configuration",id:"robot-configuration",level:3},{value:"Exercise Steps",id:"exercise-steps",level:2},{value:"Step 1: Environment Mapping and Localization",id:"step-1-environment-mapping-and-localization",level:3},{value:"Step 2: Path Planning",id:"step-2-path-planning",level:3},{value:"Step 3: Motion Control",id:"step-3-motion-control",level:3},{value:"Step 4: System Integration and Testing",id:"step-4-system-integration-and-testing",level:3},{value:"Implementation Tasks",id:"implementation-tasks",level:2},{value:"Task 1: SLAM System Implementation",id:"task-1-slam-system-implementation",level:3},{value:"Task 2: Local Planner and Obstacle Avoidance",id:"task-2-local-planner-and-obstacle-avoidance",level:3},{value:"Task 3: Motion Controller",id:"task-3-motion-controller",level:3},{value:"Task 4: Complete Navigation System",id:"task-4-complete-navigation-system",level:3},{value:"Task 5: Performance Evaluation",id:"task-5-performance-evaluation",level:3},{value:"Expected Outcomes",id:"expected-outcomes",level:2},{value:"Technical Outcomes",id:"technical-outcomes",level:3},{value:"Learning Outcomes",id:"learning-outcomes",level:3},{value:"Assessment Questions",id:"assessment-questions",level:2},{value:"Advanced Challenges",id:"advanced-challenges",level:2},{value:"Validation and Testing",id:"validation-and-testing",level:2},{value:"Performance Metrics",id:"performance-metrics",level:3},{value:"Test Scenarios",id:"test-scenarios",level:3},{value:"Resources",id:"resources",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"exercise-3-advanced-navigation",children:"Exercise 3: Advanced Navigation"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"This exercise integrates all previously learned concepts to implement advanced navigation capabilities using a multi-sensor approach. You will create a complete navigation system that uses LiDAR, depth camera, and IMU data to navigate complex environments with dynamic obstacles and challenging terrain."}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this exercise, you will be able to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Implement a complete navigation stack with perception, planning, and control"}),"\n",(0,i.jsx)(n.li,{children:"Integrate multiple sensors for robust environment understanding"}),"\n",(0,i.jsx)(n.li,{children:"Handle dynamic obstacles and changing environments"}),"\n",(0,i.jsx)(n.li,{children:"Implement path planning and trajectory execution"}),"\n",(0,i.jsx)(n.li,{children:"Validate navigation performance in complex scenarios"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Completion of Exercises 1 and 2"}),"\n",(0,i.jsx)(n.li,{children:"Understanding of sensor fusion concepts"}),"\n",(0,i.jsx)(n.li,{children:"Basic knowledge of path planning algorithms"}),"\n",(0,i.jsx)(n.li,{children:"Familiarity with control systems for robot navigation"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"exercise-setup",children:"Exercise Setup"}),"\n",(0,i.jsx)(n.h3,{id:"environment-configuration",children:"Environment Configuration"}),"\n",(0,i.jsx)(n.p,{children:"Create a complex navigation environment with:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Multiple rooms connected by corridors"}),"\n",(0,i.jsx)(n.li,{children:"Various obstacle types (static and dynamic)"}),"\n",(0,i.jsx)(n.li,{children:"Different floor surfaces and elevations"}),"\n",(0,i.jsx)(n.li,{children:"Doorways and narrow passages"}),"\n",(0,i.jsx)(n.li,{children:"Moving obstacles to test dynamic navigation"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"robot-configuration",children:"Robot Configuration"}),"\n",(0,i.jsx)(n.p,{children:"Configure your robot with:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Complete sensor suite (LiDAR, depth camera, IMU)"}),"\n",(0,i.jsx)(n.li,{children:"Differential drive or similar mobility platform"}),"\n",(0,i.jsx)(n.li,{children:"Appropriate computational resources for real-time processing"}),"\n",(0,i.jsx)(n.li,{children:"Communication interface for navigation commands"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"exercise-steps",children:"Exercise Steps"}),"\n",(0,i.jsx)(n.h3,{id:"step-1-environment-mapping-and-localization",children:"Step 1: Environment Mapping and Localization"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"SLAM Implementation"}),": Implement Simultaneous Localization and Mapping using sensor data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Map Building"}),": Create a comprehensive map of the environment"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Localization"}),": Maintain accurate robot pose estimation within the map"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Map Update"}),": Handle dynamic changes in the environment"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"step-2-path-planning",children:"Step 2: Path Planning"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Global Planner"}),": Implement a global path planner (A*, Dijkstra, or similar)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Local Planner"}),": Implement a local planner for obstacle avoidance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Path Optimization"}),": Optimize paths for safety, efficiency, and smoothness"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dynamic Replanning"}),": Handle path updates when obstacles are detected"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"step-3-motion-control",children:"Step 3: Motion Control"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Trajectory Following"}),": Implement controllers to follow planned trajectories"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Obstacle Avoidance"}),": Implement reactive avoidance for unexpected obstacles"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Motion Smoothing"}),": Ensure smooth transitions between waypoints"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Safety Systems"}),": Implement emergency stopping and safe recovery"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"step-4-system-integration-and-testing",children:"Step 4: System Integration and Testing"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Complete System"}),": Integrate all components into a working navigation system"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Performance Testing"}),": Test navigation performance in various scenarios"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Robustness Testing"}),": Test system behavior under challenging conditions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Validation"}),": Validate navigation accuracy and safety"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"implementation-tasks",children:"Implementation Tasks"}),"\n",(0,i.jsx)(n.h3,{id:"task-1-slam-system-implementation",children:"Task 1: SLAM System Implementation"}),"\n",(0,i.jsx)(n.p,{children:"Create a basic SLAM system that integrates sensor data:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\nfrom scipy.spatial import KDTree\r\nimport heapq\r\nfrom dataclasses import dataclass\r\nfrom typing import List, Tuple, Optional\r\n\r\n@dataclass\r\nclass Pose2D:\r\n    x: float\r\n    y: float\r\n    theta: float\r\n\r\nclass SimpleSLAM:\r\n    def __init__(self, map_resolution: float = 0.1):\r\n        self.map_resolution = map_resolution\r\n        self.occupancy_grid = {}  # Dictionary-based occupancy grid\r\n        self.robot_path = []      # Path history for loop closure\r\n        self.current_pose = Pose2D(0, 0, 0)\r\n\r\n    def update_map(self, lidar_points: np.ndarray, robot_pose: Pose2D):\r\n        """Update occupancy grid with LiDAR data"""\r\n        # Convert LiDAR points to global coordinates\r\n        cos_theta = np.cos(robot_pose.theta)\r\n        sin_theta = np.sin(robot_pose.theta)\r\n\r\n        # Transform points from robot frame to global frame\r\n        global_points = []\r\n        for point in lidar_points:\r\n            # Rotate and translate point\r\n            x_rot = point[0] * cos_theta - point[1] * sin_theta\r\n            y_rot = point[0] * sin_theta + point[1] * cos_theta\r\n            x_global = x_rot + robot_pose.x\r\n            y_global = y_rot + robot_pose.y\r\n            global_points.append((x_global, y_global))\r\n\r\n        # Update occupancy grid\r\n        for point in global_points:\r\n            grid_x = int(point[0] / self.map_resolution)\r\n            grid_y = int(point[1] / self.map_resolution)\r\n            grid_key = (grid_x, grid_y)\r\n\r\n            # Simple occupancy update (occupied = 1, free = 0)\r\n            if grid_key not in self.occupancy_grid:\r\n                self.occupancy_grid[grid_key] = 0\r\n            self.occupancy_grid[grid_key] = 1  # Mark as occupied\r\n\r\n        # Update robot pose\r\n        self.current_pose = robot_pose\r\n        self.robot_path.append(robot_pose)\r\n\r\n    def get_map_bounds(self):\r\n        """Get the bounds of the current map"""\r\n        if not self.occupancy_grid:\r\n            return (0, 0, 0, 0)\r\n\r\n        x_coords = [key[0] for key in self.occupancy_grid.keys()]\r\n        y_coords = [key[1] for key in self.occupancy_grid.keys()]\r\n\r\n        return (min(x_coords), max(x_coords), min(y_coords), max(y_coords))\r\n\r\n    def is_occupied(self, x: float, y: float) -> bool:\r\n        """Check if a point is occupied in the map"""\r\n        grid_x = int(x / self.map_resolution)\r\n        grid_y = int(y / self.map_resolution)\r\n        grid_key = (grid_x, grid_y)\r\n\r\n        return self.occupancy_grid.get(grid_key, 0) > 0.5\r\n\r\nclass NavigationSystem:\r\n    def __init__(self):\r\n        self.slam = SimpleSLAM()\r\n        self.path = []\r\n        self.current_goal = None\r\n        self.path_index = 0\r\n\r\n    def set_goal(self, goal_x: float, goal_y: float):\r\n        """Set navigation goal"""\r\n        self.current_goal = (goal_x, goal_y)\r\n\r\n    def plan_path(self, start_pose: Pose2D, goal: Tuple[float, float]) -> List[Tuple[float, float]]:\r\n        """Plan path using A* algorithm"""\r\n        # Simplified A* implementation\r\n        start_grid = (int(start_pose.x / 0.5), int(start_pose.y / 0.5))\r\n        goal_grid = (int(goal[0] / 0.5), int(goal[1] / 0.5))\r\n\r\n        # Use occupancy grid for path planning\r\n        # In practice, you\'d implement a proper A* algorithm\r\n        # This is a simplified version for demonstration\r\n\r\n        # Generate a simple path (in reality, implement A* with obstacle checking)\r\n        path = []\r\n        current = start_grid\r\n        target = goal_grid\r\n\r\n        # Simple grid-based path to target\r\n        while current != target:\r\n            dx = target[0] - current[0]\r\n            dy = target[1] - current[1]\r\n\r\n            if abs(dx) > abs(dy):\r\n                next_x = current[0] + (1 if dx > 0 else -1)\r\n                next_y = current[1]\r\n            else:\r\n                next_x = current[0]\r\n                next_y = current[1] + (1 if dy > 0 else -1)\r\n\r\n            current = (next_x, next_y)\r\n            path.append((current[0] * 0.5, current[1] * 0.5))  # Convert back to meters\r\n\r\n            if len(path) > 1000:  # Prevent infinite loops\r\n                break\r\n\r\n        return path\n'})}),"\n",(0,i.jsx)(n.h3,{id:"task-2-local-planner-and-obstacle-avoidance",children:"Task 2: Local Planner and Obstacle Avoidance"}),"\n",(0,i.jsx)(n.p,{children:"Implement local planning and reactive obstacle avoidance:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class LocalPlanner:\r\n    def __init__(self, robot_radius: float = 0.3, safety_distance: float = 0.5):\r\n        self.robot_radius = robot_radius\r\n        self.safety_distance = safety_distance\r\n        self.obstacle_threshold = robot_radius + safety_distance\r\n\r\n    def check_collision_free_path(self, start: Tuple[float, float],\r\n                                end: Tuple[float, float],\r\n                                slam_system: SimpleSLAM) -> bool:\r\n        """Check if path is collision-free"""\r\n        # Simple line-of-sight collision checking\r\n        steps = 10  # Number of steps to check along the path\r\n        for i in range(steps + 1):\r\n            t = i / steps\r\n            x = start[0] + t * (end[0] - start[0])\r\n            y = start[1] + t * (end[1] - start[1])\r\n\r\n            # Check if this point is occupied\r\n            if slam_system.is_occupied(x, y):\r\n                return False\r\n        return True\r\n\r\n    def reactive_avoidance(self, lidar_points: np.ndarray,\r\n                          current_velocity: Tuple[float, float],\r\n                          target_direction: Tuple[float, float]) -> Tuple[float, float]:\r\n        """Implement reactive obstacle avoidance"""\r\n        # Find closest obstacles in front of robot\r\n        front_threshold = 0.5  # Only consider obstacles within 0.5m\r\n        min_distance = float(\'inf\')\r\n        closest_obstacle = None\r\n\r\n        for point in lidar_points:\r\n            distance = np.sqrt(point[0]**2 + point[1]**2)\r\n            if distance < min_distance and distance < front_threshold:\r\n                min_distance = distance\r\n                closest_obstacle = point\r\n\r\n        if closest_obstacle is not None and min_distance < self.obstacle_threshold:\r\n            # Obstacle detected, modify velocity\r\n            # Simple reactive approach: slow down and turn away\r\n            avoidance_factor = 1.0 - (min_distance / self.obstacle_threshold)\r\n            turn_direction = 1.0 if closest_obstacle[1] > 0 else -1.0  # Turn away from obstacle\r\n\r\n            # Reduce forward velocity and add lateral component\r\n            new_vx = current_velocity[0] * (1 - avoidance_factor * 0.5)\r\n            new_vy = current_velocity[1] + turn_direction * avoidance_factor * 0.3\r\n\r\n            return (new_vx, new_vy)\r\n\r\n        # No obstacle, return original velocity\r\n        return current_velocity\n'})}),"\n",(0,i.jsx)(n.h3,{id:"task-3-motion-controller",children:"Task 3: Motion Controller"}),"\n",(0,i.jsx)(n.p,{children:"Implement a motion controller for trajectory following:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class MotionController:\r\n    def __init__(self, linear_kp: float = 1.0, angular_kp: float = 2.0):\r\n        self.linear_kp = linear_kp\r\n        self.angular_kp = angular_kp\r\n        self.max_linear_vel = 0.5  # m/s\r\n        self.max_angular_vel = 1.0  # rad/s\r\n\r\n    def compute_velocity(self, current_pose: Pose2D,\r\n                        target_pose: Pose2D) -> Tuple[float, float]:\r\n        """Compute linear and angular velocities to reach target pose"""\r\n        # Calculate error\r\n        dx = target_pose.x - current_pose.x\r\n        dy = target_pose.y - current_pose.y\r\n        distance = np.sqrt(dx**2 + dy**2)\r\n\r\n        # Calculate target angle\r\n        target_angle = np.arctan2(dy, dx)\r\n        angle_error = target_angle - current_pose.theta\r\n\r\n        # Normalize angle error to [-\u03c0, \u03c0]\r\n        while angle_error > np.pi:\r\n            angle_error -= 2 * np.pi\r\n        while angle_error < -np.pi:\r\n            angle_error += 2 * np.pi\r\n\r\n        # Compute velocities\r\n        linear_vel = min(self.linear_kp * distance, self.max_linear_vel)\r\n        angular_vel = self.angular_kp * angle_error\r\n\r\n        # Limit angular velocity\r\n        angular_vel = max(min(angular_vel, self.max_angular_vel), -self.max_angular_vel)\r\n\r\n        return (linear_vel, angular_vel)\r\n\r\n    def follow_path(self, current_pose: Pose2D, path: List[Tuple[float, float]],\r\n                   current_index: int) -> Tuple[float, float, int]:\r\n        """Follow a path and return velocity commands"""\r\n        if current_index >= len(path):\r\n            return (0.0, 0.0)  # Stop when path is complete\r\n\r\n        target_x, target_y = path[current_index]\r\n        target_pose = Pose2D(target_x, target_y, 0)  # Heading not used here\r\n\r\n        # Check if we\'ve reached current waypoint\r\n        dx = target_x - current_pose.x\r\n        dy = target_y - current_pose.y\r\n        distance_to_waypoint = np.sqrt(dx**2 + dy**2)\r\n\r\n        # Move to next waypoint if close enough\r\n        if distance_to_waypoint < 0.2:  # 20cm threshold\r\n            current_index += 1\r\n            if current_index < len(path):\r\n                target_x, target_y = path[current_index]\r\n                target_pose = Pose2D(target_x, target_y, 0)\r\n\r\n        # Compute velocity to follow path\r\n        linear_vel, angular_vel = self.compute_velocity(current_pose, target_pose)\r\n\r\n        return (linear_vel, angular_vel, current_index)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"task-4-complete-navigation-system",children:"Task 4: Complete Navigation System"}),"\n",(0,i.jsx)(n.p,{children:"Integrate all components into a complete system:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class CompleteNavigationSystem:\r\n    def __init__(self):\r\n        self.slam = SimpleSLAM()\r\n        self.local_planner = LocalPlanner()\r\n        self.motion_controller = MotionController()\r\n        self.global_path = []\r\n        self.current_waypoint = 0\r\n        self.navigation_active = False\r\n        self.emergency_stop = False\r\n\r\n    def update_sensors(self, lidar_points: np.ndarray,\r\n                      depth_image: Optional[np.ndarray],\r\n                      imu_data: dict,\r\n                      robot_pose: Pose2D):\r\n        """Process sensor data and update navigation system"""\r\n        if self.emergency_stop:\r\n            return (0.0, 0.0)  # Emergency stop\r\n\r\n        # Update SLAM with sensor data\r\n        self.slam.update_map(lidar_points, robot_pose)\r\n\r\n        # If navigation is active, compute navigation commands\r\n        if self.navigation_active and self.current_waypoint < len(self.global_path):\r\n            # Get current waypoint\r\n            target_x, target_y = self.global_path[self.current_waypoint]\r\n            target_pose = Pose2D(target_x, target_y, 0)\r\n\r\n            # Follow the path\r\n            linear_vel, angular_vel, self.current_waypoint = self.motion_controller.follow_path(\r\n                robot_pose, self.global_path, self.current_waypoint\r\n            )\r\n\r\n            # Apply local obstacle avoidance\r\n            current_vel = (linear_vel, 0)  # Simplified for differential drive\r\n            safe_vel = self.local_planner.reactive_avoidance(\r\n                lidar_points, current_vel, (target_x - robot_pose.x, target_y - robot_pose.y)\r\n            )\r\n\r\n            # Convert back to linear/angular velocities for differential drive\r\n            linear_cmd = safe_vel[0]\r\n            angular_cmd = angular_vel  # Keep original angular control\r\n\r\n            return (linear_cmd, angular_cmd)\r\n\r\n        # If not navigating, return zero velocity\r\n        return (0.0, 0.0)\r\n\r\n    def set_navigation_goal(self, goal_x: float, goal_y: float, start_pose: Pose2D):\r\n        """Set navigation goal and plan path"""\r\n        # Plan global path\r\n        self.global_path = self.slam.plan_path(start_pose, (goal_x, goal_y))\r\n        self.current_waypoint = 0\r\n        self.navigation_active = True\r\n\r\n    def stop_navigation(self):\r\n        """Stop current navigation"""\r\n        self.navigation_active = False\r\n        self.emergency_stop = False\r\n\r\n    def emergency_stop(self):\r\n        """Emergency stop the robot"""\r\n        self.emergency_stop = True\n'})}),"\n",(0,i.jsx)(n.h3,{id:"task-5-performance-evaluation",children:"Task 5: Performance Evaluation"}),"\n",(0,i.jsx)(n.p,{children:"Implement functions to evaluate navigation performance:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"class NavigationEvaluator:\r\n    def __init__(self):\r\n        self.metrics = {\r\n            'path_length': 0.0,\r\n            'time_taken': 0.0,\r\n            'collisions': 0,\r\n            'goal_reached': False,\r\n            'path_efficiency': 0.0,\r\n            'navigation_success': False\r\n        }\r\n\r\n    def evaluate_navigation(self, path_taken: List[Tuple[float, float]],\r\n                           goal_reached: bool,\r\n                           execution_time: float,\r\n                           collisions: int,\r\n                           start_pos: Tuple[float, float],\r\n                           goal_pos: Tuple[float, float]) -> dict:\r\n        \"\"\"Evaluate navigation performance\"\"\"\r\n        # Calculate path length\r\n        path_length = 0.0\r\n        for i in range(1, len(path_taken)):\r\n            dx = path_taken[i][0] - path_taken[i-1][0]\r\n            dy = path_taken[i][1] - path_taken[i-1][1]\r\n            path_length += np.sqrt(dx**2 + dy**2)\r\n\r\n        # Calculate optimal path length (straight line)\r\n        optimal_length = np.sqrt((goal_pos[0] - start_pos[0])**2 +\r\n                                (goal_pos[1] - start_pos[1])**2)\r\n\r\n        # Calculate metrics\r\n        path_efficiency = optimal_length / path_length if path_length > 0 else 0\r\n\r\n        self.metrics.update({\r\n            'path_length': path_length,\r\n            'time_taken': execution_time,\r\n            'collisions': collisions,\r\n            'goal_reached': goal_reached,\r\n            'path_efficiency': path_efficiency,\r\n            'navigation_success': goal_reached and collisions == 0\r\n        })\r\n\r\n        return self.metrics\r\n\r\n    def get_navigation_score(self) -> float:\r\n        \"\"\"Calculate overall navigation score\"\"\"\r\n        if not self.metrics['goal_reached']:\r\n            return 0.0\r\n\r\n        # Calculate weighted score\r\n        efficiency_score = min(self.metrics['path_efficiency'], 1.0)\r\n        safety_score = 1.0 if self.metrics['collisions'] == 0 else 0.0\r\n        time_score = 1.0 / (1.0 + self.metrics['time_taken'] / 100)  # Normalize time\r\n\r\n        # Weighted average (adjust weights as needed)\r\n        score = 0.5 * efficiency_score + 0.3 * safety_score + 0.2 * time_score\r\n        return score\n"})}),"\n",(0,i.jsx)(n.h2,{id:"expected-outcomes",children:"Expected Outcomes"}),"\n",(0,i.jsx)(n.h3,{id:"technical-outcomes",children:"Technical Outcomes"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Working navigation system that can reach specified goals"}),"\n",(0,i.jsx)(n.li,{children:"Robust obstacle avoidance in dynamic environments"}),"\n",(0,i.jsx)(n.li,{children:"Accurate localization and mapping capabilities"}),"\n",(0,i.jsx)(n.li,{children:"Smooth trajectory following with safety considerations"}),"\n",(0,i.jsx)(n.li,{children:"Quantitative performance metrics for navigation quality"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Understanding of complete navigation system architecture"}),"\n",(0,i.jsx)(n.li,{children:"Experience with multi-sensor integration for navigation"}),"\n",(0,i.jsx)(n.li,{children:"Knowledge of path planning and motion control"}),"\n",(0,i.jsx)(n.li,{children:"Skills in system validation and performance evaluation"}),"\n",(0,i.jsx)(n.li,{children:"Appreciation for real-world navigation challenges"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"assessment-questions",children:"Assessment Questions"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Analysis"}),": How does your navigation system handle situations where the planned path becomes blocked by unexpected obstacles?"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Problem-Solving"}),": What strategies did you implement to ensure the robot doesn't get stuck in local minima during navigation?"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Application"}),": How would you modify your navigation system to handle environments with poor lighting where the depth camera might be less effective?"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Evaluation"}),": What metrics did you use to evaluate navigation performance, and why are these important for real-world applications?"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"advanced-challenges",children:"Advanced Challenges"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Dynamic Obstacle Prediction"}),": Extend your system to predict the future positions of moving obstacles and plan accordingly"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Multi-Goal Navigation"}),": Implement navigation to multiple goals in an efficient sequence"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Exploration"}),": Add exploration capabilities to discover unknown areas of the environment"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Human-Robot Interaction"}),": Implement navigation that considers human presence and comfort in shared spaces"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"validation-and-testing",children:"Validation and Testing"}),"\n",(0,i.jsx)(n.h3,{id:"performance-metrics",children:"Performance Metrics"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Success Rate"}),": Percentage of goals reached successfully"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Path Efficiency"}),": Ratio of actual path length to optimal path length"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Safety"}),": Number of collisions or near-misses"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Time Efficiency"}),": Time taken to reach goals"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Robustness"}),": Performance under various environmental conditions"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"test-scenarios",children:"Test Scenarios"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Simple Navigation"}),": Move between two points with no obstacles"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Obstacle Avoidance"}),": Navigate around static obstacles"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Dynamic Obstacles"}),": Handle moving obstacles in the environment"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Complex Environments"}),": Navigate through cluttered or narrow spaces"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Long-term Operation"}),": Extended navigation sessions to test system stability"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"http://wiki.ros.org/navigation",children:"ROS Navigation Stack Documentation"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://ieeexplore.ieee.org/document/8202188",children:"Path Planning Algorithms Comparison"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://www.cs.cmu.edu/~16831-f14/notes/LEC/16831_lecture29_trotz_2014.pdf",children:"SLAM Tutorial"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://www.springer.com/gp/book/9783319515941",children:"Motion Control in Robotics"})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsx)(n.p,{children:"After completing this exercise, you will have implemented a complete navigation system. Consider exploring advanced topics such as:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Learning-based navigation approaches"}),"\n",(0,i.jsx)(n.li,{children:"Multi-robot coordination"}),"\n",(0,i.jsx)(n.li,{children:"Navigation in 3D environments"}),"\n",(0,i.jsx)(n.li,{children:"Integration with higher-level task planning systems"}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>o});var t=r(6540);const i={},a=t.createContext(i);function s(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);