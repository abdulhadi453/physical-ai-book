"use strict";(globalThis.webpackChunkai_native_textbook_physical_ai_humanoid_robotics=globalThis.webpackChunkai_native_textbook_physical_ai_humanoid_robotics||[]).push([[8563],{3628:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"chapter-4/glossary","title":"Module 4: Vision-Language-Action (VLA) Systems - Glossary","description":"A","source":"@site/docs/chapter-4/glossary.md","sourceDirName":"chapter-4","slug":"/chapter-4/glossary","permalink":"/docs/chapter-4/glossary","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter-4/glossary.md","tags":[],"version":"current","frontMatter":{}}');var a=i(4848),o=i(8453);const r={},s="Module 4: Vision-Language-Action (VLA) Systems - Glossary",l={},c=[{value:"A",id:"a",level:2},{value:"Action Execution",id:"action-execution",level:3},{value:"Action Sequence",id:"action-sequence",level:3},{value:"Action Step",id:"action-step",level:3},{value:"API Contract",id:"api-contract",level:3},{value:"Async Processing",id:"async-processing",level:3},{value:"B",id:"b",level:2},{value:"Bounding Box",id:"bounding-box",level:3},{value:"Bridge Pattern",id:"bridge-pattern",level:3},{value:"C",id:"c",level:2},{value:"Cognitive Planning",id:"cognitive-planning",level:3},{value:"Component Integration",id:"component-integration",level:3},{value:"Confidence Scoring",id:"confidence-scoring",level:3},{value:"Constitution Compliance",id:"constitution-compliance",level:3},{value:"Context Awareness",id:"context-awareness",level:3},{value:"D",id:"d",level:2},{value:"Data Flow",id:"data-flow",level:3},{value:"Data Model",id:"data-model",level:3},{value:"Detected Object",id:"detected-object",level:3},{value:"Deep Learning",id:"deep-learning",level:3},{value:"Dependency Injection",id:"dependency-injection",level:3},{value:"E",id:"e",level:2},{value:"End-to-End Pipeline",id:"end-to-end-pipeline",level:3},{value:"Entity Relationship",id:"entity-relationship",level:3},{value:"Error Handling",id:"error-handling",level:3},{value:"Event-Driven Architecture",id:"event-driven-architecture",level:3},{value:"Execution State",id:"execution-state",level:3},{value:"F",id:"f",level:2},{value:"Factory Pattern",id:"factory-pattern",level:3},{value:"Feature Extraction",id:"feature-extraction",level:3},{value:"Feedback Loop",id:"feedback-loop",level:3},{value:"Functional Requirement",id:"functional-requirement",level:3},{value:"G",id:"g",level:2},{value:"Generative AI",id:"generative-ai",level:3},{value:"Geometric Transformation",id:"geometric-transformation",level:3},{value:"Grasp Planning",id:"grasp-planning",level:3},{value:"H",id:"h",level:2},{value:"Human-Robot Interaction (HRI)",id:"human-robot-interaction-hri",level:3},{value:"Hyperparameter Tuning",id:"hyperparameter-tuning",level:3},{value:"I",id:"i",level:2},{value:"Intent Classification",id:"intent-classification",level:3},{value:"Integration Testing",id:"integration-testing",level:3},{value:"Iterative Development",id:"iterative-development",level:3},{value:"K",id:"k",level:2},{value:"Knowledge Representation",id:"knowledge-representation",level:3},{value:"L",id:"l",level:2},{value:"Large Language Model (LLM)",id:"large-language-model-llm",level:3},{value:"Latency",id:"latency",level:3},{value:"Linear Algebra",id:"linear-algebra",level:3},{value:"Logger",id:"logger",level:3},{value:"M",id:"m",level:2},{value:"Machine Learning",id:"machine-learning",level:3},{value:"Message Queuing",id:"message-queuing",level:3},{value:"Microservice Architecture",id:"microservice-architecture",level:3},{value:"Middleware",id:"middleware",level:3},{value:"Model Optimization",id:"model-optimization",level:3},{value:"N",id:"n",level:2},{value:"Natural Language Processing (NLP)",id:"natural-language-processing-nlp",level:3},{value:"Neural Network",id:"neural-network",level:3},{value:"Non-Functional Requirement",id:"non-functional-requirement",level:3},{value:"O",id:"o",level:2},{value:"Object Detection",id:"object-detection",level:3},{value:"Observer Pattern",id:"observer-pattern",level:3},{value:"OpenAI API",id:"openai-api",level:3},{value:"Operational Semantics",id:"operational-semantics",level:3},{value:"P",id:"p",level:2},{value:"Perception Pipeline",id:"perception-pipeline",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Planning Algorithm",id:"planning-algorithm",level:3},{value:"Plugin Architecture",id:"plugin-architecture",level:3},{value:"Prompt Engineering",id:"prompt-engineering",level:3},{value:"Publisher-Subscriber Pattern",id:"publisher-subscriber-pattern",level:3},{value:"Q",id:"q",level:2},{value:"Quality Assurance",id:"quality-assurance",level:3},{value:"Query Optimization",id:"query-optimization",level:3},{value:"R",id:"r",level:2},{value:"Real-Time Processing",id:"real-time-processing",level:3},{value:"Repository Pattern",id:"repository-pattern",level:3},{value:"Robot Operating System 2 (ROS 2)",id:"robot-operating-system-2-ros-2",level:3},{value:"ROS 2 Actions",id:"ros-2-actions",level:3},{value:"Runtime Environment",id:"runtime-environment",level:3},{value:"S",id:"s",level:2},{value:"Semantic Segmentation",id:"semantic-segmentation",level:3},{value:"Singleton Pattern",id:"singleton-pattern",level:3},{value:"Speech-to-Text",id:"speech-to-text",level:3},{value:"State Machine",id:"state-machine",level:3},{value:"State Management",id:"state-management",level:3},{value:"Stereo Vision",id:"stereo-vision",level:3},{value:"Supervised Learning",id:"supervised-learning",level:3},{value:"System Architecture",id:"system-architecture",level:3},{value:"T",id:"t",level:2},{value:"Task Decomposition",id:"task-decomposition",level:3},{value:"Thread Safety",id:"thread-safety",level:3},{value:"Three-Dimensional (3D) Reconstruction",id:"three-dimensional-3d-reconstruction",level:3},{value:"Transformer Architecture",id:"transformer-architecture",level:3},{value:"Type Hints",id:"type-hints",level:3},{value:"U",id:"u",level:2},{value:"Unit Testing",id:"unit-testing",level:3},{value:"User Experience (UX)",id:"user-experience-ux",level:3},{value:"Utility Functions",id:"utility-functions",level:3},{value:"V",id:"v",level:2},{value:"Vision-Language-Action (VLA)",id:"vision-language-action-vla",level:3},{value:"Voice Command Processing",id:"voice-command-processing",level:3},{value:"Voice Input Handler",id:"voice-input-handler",level:3},{value:"Vision Processing",id:"vision-processing",level:3},{value:"Value Stream Mapping",id:"value-stream-mapping",level:3},{value:"W",id:"w",level:2},{value:"Whisper Model",id:"whisper-model",level:3},{value:"Workload Management",id:"workload-management",level:3},{value:"WebSocket Communication",id:"websocket-communication",level:3},{value:"X",id:"x",level:2},{value:"XML Configuration",id:"xml-configuration",level:3},{value:"Y",id:"y",level:2},{value:"YAML Configuration",id:"yaml-configuration",level:3},{value:"Z",id:"z",level:2},{value:"Zero-Shot Learning",id:"zero-shot-learning",level:3},{value:"Zipf&#39;s Law",id:"zipfs-law",level:3}];function d(e){const n={h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"module-4-vision-language-action-vla-systems---glossary",children:"Module 4: Vision-Language-Action (VLA) Systems - Glossary"})}),"\n",(0,a.jsx)(n.h2,{id:"a",children:"A"}),"\n",(0,a.jsx)(n.h3,{id:"action-execution",children:"Action Execution"}),"\n",(0,a.jsx)(n.p,{children:"The process of carrying out planned robotic actions through ROS 2 action servers and clients. Action execution translates high-level plans into low-level motor commands that control the robot's physical movements."}),"\n",(0,a.jsx)(n.h3,{id:"action-sequence",children:"Action Sequence"}),"\n",(0,a.jsx)(n.p,{children:"An ordered list of executable robotic actions generated by the cognitive planner. Each action sequence represents the decomposition of a high-level command into specific, achievable steps."}),"\n",(0,a.jsx)(n.h3,{id:"action-step",children:"Action Step"}),"\n",(0,a.jsx)(n.p,{children:"An individual robotic action within an action sequence, specifying a particular behavior (navigation, manipulation, etc.) with associated parameters and constraints."}),"\n",(0,a.jsx)(n.h3,{id:"api-contract",children:"API Contract"}),"\n",(0,a.jsx)(n.p,{children:"A formal specification defining the interface between system components, including endpoints, request/response formats, and data schemas for reliable communication."}),"\n",(0,a.jsx)(n.h3,{id:"async-processing",children:"Async Processing"}),"\n",(0,a.jsx)(n.p,{children:"Asynchronous processing that allows multiple operations to execute concurrently without blocking the main execution thread, improving system responsiveness."}),"\n",(0,a.jsx)(n.h2,{id:"b",children:"B"}),"\n",(0,a.jsx)(n.h3,{id:"bounding-box",children:"Bounding Box"}),"\n",(0,a.jsx)(n.p,{children:"A rectangular frame that defines the location and extent of an object in a 2D image, specified by coordinates for the top-left and bottom-right corners."}),"\n",(0,a.jsx)(n.h3,{id:"bridge-pattern",children:"Bridge Pattern"}),"\n",(0,a.jsx)(n.p,{children:"A structural design pattern that separates an abstraction from its implementation, allowing both to vary independently. Used in VLA system for separating interfaces from implementations."}),"\n",(0,a.jsx)(n.h2,{id:"c",children:"C"}),"\n",(0,a.jsx)(n.h3,{id:"cognitive-planning",children:"Cognitive Planning"}),"\n",(0,a.jsx)(n.p,{children:"The process of interpreting natural language commands and generating executable action sequences using LLM-based reasoning and task decomposition."}),"\n",(0,a.jsx)(n.h3,{id:"component-integration",children:"Component Integration"}),"\n",(0,a.jsx)(n.p,{children:"The process of connecting and coordinating different system components (voice, vision, planning, action) to work together as a unified system."}),"\n",(0,a.jsx)(n.h3,{id:"confidence-scoring",children:"Confidence Scoring"}),"\n",(0,a.jsx)(n.p,{children:"A numerical measure of the reliability or certainty of a system's output, particularly important in speech recognition and object detection."}),"\n",(0,a.jsx)(n.h3,{id:"constitution-compliance",children:"Constitution Compliance"}),"\n",(0,a.jsx)(n.p,{children:"Adherence to the project's foundational principles and requirements as defined in the system constitution document."}),"\n",(0,a.jsx)(n.h3,{id:"context-awareness",children:"Context Awareness"}),"\n",(0,a.jsx)(n.p,{children:"The system's ability to understand and utilize environmental context, including detected objects and spatial relationships, to inform decision making."}),"\n",(0,a.jsx)(n.h2,{id:"d",children:"D"}),"\n",(0,a.jsx)(n.h3,{id:"data-flow",children:"Data Flow"}),"\n",(0,a.jsx)(n.p,{children:"The movement of information between system components, including voice commands, perception data, planning results, and execution feedback."}),"\n",(0,a.jsx)(n.h3,{id:"data-model",children:"Data Model"}),"\n",(0,a.jsx)(n.p,{children:"A structured representation of the entities and relationships used within the VLA system, defining how information is organized and processed."}),"\n",(0,a.jsx)(n.h3,{id:"detected-object",children:"Detected Object"}),"\n",(0,a.jsx)(n.p,{children:"An object identified by the vision system with properties such as class, position, confidence, and graspability for use in action planning."}),"\n",(0,a.jsx)(n.h3,{id:"deep-learning",children:"Deep Learning"}),"\n",(0,a.jsx)(n.p,{children:"A subset of machine learning that uses neural networks with multiple layers to learn complex patterns, applied in VLA systems for speech recognition and object detection."}),"\n",(0,a.jsx)(n.h3,{id:"dependency-injection",children:"Dependency Injection"}),"\n",(0,a.jsx)(n.p,{children:"A design pattern where components receive their dependencies from external sources rather than creating them internally, promoting loose coupling."}),"\n",(0,a.jsx)(n.h2,{id:"e",children:"E"}),"\n",(0,a.jsx)(n.h3,{id:"end-to-end-pipeline",children:"End-to-End Pipeline"}),"\n",(0,a.jsx)(n.p,{children:"A complete system implementation that processes input from the initial stage (voice command) through to the final stage (robotic action) without interruption."}),"\n",(0,a.jsx)(n.h3,{id:"entity-relationship",children:"Entity Relationship"}),"\n",(0,a.jsx)(n.p,{children:"The defined connections and associations between different data entities in the system, such as the relationship between voice commands and processed intents."}),"\n",(0,a.jsx)(n.h3,{id:"error-handling",children:"Error Handling"}),"\n",(0,a.jsx)(n.p,{children:"Mechanisms and strategies for detecting, managing, and recovering from errors or exceptional conditions in the system."}),"\n",(0,a.jsx)(n.h3,{id:"event-driven-architecture",children:"Event-Driven Architecture"}),"\n",(0,a.jsx)(n.p,{children:"A software architecture pattern where components communicate through events and messages, enabling loose coupling and asynchronous processing."}),"\n",(0,a.jsx)(n.h3,{id:"execution-state",children:"Execution State"}),"\n",(0,a.jsx)(n.p,{children:"The current status and progress of an action sequence, including information about which actions have been completed and which remain pending."}),"\n",(0,a.jsx)(n.h2,{id:"f",children:"F"}),"\n",(0,a.jsx)(n.h3,{id:"factory-pattern",children:"Factory Pattern"}),"\n",(0,a.jsx)(n.p,{children:"A creational design pattern that provides an interface for creating objects without specifying their concrete classes, used for component instantiation."}),"\n",(0,a.jsx)(n.h3,{id:"feature-extraction",children:"Feature Extraction"}),"\n",(0,a.jsx)(n.p,{children:"The process of identifying and selecting relevant characteristics from raw data (audio, visual) for further processing and analysis."}),"\n",(0,a.jsx)(n.h3,{id:"feedback-loop",children:"Feedback Loop"}),"\n",(0,a.jsx)(n.p,{children:"A system design where output is fed back as input to improve performance, used in VLA for refining command execution based on results."}),"\n",(0,a.jsx)(n.h3,{id:"functional-requirement",children:"Functional Requirement"}),"\n",(0,a.jsx)(n.p,{children:"A specification of what the system should do, as opposed to non-functional requirements that specify how the system should perform."}),"\n",(0,a.jsx)(n.h2,{id:"g",children:"G"}),"\n",(0,a.jsx)(n.h3,{id:"generative-ai",children:"Generative AI"}),"\n",(0,a.jsx)(n.p,{children:"Artificial intelligence systems that can create new content or data, including LLMs that generate action plans from natural language commands."}),"\n",(0,a.jsx)(n.h3,{id:"geometric-transformation",children:"Geometric Transformation"}),"\n",(0,a.jsx)(n.p,{children:"Mathematical operations that convert coordinates between different reference frames, essential for converting 2D vision data to 3D world coordinates."}),"\n",(0,a.jsx)(n.h3,{id:"grasp-planning",children:"Grasp Planning"}),"\n",(0,a.jsx)(n.p,{children:"The process of determining the optimal way for a robot to grasp an object, considering its shape, size, and orientation."}),"\n",(0,a.jsx)(n.h2,{id:"h",children:"H"}),"\n",(0,a.jsx)(n.h3,{id:"human-robot-interaction-hri",children:"Human-Robot Interaction (HRI)"}),"\n",(0,a.jsx)(n.p,{children:"The study and implementation of interfaces and protocols that enable effective communication and collaboration between humans and robots."}),"\n",(0,a.jsx)(n.h3,{id:"hyperparameter-tuning",children:"Hyperparameter Tuning"}),"\n",(0,a.jsx)(n.p,{children:"The process of adjusting model parameters that control the learning process, such as temperature in LLM generation or confidence thresholds."}),"\n",(0,a.jsx)(n.h2,{id:"i",children:"I"}),"\n",(0,a.jsx)(n.h3,{id:"intent-classification",children:"Intent Classification"}),"\n",(0,a.jsx)(n.p,{children:"The process of categorizing natural language commands into different types (navigation, manipulation, inspection) to guide appropriate processing."}),"\n",(0,a.jsx)(n.h3,{id:"integration-testing",children:"Integration Testing"}),"\n",(0,a.jsx)(n.p,{children:"Testing approach that verifies the interactions between different system components work correctly when combined."}),"\n",(0,a.jsx)(n.h3,{id:"iterative-development",children:"Iterative Development"}),"\n",(0,a.jsx)(n.p,{children:"A software development approach that cycles through repeated phases of design, implementation, and testing to gradually improve the system."}),"\n",(0,a.jsx)(n.h2,{id:"k",children:"K"}),"\n",(0,a.jsx)(n.h3,{id:"knowledge-representation",children:"Knowledge Representation"}),"\n",(0,a.jsx)(n.p,{children:"The field of AI focused on how to formally represent information in a way that can be processed by computer systems for reasoning."}),"\n",(0,a.jsx)(n.h2,{id:"l",children:"L"}),"\n",(0,a.jsx)(n.h3,{id:"large-language-model-llm",children:"Large Language Model (LLM)"}),"\n",(0,a.jsx)(n.p,{children:"Advanced neural networks trained on vast amounts of text that can understand and generate human-like responses, used for cognitive planning."}),"\n",(0,a.jsx)(n.h3,{id:"latency",children:"Latency"}),"\n",(0,a.jsx)(n.p,{children:"The time delay between a command being issued and the system's response, critical for real-time robotic applications."}),"\n",(0,a.jsx)(n.h3,{id:"linear-algebra",children:"Linear Algebra"}),"\n",(0,a.jsx)(n.p,{children:"Mathematical foundation for transformations and calculations in computer vision and robotics, including matrix operations and vector mathematics."}),"\n",(0,a.jsx)(n.h3,{id:"logger",children:"Logger"}),"\n",(0,a.jsx)(n.p,{children:"A system component that records events, errors, and other information for debugging and monitoring purposes."}),"\n",(0,a.jsx)(n.h2,{id:"m",children:"M"}),"\n",(0,a.jsx)(n.h3,{id:"machine-learning",children:"Machine Learning"}),"\n",(0,a.jsx)(n.p,{children:"A branch of AI that enables systems to learn and improve from experience without being explicitly programmed for every task."}),"\n",(0,a.jsx)(n.h3,{id:"message-queuing",children:"Message Queuing"}),"\n",(0,a.jsx)(n.p,{children:"A communication pattern where messages are stored in queues for asynchronous processing, ensuring reliable component communication."}),"\n",(0,a.jsx)(n.h3,{id:"microservice-architecture",children:"Microservice Architecture"}),"\n",(0,a.jsx)(n.p,{children:"A software design approach that structures an application as a collection of loosely coupled services, applicable to VLA component design."}),"\n",(0,a.jsx)(n.h3,{id:"middleware",children:"Middleware"}),"\n",(0,a.jsx)(n.p,{children:"Software that provides common services and capabilities to applications beyond what's offered by the operating system, used in ROS 2."}),"\n",(0,a.jsx)(n.h3,{id:"model-optimization",children:"Model Optimization"}),"\n",(0,a.jsx)(n.p,{children:"Techniques to improve the efficiency and performance of AI models, including quantization, pruning, and distillation."}),"\n",(0,a.jsx)(n.h2,{id:"n",children:"N"}),"\n",(0,a.jsx)(n.h3,{id:"natural-language-processing-nlp",children:"Natural Language Processing (NLP)"}),"\n",(0,a.jsx)(n.p,{children:"A field of AI focused on enabling computers to understand, interpret, and generate human language, central to VLA command processing."}),"\n",(0,a.jsx)(n.h3,{id:"neural-network",children:"Neural Network"}),"\n",(0,a.jsx)(n.p,{children:"A computing system inspired by biological neural networks that learns to perform tasks by considering examples, used in vision and speech systems."}),"\n",(0,a.jsx)(n.h3,{id:"non-functional-requirement",children:"Non-Functional Requirement"}),"\n",(0,a.jsx)(n.p,{children:"A requirement that specifies criteria for evaluating how a system performs, such as response time, reliability, and security."}),"\n",(0,a.jsx)(n.h2,{id:"o",children:"O"}),"\n",(0,a.jsx)(n.h3,{id:"object-detection",children:"Object Detection"}),"\n",(0,a.jsx)(n.p,{children:"A computer vision task that identifies and locates objects within an image, providing bounding boxes and class labels."}),"\n",(0,a.jsx)(n.h3,{id:"observer-pattern",children:"Observer Pattern"}),"\n",(0,a.jsx)(n.p,{children:"A behavioral design pattern where an object maintains a list of dependents that are notified of state changes, used in status reporting."}),"\n",(0,a.jsx)(n.h3,{id:"openai-api",children:"OpenAI API"}),"\n",(0,a.jsx)(n.p,{children:"Application programming interface providing access to OpenAI's models including Whisper for speech recognition and GPT for cognitive planning."}),"\n",(0,a.jsx)(n.h3,{id:"operational-semantics",children:"Operational Semantics"}),"\n",(0,a.jsx)(n.p,{children:"The specification of how a system behaves and processes commands, defining the meaning of operations in the VLA system."}),"\n",(0,a.jsx)(n.h2,{id:"p",children:"P"}),"\n",(0,a.jsx)(n.h3,{id:"perception-pipeline",children:"Perception Pipeline"}),"\n",(0,a.jsx)(n.p,{children:"The complete processing chain from raw sensor data to meaningful information about the environment, including object detection and spatial reasoning."}),"\n",(0,a.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,a.jsx)(n.p,{children:"Techniques to improve the efficiency, speed, and resource usage of the VLA system while maintaining functionality."}),"\n",(0,a.jsx)(n.h3,{id:"planning-algorithm",children:"Planning Algorithm"}),"\n",(0,a.jsx)(n.p,{children:"A computational method for determining a sequence of actions to achieve a goal, used in cognitive planning for command interpretation."}),"\n",(0,a.jsx)(n.h3,{id:"plugin-architecture",children:"Plugin Architecture"}),"\n",(0,a.jsx)(n.p,{children:"A design pattern that allows functionality to be added to an application at runtime, used in VLA for extending capabilities."}),"\n",(0,a.jsx)(n.h3,{id:"prompt-engineering",children:"Prompt Engineering"}),"\n",(0,a.jsx)(n.p,{children:"The practice of crafting effective inputs to guide LLMs toward desired outputs, crucial for cognitive planning quality."}),"\n",(0,a.jsx)(n.h3,{id:"publisher-subscriber-pattern",children:"Publisher-Subscriber Pattern"}),"\n",(0,a.jsx)(n.p,{children:"A messaging pattern where senders publish messages without knowledge of receivers, used extensively in ROS 2 communication."}),"\n",(0,a.jsx)(n.h2,{id:"q",children:"Q"}),"\n",(0,a.jsx)(n.h3,{id:"quality-assurance",children:"Quality Assurance"}),"\n",(0,a.jsx)(n.p,{children:"Systematic process to ensure that the VLA system meets specified requirements and performs as expected."}),"\n",(0,a.jsx)(n.h3,{id:"query-optimization",children:"Query Optimization"}),"\n",(0,a.jsx)(n.p,{children:"Techniques to improve the efficiency of data retrieval operations, applicable to perception data access patterns."}),"\n",(0,a.jsx)(n.h2,{id:"r",children:"R"}),"\n",(0,a.jsx)(n.h3,{id:"real-time-processing",children:"Real-Time Processing"}),"\n",(0,a.jsx)(n.p,{children:"Systems that process data as it arrives with guaranteed response times, essential for responsive VLA command execution."}),"\n",(0,a.jsx)(n.h3,{id:"repository-pattern",children:"Repository Pattern"}),"\n",(0,a.jsx)(n.p,{children:"A design pattern that mediates between domain objects and data mapping layers, used for managing VLA system data access."}),"\n",(0,a.jsx)(n.h3,{id:"robot-operating-system-2-ros-2",children:"Robot Operating System 2 (ROS 2)"}),"\n",(0,a.jsx)(n.p,{children:"Middleware framework for robotics applications providing services like hardware abstraction, device drivers, and message passing."}),"\n",(0,a.jsx)(n.h3,{id:"ros-2-actions",children:"ROS 2 Actions"}),"\n",(0,a.jsx)(n.p,{children:"A communication pattern in ROS 2 for long-running tasks with feedback and status updates, used for robotic action execution."}),"\n",(0,a.jsx)(n.h3,{id:"runtime-environment",children:"Runtime Environment"}),"\n",(0,a.jsx)(n.p,{children:"The set of software components and configurations required to execute the VLA system, including Python, ROS 2, and dependencies."}),"\n",(0,a.jsx)(n.h2,{id:"s",children:"S"}),"\n",(0,a.jsx)(n.h3,{id:"semantic-segmentation",children:"Semantic Segmentation"}),"\n",(0,a.jsx)(n.p,{children:"A computer vision task that classifies each pixel in an image, providing detailed object boundaries for precise manipulation."}),"\n",(0,a.jsx)(n.h3,{id:"singleton-pattern",children:"Singleton Pattern"}),"\n",(0,a.jsx)(n.p,{children:"A design pattern that restricts a class to a single instance, used for system managers and coordinators."}),"\n",(0,a.jsx)(n.h3,{id:"speech-to-text",children:"Speech-to-Text"}),"\n",(0,a.jsx)(n.p,{children:"The process of converting spoken language into written text, implemented using Whisper in the VLA system."}),"\n",(0,a.jsx)(n.h3,{id:"state-machine",children:"State Machine"}),"\n",(0,a.jsx)(n.p,{children:"A behavioral model that defines the states of a system and the transitions between them, used for execution state management."}),"\n",(0,a.jsx)(n.h3,{id:"state-management",children:"State Management"}),"\n",(0,a.jsx)(n.p,{children:"The process of tracking and managing the current condition of the system across all components and execution phases."}),"\n",(0,a.jsx)(n.h3,{id:"stereo-vision",children:"Stereo Vision"}),"\n",(0,a.jsx)(n.p,{children:"A computer vision technique that uses two or more cameras to determine depth information, enhancing 3D position estimation."}),"\n",(0,a.jsx)(n.h3,{id:"supervised-learning",children:"Supervised Learning"}),"\n",(0,a.jsx)(n.p,{children:"A machine learning approach where models learn from labeled training data, used in object detection model training."}),"\n",(0,a.jsx)(n.h3,{id:"system-architecture",children:"System Architecture"}),"\n",(0,a.jsx)(n.p,{children:"The fundamental structure of the VLA system, defining components, relationships, and principles for organization."}),"\n",(0,a.jsx)(n.h2,{id:"t",children:"T"}),"\n",(0,a.jsx)(n.h3,{id:"task-decomposition",children:"Task Decomposition"}),"\n",(0,a.jsx)(n.p,{children:"The process of breaking complex commands into simpler, executable steps, performed by the cognitive planning component."}),"\n",(0,a.jsx)(n.h3,{id:"thread-safety",children:"Thread Safety"}),"\n",(0,a.jsx)(n.p,{children:"Programming practice ensuring correct behavior of concurrent programs where multiple threads access shared resources."}),"\n",(0,a.jsx)(n.h3,{id:"three-dimensional-3d-reconstruction",children:"Three-Dimensional (3D) Reconstruction"}),"\n",(0,a.jsx)(n.p,{children:"The process of creating 3D models from 2D images, used in VLA for spatial reasoning and navigation planning."}),"\n",(0,a.jsx)(n.h3,{id:"transformer-architecture",children:"Transformer Architecture"}),"\n",(0,a.jsx)(n.p,{children:"A deep learning model architecture that uses attention mechanisms, foundational to both Whisper and LLM components."}),"\n",(0,a.jsx)(n.h3,{id:"type-hints",children:"Type Hints"}),"\n",(0,a.jsx)(n.p,{children:"Annotations in Python code that specify the expected data types of variables, parameters, and return values for better code clarity."}),"\n",(0,a.jsx)(n.h2,{id:"u",children:"U"}),"\n",(0,a.jsx)(n.h3,{id:"unit-testing",children:"Unit Testing"}),"\n",(0,a.jsx)(n.p,{children:"A testing methodology that validates individual components of the VLA system in isolation to ensure correct functionality."}),"\n",(0,a.jsx)(n.h3,{id:"user-experience-ux",children:"User Experience (UX)"}),"\n",(0,a.jsx)(n.p,{children:"The overall experience of a person using the VLA system, including ease of use and effectiveness of command processing."}),"\n",(0,a.jsx)(n.h3,{id:"utility-functions",children:"Utility Functions"}),"\n",(0,a.jsx)(n.p,{children:"Helper functions that provide common operations used across multiple components of the VLA system."}),"\n",(0,a.jsx)(n.h2,{id:"v",children:"V"}),"\n",(0,a.jsx)(n.h3,{id:"vision-language-action-vla",children:"Vision-Language-Action (VLA)"}),"\n",(0,a.jsx)(n.p,{children:"The integrated system combining computer vision, natural language processing, and robotic action execution for human-robot interaction."}),"\n",(0,a.jsx)(n.h3,{id:"voice-command-processing",children:"Voice Command Processing"}),"\n",(0,a.jsx)(n.p,{children:"The component responsible for converting speech input into structured text commands for the cognitive planning system."}),"\n",(0,a.jsx)(n.h3,{id:"voice-input-handler",children:"Voice Input Handler"}),"\n",(0,a.jsx)(n.p,{children:"A system component that captures and preprocesses audio data from microphones for speech recognition."}),"\n",(0,a.jsx)(n.h3,{id:"vision-processing",children:"Vision Processing"}),"\n",(0,a.jsx)(n.p,{children:"The component responsible for analyzing visual data to detect objects, estimate positions, and understand spatial relationships."}),"\n",(0,a.jsx)(n.h3,{id:"value-stream-mapping",children:"Value Stream Mapping"}),"\n",(0,a.jsx)(n.p,{children:"A lean manufacturing technique adapted for software to identify and optimize the flow of value in the VLA system."}),"\n",(0,a.jsx)(n.h2,{id:"w",children:"W"}),"\n",(0,a.jsx)(n.h3,{id:"whisper-model",children:"Whisper Model"}),"\n",(0,a.jsx)(n.p,{children:"OpenAI's speech recognition model used in the VLA system for converting voice commands to text."}),"\n",(0,a.jsx)(n.h3,{id:"workload-management",children:"Workload Management"}),"\n",(0,a.jsx)(n.p,{children:"The process of distributing and scheduling computational tasks across available resources to optimize performance."}),"\n",(0,a.jsx)(n.h3,{id:"websocket-communication",children:"WebSocket Communication"}),"\n",(0,a.jsx)(n.p,{children:"A communication protocol that provides full-duplex communication channels over a single TCP connection, used in Isaac Sim integration."}),"\n",(0,a.jsx)(n.h2,{id:"x",children:"X"}),"\n",(0,a.jsx)(n.h3,{id:"xml-configuration",children:"XML Configuration"}),"\n",(0,a.jsx)(n.p,{children:"Extensible Markup Language used for configuration files and data exchange between VLA system components."}),"\n",(0,a.jsx)(n.h2,{id:"y",children:"Y"}),"\n",(0,a.jsx)(n.h3,{id:"yaml-configuration",children:"YAML Configuration"}),"\n",(0,a.jsx)(n.p,{children:"A human-readable data serialization format used for VLA system configuration files and documentation."}),"\n",(0,a.jsx)(n.h2,{id:"z",children:"Z"}),"\n",(0,a.jsx)(n.h3,{id:"zero-shot-learning",children:"Zero-Shot Learning"}),"\n",(0,a.jsx)(n.p,{children:"An AI capability where models can perform tasks they weren't explicitly trained on, relevant for handling novel commands."}),"\n",(0,a.jsx)(n.h3,{id:"zipfs-law",children:"Zipf's Law"}),"\n",(0,a.jsx)(n.p,{children:"A statistical observation about natural language distribution that influences how language models process commands in the VLA system."})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>s});var t=i(6540);const a={},o=t.createContext(a);function r(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);