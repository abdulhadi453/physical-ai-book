import type {SidebarsConfig} from '@docusaurus/plugin-content-docs';

// This runs in Node.js - Don't use client-side code here (browser APIs, JSX...)

/**
 * Creating a sidebar enables you to:
 - create an ordered group of docs
 - render a sidebar for each doc of that group
 - provide next/previous navigation

 The sidebars can be generated from the filesystem, or explicitly defined here.

 Create as many sidebars as you want.
 */
const sidebars: SidebarsConfig = {
  // By default, Docusaurus generates a sidebar from the docs folder structure
  // tutorialSidebar: [{type: 'autogenerated', dirName: '.'}],

  // Manual sidebar structure for Physical AI Book following Module X: Title, Chapter X.Y: Title, Lesson Title hierarchy
  tutorialSidebar: [
    'intro',
    {
      type: 'category',
      label: 'Module 1: The Robotic Nervous System (ROS 2)',
      items: [
        {
          type: 'category',
          label: 'Chapter 1.1: Introduction to ROS 2 as the Robotic Nervous System',
          items: [
            'chapter-1/intro',
            'chapter-1/lesson-1',  // Communication Primitives
            'chapter-1/lesson-2',  // rclpy for AI Agent Integration
            'chapter-1/lesson-3',  // URDF Fundamentals for Humanoid Robots
            'chapter-1/lesson-4',  // Data Flow Tracing (AI → ROS 2 → Actuator)
            'chapter-1/lesson-5',  // Humanoid Context Applications
            'chapter-1/lesson-6',  // Advanced ROS 2 Concepts
          ],
        },
      ],
    },
    {
      type: 'category',
      label: 'Module 2: The Digital Twin (Gazebo & Unity)',
      items: [
        {
          type: 'category',
          label: 'Chapter 2.1: Physics Simulation Environment Setup',
          items: [
            'chapter-2/intro',
            'chapter-2/lesson-1',  // Physics Simulation Environment Setup
            'chapter-2/lesson-2',  // Unity Physics Environment Setup
            'chapter-2/lesson-3',  // Physics Parameters Configuration
          ],
        },
        {
          type: 'category',
          label: 'Chapter 2.2: Sensor Simulation and Integration',
          items: [
            'chapter-2/lesson-4',  // Gazebo Physics Environment Setup (LiDAR)
            'chapter-2/lesson-5',  // Unity Physics Environment Setup (Depth Camera)
            'chapter-2/lesson-6',  // Physics Parameters Configuration (IMU)
            'chapter-2/lesson-7',  // LiDAR Sensor Simulation Guide
            'chapter-2/lesson-8',  // Depth Camera Simulation Guide
            'chapter-2/lesson-9',  // IMU Sensor Simulation Guide
          ],
        },
        {
          type: 'category',
          label: 'Chapter 2.3: Advanced Simulation and Validation',
          items: [
            'chapter-2/exercise-1',  // Exercise 1: Basic Environment Creation
            'chapter-2/exercise-2',  // Exercise 2: Sensor Integration
            'chapter-2/exercise-3',  // Exercise 3: Advanced Navigation
            'chapter-2/exercise-4',  // Exercise 4: Cross-Platform Comparative Analysis
            'chapter-2/tests',       // Physics Simulation Validation Tests
            'chapter-2/sensor-validation-tests',  // Sensor Data Validation Tests
            'chapter-2/assessments', // Assessment Questions for Physics Simulation
            'chapter-2/sensor-assessments',      // Assessment Questions for Sensor Simulation
            'chapter-2/educator-guide',          // Educator Guide for Simulation Exercises
            'chapter-2/prerequisite-check',      // Prerequisite Knowledge Validation
            'chapter-2/cross-platform-guide',    // Cross-Platform Simulation Comparison Guide
            'chapter-2/platform-differences',    // Platform-Specific Differences
            'chapter-2/quality-validation',      // Quality Validation Guide
            'chapter-2/progress-tracking-guide', // Progress Tracking Guide
            'chapter-2/researcher-resources',    // Researcher Resources
            'chapter-2/ai-integration',          // AI Integration Guide
            'chapter-2/references',              // References
          ],
        },
      ],
    },
    {
      type: 'category',
      label: 'Module 3: The AI-Robot Brain (NVIDIA Isaac™)',
      items: [
        {
          type: 'category',
          label: 'Chapter 3.1: NVIDIA Isaac Platform Integration',
          items: [
            'chapter-3/intro',
            'chapter-3/lesson-1',  // NVIDIA Isaac Simulation Environment and ROS Integration
            'chapter-3/lesson-2',  // Navigation and Path Planning with Nav2
            'chapter-3/lesson-3',  // Perception and AI Decision Making
            'chapter-3/lesson-4',  // AI-Robot Integration and Optimization
          ],
        },
        {
          type: 'category',
          label: 'Chapter 3.2: System Setup and Configuration',
          items: [
            'chapter-3/setup',     // Setup Guide for NVIDIA Isaac
            'chapter-3/isaac-ros-setup',      // Isaac ROS Bridge Setup
            'chapter-3/nav2-setup',           // Nav2 Setup for Isaac
            'chapter-3/simulation-setup',     // Isaac Simulation Setup
          ],
        },
        {
          type: 'category',
          label: 'Chapter 3.3: Advanced Implementation',
          items: [
            'chapter-3/perception-pipeline',  // Perception Pipeline Implementation
            'chapter-3/sensor-integration',   // Sensor Integration in Isaac
            'chapter-3/model-deployment',     // AI Model Deployment in Isaac
            'chapter-3/exercises',            // Isaac Exercises
            'chapter-3/assessments',          // Isaac Assessments
            'chapter-3/assessment',           // Isaac Assessment Details
            'chapter-3/progress-tracking-guide',  // Progress Tracking Guide
            'chapter-3/educator-guide',           // Educator Guide
            'chapter-3/researcher-resources',     // Researcher Resources
            'chapter-3/communication-protocols',  // Communication Protocols
            'chapter-3/safety-framework',         // Safety Framework
            'chapter-3/performance-monitoring',   // Performance Monitoring
            'chapter-3/summary',                  // Module Summary
          ],
        },
      ],
    },
    {
      type: 'category',
      label: 'Module 4: Vision-Language-Action (VLA) Systems',
      items: [
        {
          type: 'category',
          label: 'Chapter 4.1: Introduction to Vision-Language-Action Systems',
          items: [
            'chapter-4/intro',
            'chapter-4/lesson-1',  // Voice Command Processing with Whisper
            'chapter-4/lesson-2',  // LLM-based Cognitive Planning
            'chapter-4/lesson-3',  // Visual Perception Integration
            'chapter-4/lesson-4',  // ROS 2 Action Execution
            'chapter-4/lesson-5',  // VLA System Integration
          ],
        },
        {
          type: 'category',
          label: 'Chapter 4.2: Advanced VLA Implementation',
          items: [
            'chapter-4/setup',     // VLA System Setup Guide
            'chapter-4/integration-guide',         // Integration of VLA Components
            'chapter-4/exercises',                 // VLA Practical Exercises
            'chapter-4/assessments',               // VLA Assessment Questions
            'chapter-4/educator-guide',            // Educator Guide for VLA Module
            'chapter-4/researcher-resources',      // Researcher Resources for VLA
            'chapter-4/performance-monitoring',    // Performance Monitoring for VLA Systems
            'chapter-4/troubleshooting',           // Troubleshooting VLA Systems
            'chapter-4/security-considerations',   // Security Considerations for VLA Systems
            'chapter-4/capstone-project',          // Capstone: Autonomous Humanoid Task
          ],
        },
      ],
    },
    'contributing',
  ],
};

export default sidebars;
